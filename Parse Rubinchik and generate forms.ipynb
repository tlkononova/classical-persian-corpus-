{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get verbs from Rubinchik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata as ud\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class AlphabetDetector:\n",
    "    def __init__(self, no_memory=False):\n",
    "        self.alphabet_letters = defaultdict(dict)\n",
    "        self.no_memory = no_memory\n",
    "\n",
    "    def is_in_alphabet(self, uchr, alphabet):\n",
    "        if self.no_memory:\n",
    "            return alphabet in ud.name(uchr)\n",
    "        try:\n",
    "            return self.alphabet_letters[alphabet][uchr]\n",
    "        except KeyError:\n",
    "            return self.alphabet_letters[alphabet].setdefault(\n",
    "                uchr, alphabet in ud.name(uchr))\n",
    "\n",
    "    def only_alphabet_chars(self, unistr, alphabet):\n",
    "        return all(self.is_in_alphabet(uchr, alphabet)\n",
    "                   for uchr in unistr if uchr.isalpha())\n",
    "\n",
    "    def detect_alphabet(self, unistr):\n",
    "        return set(ud.name(char).split(' ')[0]\n",
    "                   for char in unistr if char.isalpha())\n",
    "\n",
    "    def is_cyrillic(self, unistr):\n",
    "        return True if self.only_alphabet_chars(unistr, 'CYRILLIC') else False\n",
    "\n",
    "    def is_latin(self, unistr):\n",
    "        return True if self.only_alphabet_chars(unistr, 'LATIN') else False\n",
    "\n",
    "    def is_arabic(self, unistr):\n",
    "        return True if self.only_alphabet_chars(unistr, 'ARABIC') else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ad = AlphabetDetector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "persian = '[ا-یۀۀآـةيژؤإأ]+'\n",
    "p = re.compile(persian)\n",
    "\n",
    "#states = {(1,'word'), (2,'trans'), (3,'pos'), (4,'verb'), (5,'stem')}\n",
    "auto = {}\n",
    "AllPOS = set()\n",
    "state = 0\n",
    "word = ''\n",
    "pos = ''\n",
    "stem = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "باش بودن\n",
      "بودن باش\n",
      "برافراز برافراشتن\n",
      "برافراشتن برافراز\n",
      "برانداز برانداختن\n",
      "برانداختن برانداز\n",
      "برشو برشدن\n",
      "برشدن برشو\n",
      "تنیدن تن\n",
      "تن تنیدن\n",
      "تندیدن تن\n",
      "تن تندیدن\n",
      "تنیدن تن\n",
      "تن تنیدن\n",
      "ОНВ гл.\n",
      "\n",
      "سا سودن\n",
      "سودن سا\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state = 0\n",
    "Vocab = {}\n",
    "\n",
    "def getPersian(line):\n",
    "    match = p.search(line)\n",
    "    if match and match.group() != None:\n",
    "        return match.group().rstrip().strip('\\u200c')\n",
    "    else:\n",
    "        print(line)\n",
    "        return None\n",
    "\n",
    "def addVerb(stem, verb):\n",
    "    \n",
    "    verb = verb.strip('\\u200c')\n",
    "    stem = stem.strip('\\u200c')\n",
    "    if (stem.strip().endswith('تن') or stem.strip().endswith('دن')) and (not verb.strip().endswith('تن') or not stem.strip().endswith('دن')):\n",
    "        print(verb, stem)\n",
    "        verbnew  = stem\n",
    "        stem = verb\n",
    "        verb = verbnew\n",
    "        print(verb, stem)\n",
    "    if verb in Vocab.keys() and Vocab[verb] != stem:\n",
    "        Vocab[verb] = [Vocab[verb], stem]\n",
    "        #print(str(verb[:-1])+'#'+str(stem))\n",
    "        w.write(str(verb[:-1])+'#'+str(stem)+'\\n')\n",
    "    elif verb not in Vocab.keys():\n",
    "        Vocab[verb] = stem\n",
    "        #print(str(verb[:-1])+'#'+str(stem))\n",
    "        w.write(str(verb[:-1])+'#'+str(stem)+'\\n')\n",
    "\n",
    "w = open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\verb-stem.txt', 'w', encoding='utf-8')\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\rubinchik.txt\", 'r', encoding='utf-8') as f:\n",
    "#with open(\"./rubinchik/rub_test.txt\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if ad.is_arabic(line.strip()) and state == 0: \n",
    "            state = 1\n",
    "            #entry[0] = line.strip()\n",
    "            word = line.strip().strip('\\u200c')\n",
    "            #print('state1')\n",
    "        elif len(line)>2 and line.strip()[0] == '[' and line.strip()[-1] == ']' and state == 1:\n",
    "            state = 2\n",
    "            #print('state2')\n",
    "            #print(line)\n",
    "        elif ad.is_cyrillic(line.strip()) and state == 2:\n",
    "            #print('state3')\n",
    "            #if line.split('., ')[0].strip(' \\\\n') in poslist:\n",
    "            state = 3\n",
    "            #entry[1] = line.split('., ')[0].strip(' \\\\n')\n",
    "            pos = line.split('., ')[0].strip(' \\\\n').strip('\\\\n')\n",
    "            #AllPOS.add(pos)\n",
    "            #if entry[1] == 'гл.':\n",
    "            if 'гл.' in pos:\n",
    "                #print('verb')\n",
    "                state = 4\n",
    "                #print('state4')\n",
    "                \n",
    "            #elif entry[1] == 'ОНВ':\n",
    "            elif 'ОНВ' in pos:\n",
    "                #print('ONV')\n",
    "                state = 5\n",
    "                #print('state5')\n",
    "                \n",
    "        elif state == 4 and 'ОНВ' in line:\n",
    "            #print('verb --- ONV')\n",
    "            if getPersian(line):\n",
    "                stem = getPersian(line) \n",
    "            #print(stem)\n",
    "            verb = word\n",
    "            \n",
    "            AllPOS.add(pos)\n",
    "            #Vocab[entry[0]] = entry[1]\n",
    "            #entry = verb, pos, stem\n",
    "            #Vocab[verb] = stem\n",
    "            #print(str(verb[:-1])+'#'+str(stem))\n",
    "            addVerb(stem, verb)\n",
    "            state = 0\n",
    "            word = ''\n",
    "            pos = ''\n",
    "            stem = ''\n",
    "            \n",
    "        elif state == 5 and 'гл.' in line:\n",
    "            #print('ONV ---- verb')\n",
    "            if getPersian(line):\n",
    "                verb = getPersian(line)\n",
    "            stem = word\n",
    "            #print(verb)\n",
    "            \n",
    "            AllPOS.add(pos)\n",
    "            #Vocab[verb] = stem\n",
    "            #print(str(verb[:-1])+'#'+str(stem))\n",
    "            addVerb(stem, verb)\n",
    "            state = 0\n",
    "            word = ''\n",
    "            pos = ''\n",
    "            stem = ''\n",
    "                #print(entry[1])\n",
    "        elif line.startswith('ОНВ') and state == 2:\n",
    "            if 'гл.' in line:\n",
    "                #print('ONV+verb')\n",
    "                if getPersian(line):\n",
    "                    verb = getPersian(line)\n",
    "                #print(verb)\n",
    "                stem = word\n",
    "                AllPOS.add(pos)\n",
    "                #Vocab[verb] = stem\n",
    "                addVerb(stem, verb)\n",
    "                #print(str(verb[:-1])+'#'+str(stem))\n",
    "                state = 0\n",
    "                word = ''\n",
    "                pos = ''\n",
    "                stem = ''\n",
    "        elif line.startswith('гл.') and state == 2:\n",
    "            if 'ОНВ' in line:\n",
    "                #print('verb+ONV')\n",
    "                #parse\n",
    "                if getPersian(line):\n",
    "                    stem = getPersian(line)\n",
    "                #print(stem)\n",
    "                verb = word\n",
    "                AllPOS.add(pos)\n",
    "                #print(str(verb[:-1])+'#'+str(stem))\n",
    "                #Vocab[verb] = stem\n",
    "                addVerb(stem, verb)\n",
    "                state = 0\n",
    "                word = ''\n",
    "                pos = ''\n",
    "                stem = ''\n",
    "            \n",
    "        else:\n",
    "            state = 0\n",
    "            #print('state0')\n",
    "            word = ''\n",
    "            pos = ''\n",
    "            stem = ''\n",
    "\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AllPOS)\n",
    "#AllPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Nouns from Rubinchik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "درجات\n",
    "[darajāt]\n",
    "сущ.\n",
    "мн. от درجه\n",
    "\n",
    "درجه\n",
    "[daraje]\n",
    "сущ.\n",
    "мн. درجات [darajāt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мн.\n",
      "\n",
      "мн. дядья (дяди по отцу)\n",
      "\n",
      "мн.\n",
      "\n",
      "мн. ч. выдающиеся (от суффикса превосходной степени -tarin)\n",
      "\n",
      "сущ. мн.\n",
      "\n",
      "мн. ч. от \n",
      "\n",
      "мн. неслышащие, глухие\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word = ''\n",
    "noun = ''\n",
    "plural = ''\n",
    "state = 0\n",
    "Nouns = {}\n",
    "\n",
    "def getPersian(line):\n",
    "    match = p.search(line)\n",
    "    if match and match.group() != None:\n",
    "        return match.group().rstrip().strip('\\u200c')\n",
    "    else:\n",
    "        print(line)\n",
    "        return None\n",
    "\n",
    "def addNoun(noun, plural):\n",
    "    \n",
    "    noun = noun.strip('\\u200c')\n",
    "    plural = plural.strip('\\u200c')\n",
    "    \n",
    "    if noun in Nouns.keys() and plural not in Nouns[noun]:\n",
    "\n",
    "        Nouns[noun].append(plural)\n",
    "        w.write(str(noun)+'#'+str(plural)+'\\n')\n",
    "    elif noun not in Nouns.keys():\n",
    "        Nouns[noun] = []\n",
    "        Nouns[noun].append(plural)\n",
    "       \n",
    "        w.write(str(noun)+'#'+str(plural)+'\\n')\n",
    "\n",
    "w = open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\noun-plural.txt', 'w', encoding='utf-8')\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\rubinchik.txt\", 'r', encoding='utf-8') as f:\n",
    "\n",
    "    for line in f:\n",
    "        if ad.is_arabic(line.strip()) and state == 0: \n",
    "            state = 1\n",
    "            \n",
    "            word = line.strip().strip('\\u200c')\n",
    "            #print('state1')\n",
    "        elif len(line) > 2 and line.strip()[0] == '[' and line.strip()[-1] == ']' and state == 1:\n",
    "            state = 2\n",
    "            #print('state2')\n",
    "        elif ad.is_cyrillic(line.strip()) and state == 2 and 'сущ.' in line:\n",
    "            #print('state3')\n",
    "            state = 3\n",
    "            #pos = line.split('., ')[0].strip(' \\n').strip('\\n')\n",
    "        \n",
    "            if 'мн. от' in line:\n",
    "                #print('verb')\n",
    "                if getPersian(line):\n",
    "                    noun = getPersian(line) \n",
    "                plural = word\n",
    "                addNoun(noun, plural)\n",
    "                state = 0\n",
    "                word = ''\n",
    "                pos = ''\n",
    "                noun = ''\n",
    "                plural = ''\n",
    "                #print('state4')\n",
    "                \n",
    "            elif 'мн.' in line:\n",
    "                \n",
    "                if getPersian(line):\n",
    "                    plural = getPersian(line) \n",
    "                noun = word\n",
    "                addNoun(noun, plural)\n",
    "                state = 0\n",
    "                word = ''\n",
    "                pos = ''\n",
    "                noun = ''\n",
    "                plural = ''\n",
    "                #print('state5')\n",
    "                \n",
    "        elif state == 3 and 'мн. от' in line:\n",
    "            \n",
    "            if getPersian(line):\n",
    "                noun = getPersian(line) \n",
    "            \n",
    "            plural = word\n",
    "            addNoun(noun, plural)\n",
    "            state = 0\n",
    "            word = ''\n",
    "            pos = ''\n",
    "            noun = ''\n",
    "            plural = ''\n",
    "            \n",
    "        elif state == 3 and 'мн.' in line:\n",
    "            if getPersian(line):\n",
    "                plural = getPersian(line)\n",
    "            noun = word\n",
    "            \n",
    "            addNoun(noun, plural)\n",
    "            state = 0\n",
    "            word = ''\n",
    "            pos = ''\n",
    "            noun = ''\n",
    "            plural = ''\n",
    "               \n",
    "        \n",
    "            \n",
    "        else:\n",
    "            state = 0\n",
    "            #print('state0')\n",
    "            word = ''\n",
    "            pos = ''\n",
    "            stem = ''\n",
    "\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Noun with all affices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#conj + prep + stem + plur + pron + art + ra + cop\n",
    "#conj + prep + stem + plur + pron + art + ke\n",
    "#conj + prep + stem + plur + ez\n",
    "\n",
    "\n",
    "conjs = {'و': 'CONJ ', '': ''}\n",
    "\n",
    "preps = {'اندر': 'PREP ', 'در': 'PREP ', 'بر': 'PREP ', 'ز': 'PREP ', 'ب': 'PREP ', '': ''}\n",
    "\n",
    "#stems = set() #get from file\n",
    "\n",
    "#plur = ('ها', 'ان', 'جات', 'ات', 'گان', '')\n",
    "#plurs = {'ها': 'PL', 'ان': 'PL', 'ات': 'PL', '': 'SG'}\n",
    "plursE = {u'\\u200c'+'ها': 'PL', u'\\u200c'+'گان': 'PL', 'ات': 'PL', 'گان': 'PL', '': 'SG'}\n",
    "plursAll = {'ها': 'PL', 'ان': 'PL', '': 'SG', u'\\u200c'+'ها': 'PL'}\n",
    "\n",
    "\n",
    "# u'\\u200c' + pron\n",
    "# stem[:-1] + pron if stem.endswith('ه') or stem.endswith('ة') and plur in {'جات', 'ات', 'گان'}\n",
    "\n",
    "pronsAll = {'م': ' PRO1SG', 'ت': ' PRO2SG', 'ش': ' PRO3SG', 'مان': ' PRO1PL', \n",
    "         'تان': ' PRO2PL', 'شان': ' PRO3PL', '':'', u'\\u200c'+'م': ' PRO1SG', u'\\u200c'+'ت': ' PRO2SG', \n",
    "            u'\\u200c'+'ش': ' PRO3SG', u'\\u200c'+'مان': ' PRO1PL', \n",
    "         u'\\u200c'+'تان': ' PRO2PL', u'\\u200c'+'شان': ' PRO3PL'} \n",
    "pronsE = {u'\\u200c'+'ام': ' PRO1SG', u'\\u200c'+'ات': ' PRO2SG', u'\\u200c'+'اش': ' PRO3SG',\n",
    "          u'\\u200c'+'امان': ' PRO1PL', \n",
    "         u'\\u200c'+'اتان': ' PRO2PL', u'\\u200c'+'اشان': ' PRO3PL', '':''}\n",
    "pronsAIU = {'یم': ' PRO1SG', 'یت': ' PRO2SG', 'یش': ' PRO3SG', 'یمان': ' PRO1PL', \n",
    "         'یتان': ' PRO2PL', 'یشان': ' PRO3PL', '':''}\n",
    "\n",
    "# u'\\u200c' + pron\n",
    "# 'ا' + pron if stem.endswith('ه')\n",
    "# 'ی' + pron if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا')\n",
    "\n",
    "\n",
    "artsAll = {'ی':' YEH', '': ''}\n",
    "artsAIUE = {'یی': ' YEH', 'ئی': ' YEH', u'\\u200c'+'یی': ' YEH', u'\\u200c'+'ئی': ' YEH','': ''}\n",
    "# art = 'یی' if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# art = 'ئی' if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# u'\\u200c' + art\n",
    "\n",
    "ras = {'را': ' POSTP', '': ''}\n",
    "\n",
    "\n",
    "copsE = {u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': ''}\n",
    "\n",
    "copsAll = {'م': ' COP1SG', 'ی': ' COP2SG', 'ست': ' COP3SG', 'یم': ' COP1PL', 'ید': ' COP2PL',\n",
    "       'ند': ' COP3PL', u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': ''}\n",
    "# u'\\u200c' + cop\n",
    "# 'ا' + cop #if stem.endswith('ه')\n",
    "# u'\\u200c' + cop\n",
    "\n",
    "ezsAll = {'ی': ' EZ', '': ''}\n",
    "ezsE = {u'\\u200c'+'ی': ' EZ', '': ''}\n",
    "# if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "kes = {'که': ' CONJ', '':''}  #if gloss.endswith('YEH')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stems = {'کتاب'}\n",
    "\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "#w = open(path+'Nforms.txt', 'w', encoding='utf-8')\n",
    "\n",
    "forms = set()\n",
    "k = 0\n",
    "\n",
    "form = ''\n",
    "tag = ''\n",
    "for stem in stems:\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "    \n",
    "    for conj in conjs:\n",
    "        conjform = ''\n",
    "        conjtag = ''\n",
    "        conjform += conj\n",
    "        conjtag += conjs[conj]\n",
    "        \n",
    "        for prep in preps:\n",
    "            prepform = ''\n",
    "            preptag = ''\n",
    "            prepform = conjform + prep\n",
    "            preptag = conjtag + preps[prep]\n",
    "            \n",
    "            stemform = prepform + stem\n",
    "            \n",
    "            if (stemform.endswith('ه') or stemform.endswith('ة')):\n",
    "                plurs = plursE\n",
    "            else:\n",
    "                plurs = plursAll\n",
    "                \n",
    "            for plur in plurs:\n",
    "                \n",
    "                plurform = ''\n",
    "                plurtag = ''\n",
    "                \n",
    "                if plur == 'ات' or plur == 'گان':\n",
    "                    stemform = stemform[:-1]\n",
    "                \n",
    "                plurform = stemform + plur\n",
    "                plurtag = preptag + plurs[plur]\n",
    "                \n",
    "    \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    ezs = ezsAll\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    ezs = ezsE\n",
    "                else:\n",
    "                    ezs = {'':''}\n",
    "                # if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "                # u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "                for ez in ezs:\n",
    "                    ezform = ''\n",
    "                    eztag = ''\n",
    "                    ezform = plurform + ez\n",
    "                    eztag = plurtag + ezs[ez]\n",
    "                    \n",
    "                    forms.add((ezform, eztag))\n",
    "                    k += 1\n",
    "                    #if k%100 == 0:\n",
    "                    #    print(k)\n",
    "                    #if ezform:\n",
    "                    #    w.write(ezform)\n",
    "                    #    w.write('\\t')\n",
    "                    #    w.write(eztag)\n",
    "                    #    w.write('\\n')\n",
    "                    \n",
    "                \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    prons = pronsAIU\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    prons = pronsE\n",
    "                else:\n",
    "                    prons = pronsAll\n",
    "                \n",
    "                for pron in prons:\n",
    "                    pronform = ''\n",
    "                    prontag = ''\n",
    "                    pronform = plurform + pron\n",
    "                    prontag = plurtag + prons[pron]\n",
    "                    \n",
    "                    if pronform.endswith('ی') or pronform.endswith('و') or pronform.endswith('ا') or pronform.endswith('ه') or pronform.endswith('ة'):\n",
    "                        arts = artsAIUE\n",
    "                    else:\n",
    "                        arts = artsAll\n",
    "                \n",
    "                    for art in arts:\n",
    "                        artform = ''\n",
    "                        arttag = ''\n",
    "                        artform = pronform + art\n",
    "                        arttag = prontag + arts[art]\n",
    "                        \n",
    "                        if 'YEH' in arttag:\n",
    "                            for ke in kes:\n",
    "                                keform = ''\n",
    "                                ketag = ''\n",
    "                                keform = artform + ke\n",
    "                                ketag = arttag + kes[ke]\n",
    "\n",
    "                                forms.add((keform, ketag))\n",
    "                                k += 1\n",
    "                                #if k%100 == 0:\n",
    "                                #    print(k)\n",
    "                                #if keform:\n",
    "                                #    w.write(keform)\n",
    "                                #    w.write('\\t')\n",
    "                                #    w.write(ketag)\n",
    "                                #    w.write('\\n')\n",
    "                                \n",
    "                        \n",
    "                        for ra in ras:\n",
    "                            raform = ''\n",
    "                            ratag = ''\n",
    "                            \n",
    "                            raform = artform + ra\n",
    "                            ratag = arttag + ras[ra]\n",
    "                            \n",
    "                            if (raform.endswith('ه') or raform.endswith('ة')):\n",
    "                                cops = copsE\n",
    "                            else:\n",
    "                                cops = copsAll\n",
    "                                \n",
    "                            for cop in cops:\n",
    "                                copform = ''\n",
    "                                coptag = ''\n",
    "                                copform = raform + cop\n",
    "                                coptag = ratag + cops[cop]\n",
    "                                \n",
    "                                forms.add((copform, coptag))\n",
    "                                k += 1\n",
    "                                #if k%100 == 0:\n",
    "                                #    print(k)\n",
    "                                #if copform:\n",
    "                                #    w.write(copform)\n",
    "                                #    w.write('\\t')\n",
    "                                #    w.write(coptag)\n",
    "                                #    w.write('\\n')\n",
    "                                \n",
    "                                #form = ''\n",
    "                                #tag = ''\n",
    "                        \n",
    "                        \n",
    "#w.close()\n",
    "                \n",
    "                \n",
    "def addAff(affs, form, tag):\n",
    "    for aff in affs:\n",
    "        form += aff\n",
    "        tag += affs[aff]\n",
    "        \n",
    "        return form, tag\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39792"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "with open(path+'Nforms.txt', 'w', encoding='utf-8') as w:\n",
    "    for form, tag in forms:\n",
    "        w.write(form)\n",
    "        w.write('\\t')\n",
    "        w.write(tag)\n",
    "        w.write('\\n')\n",
    "#forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "na mi be present|past termPres|termPast|termPerf|termPP| pron\n",
    "\n",
    "nas = {'': 'NEG', '': 'NEGMA', '': 'POS'}\n",
    "mis = {'': 'MI', '':'MI', '':''}\n",
    "bes = {'': 'BE', '': ''}\n",
    "\n",
    "terms = {termPres, termPast, termPerf, termPP}\n",
    "termPres = {'': ''}\n",
    "\n",
    "termPP = {'': 'PP'}\n",
    "prons = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate noun forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "آباء\n",
      "آثار\n",
      "آثام\n",
      "آجال\n",
      "آحاد\n",
      "آذرع\n",
      "آرا\n",
      "آراء\n",
      "آزادگان\n",
      "آساد\n",
      "آصار\n",
      "آصال\n",
      "آفات\n",
      "آفاق\n",
      "آلات\n",
      "آلاف\n",
      "آلام\n",
      "آلهه\n",
      "آموزندگان\n",
      "آنات\n",
      "آنیه\n",
      "آیات\n",
      "اباریق\n",
      "اباعد\n",
      "ابالسه\n",
      "ابحاث\n",
      "ابخره\n",
      "ابخره\n",
      "ابدان\n",
      "ابراج\n",
      "ابصار\n",
      "ابصار\n",
      "ابطال\n",
      "ابطال\n",
      "ابعاد\n",
      "ابعاد\n",
      "ابعار\n",
      "ابعاض\n",
      "ابکار\n",
      "ابناء\n",
      "ابنیه\n",
      "ابواب\n",
      "ابوال\n",
      "ابیات\n",
      "اتباع\n",
      "اتباع\n",
      "اتباع\n",
      "اتباع\n",
      "اتعاب\n",
      "اتلال\n",
      "اثقال\n",
      "اثمار\n",
      "اثمان\n",
      "اثنیه\n",
      "اثواب\n",
      "اجانب\n",
      "اجداد\n",
      "اجراس\n",
      "اجرام\n",
      "اجرام\n",
      "اجزاء\n",
      "اجساد\n",
      "اجسام\n",
      "اجفان\n",
      "اجلاد\n",
      "اجلاف\n",
      "اجله\n",
      "اجناد\n",
      "اجناس\n",
      "اجنحه\n",
      "اجنه\n",
      "اجواف\n",
      "اجوبه\n",
      "اجور\n",
      "اجهزه\n",
      "اجیاد\n",
      "اجیال\n",
      "احادیث\n",
      "احباء\n",
      "احباب\n",
      "احبار\n",
      "احبال\n",
      "احبه\n",
      "احجار\n",
      "احجام\n",
      "احجام\n",
      "احداث\n",
      "احداث\n",
      "احداق\n",
      "احرار\n",
      "احرام\n",
      "احرام\n",
      "احرف\n",
      "احزاب\n",
      "احزان\n",
      "احساب\n",
      "احقاب\n",
      "احقاد\n",
      "احکام\n",
      "احکام\n",
      "احلام\n",
      "احمال\n",
      "احوال\n",
      "احوالات\n",
      "احیان\n",
      "اخبار\n",
      "اخبار\n",
      "اخدان\n",
      "اخراج\n",
      "اخراج\n",
      "اخراج\n",
      "اخراجات\n",
      "اخراجات\n",
      "اخریات\n",
      "اخشاب\n",
      "اخطار\n",
      "اخطار\n",
      "اخفاف\n",
      "اخلاء\n",
      "اخلاء\n",
      "اخلاط\n",
      "اخلاف\n",
      "اخلاق\n",
      "اخماس\n",
      "اخوات\n",
      "اخوان\n",
      "اخیار\n",
      "ادباء\n",
      "ادراج\n",
      "ادراج\n",
      "ادراک\n",
      "ادراک\n",
      "ادعیه\n",
      "ادله\n",
      "ادناس\n",
      "ادوات\n",
      "ادوار\n",
      "ادویه\n",
      "ادویه‌جات\n",
      "ادهار\n",
      "ادهان\n",
      "ادیار\n",
      "ادیان\n",
      "اذکار\n",
      "اذکار\n",
      "اذناب\n",
      "اذواق\n",
      "اذهان\n",
      "اذیال\n",
      "اراضی\n",
      "اراقم\n",
      "ارامل\n",
      "ارامنه\n",
      "ارانب\n",
      "ارایک\n",
      "ارباب\n",
      "ارباح\n",
      "ارباض\n",
      "ارباع\n",
      "ارباع\n",
      "اربطه\n",
      "ارتباطات\n",
      "ارجا\n",
      "ارجا\n",
      "ارجاس\n",
      "ارجل\n",
      "ارحام\n",
      "ارخته\n",
      "ارداف\n",
      "ارداف\n",
      "ارذال\n",
      "ارزاق\n",
      "ارضین\n",
      "ارغفه\n",
      "ارقا\n",
      "ارقا\n",
      "ارقام\n",
      "ارکان\n",
      "ارواث\n",
      "ارواح\n",
      "اریاح\n",
      "ازاهیر\n",
      "ازما‌ن\n",
      "ازمنه\n",
      "ازمه\n",
      "ازواج\n",
      "ازهار\n",
      "اساتید\n",
      "اساطیر\n",
      "اساطین\n",
      "اسافل\n",
      "اساقفه\n",
      "اسالیب\n",
      "اسامی\n",
      "اسانید\n",
      "اسباب\n",
      "اسباط\n",
      "اسباق\n",
      "استار\n",
      "استار\n",
      "استعارات\n",
      "اسجاع\n",
      "اسجان\n",
      "اسحار\n",
      "اسخیا\n",
      "اسر\n",
      "اسر\n",
      "اسراء\n",
      "اسرار\n",
      "اسرار\n",
      "اسطار\n",
      "اسفار\n",
      "اسفار\n",
      "اسقاط\n",
      "اسقاط\n",
      "اسقام\n",
      "اسلاف\n",
      "اسلاک\n",
      "اسماء\n",
      "اسمار\n",
      "اسماع\n",
      "اسماع\n",
      "اسماک\n",
      "اسناد\n",
      "اسناد\n",
      "اسنان\n",
      "اسنه\n",
      "اسوار\n",
      "اسواره\n",
      "اسواق\n",
      "اسود\n",
      "اسوله\n",
      "اسهام\n",
      "اسئله\n",
      "اشارت\n",
      "اشباح\n",
      "اشبار\n",
      "اشبال\n",
      "اشباه\n",
      "اشجار\n",
      "اشجان\n",
      "اشخاص\n",
      "اشخاص\n",
      "اشرار\n",
      "اشراف\n",
      "اشراف\n",
      "اشراقیون\n",
      "اشربه\n",
      "اشعار\n",
      "اشعار\n",
      "اشعار\n",
      "اشعه\n",
      "اشغال\n",
      "اشغال\n",
      "اشقیاء\n",
      "اشکال\n",
      "اشکال\n",
      "اشکانیان\n",
      "اشواق\n",
      "اشواک\n",
      "اشهر\n",
      "اشیاء\n",
      "اشیاع\n",
      "اصابع\n",
      "اصاغر\n",
      "اصباح\n",
      "اصحا\n",
      "اصحاب\n",
      "اصداغ\n",
      "اصداف\n",
      "اصدقا\n",
      "اصطلاحات\n",
      "اصفاد\n",
      "اصفار\n",
      "اصفیا\n",
      "اصقاع\n",
      "اصلاب\n",
      "اصم\n",
      "اصناف\n",
      "اصنام\n",
      "اصوات\n",
      "اصول\n",
      "اضافات\n",
      "اضالیل\n",
      "اضداد\n",
      "اضراب\n",
      "اضراب\n",
      "اضرار\n",
      "اضرار\n",
      "اضراس\n",
      "اضعاف\n",
      "اضعاف\n",
      "اضغاث\n",
      "اضلاع\n",
      "اضوا\n",
      "اضیاف\n",
      "اطایب\n",
      "اطباع\n",
      "اطباق\n",
      "اطعمه\n",
      "اطفال\n",
      "اطلاب\n",
      "اطلاعات\n",
      "اطناب\n",
      "اطناب\n",
      "اطواق\n",
      "اطهار\n",
      "اطیاب\n",
      "اطیار\n",
      "اظافر\n",
      "اظفار\n",
      "اظلال\n",
      "اظهارات\n",
      "اعاجم\n",
      "اعاجیب\n",
      "اعادی\n",
      "اعاریض\n",
      "اعالی\n",
      "اعتاب\n",
      "اعجاز\n",
      "اعجاز\n",
      "اعجام\n",
      "اعجام\n",
      "اعداء\n",
      "اعداد\n",
      "اعداد\n",
      "اعدام\n",
      "اعدام\n",
      "اعذار\n",
      "اعذار\n",
      "اعراب\n",
      "اعراب\n",
      "اعراص\n",
      "اعراض\n",
      "اعراض\n",
      "اعراض\n",
      "اعراق\n",
      "اعشار\n",
      "اعصاب\n",
      "اعصار\n",
      "اعضاء\n",
      "اعطاف\n",
      "اعطاف\n",
      "اعفا\n",
      "اعلاق\n",
      "اعلام\n",
      "اعمار\n",
      "اعمار\n",
      "اعماق\n",
      "اعمال\n",
      "اعمال\n",
      "اعمام\n",
      "اعناب\n",
      "اعناق\n",
      "اعواد\n",
      "اعوان\n",
      "اعیاد\n",
      "اعین\n",
      "اغارید\n",
      "اغالیط\n",
      "اغانی\n",
      "اغبیا\n",
      "اغذیه\n",
      "اغراس\n",
      "اغراض\n",
      "اغشیه\n",
      "اغصان\n",
      "اغطیه\n",
      "اغلاط\n",
      "اغلال\n",
      "اغلمه\n",
      "اغمار\n",
      "اغنیا\n",
      "اغوار\n",
      "اغوال\n",
      "افاعی\n",
      "افاعیل\n",
      "افاغنه\n",
      "افانین\n",
      "افاویه\n",
      "افراد\n",
      "افراد\n",
      "افعال\n",
      "افعال\n",
      "افکار\n",
      "افلاک\n",
      "افنان\n",
      "افواج\n",
      "افواه\n",
      "افیال\n",
      "اقاریر\n",
      "اقاصیص\n",
      "اقالیم\n",
      "اقانیم\n",
      "اقاویل\n",
      "اقحاف\n",
      "اقداح\n",
      "اقدار\n",
      "اقدار\n",
      "اقدام\n",
      "اقدام\n",
      "اقراص\n",
      "اقران\n",
      "اقرباء\n",
      "اقساط\n",
      "اقسام\n",
      "اقشار\n",
      "اقطاب\n",
      "اقطار\n",
      "اقلام\n",
      "اقمار\n",
      "اقمشه\n",
      "اقوات\n",
      "اقواس\n",
      "اقوال\n",
      "اقوام\n",
      "اقیال\n",
      "اکادشه\n",
      "اکارم\n",
      "اکاسر\n",
      "اکاسره\n",
      "اکتاف\n",
      "اکر\n",
      "اکراد\n",
      "اکره\n",
      "اکفا\n",
      "اکمام\n",
      "اکناف\n",
      "اکناف\n",
      "اکواب\n",
      "اکوان\n",
      "اکیاس\n",
      "اکیال\n",
      "الاف\n",
      "الاهیات\n",
      "البا\n",
      "البا\n",
      "الباب\n",
      "البان\n",
      "البسه\n",
      "الحاظ\n",
      "الحاقات\n",
      "الحان\n",
      "السن\n",
      "السنه\n",
      "الطاف\n",
      "الطاف\n",
      "القاب\n",
      "الواث\n",
      "الواح\n",
      "الوار\n",
      "الوار\n",
      "الواط\n",
      "الوان\n",
      "الوف\n",
      "الویه\n",
      "الویه\n",
      "الیاف\n",
      "اما\n",
      "امات\n",
      "اماجد\n",
      "امارات\n",
      "امارات\n",
      "امارد\n",
      "امارده\n",
      "اماکن\n",
      "امانات\n",
      "امتعه\n",
      "امتیازات\n",
      "امثال\n",
      "امثله\n",
      "امداد\n",
      "امداد\n",
      "امراء\n",
      "امراض\n",
      "امزجه\n",
      "امشاج\n",
      "امصار\n",
      "امطار\n",
      "امعاء\n",
      "امکانات\n",
      "امکنه\n",
      "املاح\n",
      "املاک\n",
      "امم\n",
      "امناء\n",
      "اموات\n",
      "امواج\n",
      "اموال\n",
      "امواه\n",
      "امور\n",
      "امهات\n",
      "امهار\n",
      "امیال\n",
      "انابیب\n",
      "انابیب\n",
      "اناث\n",
      "اناجیل\n",
      "اناشید\n",
      "انامل\n",
      "انباء\n",
      "انبیاء\n",
      "انتخاب‌کنندگان\n",
      "انجاد\n",
      "انجاد\n",
      "انجاس\n",
      "انجال\n",
      "انجم\n",
      "انحاء\n",
      "انحصارات\n",
      "انداد\n",
      "اندیه\n",
      "انزال\n",
      "انزال\n",
      "انساب\n",
      "انساج\n",
      "انسال\n",
      "انصار\n",
      "انصبا\n",
      "انطاء\n",
      "انظار\n",
      "انعام\n",
      "انعام\n",
      "انعام\n",
      "انعام\n",
      "انفاس\n",
      "انفال\n",
      "انفس\n",
      "انقاس\n",
      "انقاض\n",
      "انقلابیون\n",
      "انکال\n",
      "انوا\n",
      "انوار\n",
      "انوار\n",
      "انواع\n",
      "انوف\n",
      "انهار\n",
      "انیاب\n",
      "اوا\n",
      "اواخر\n",
      "اواسط\n",
      "اوامر\n",
      "اوان\n",
      "اوانس\n",
      "اوایل\n",
      "اوتار\n",
      "اوثان\n",
      "اوجاع\n",
      "اوجال\n",
      "اوحال\n",
      "اودا\n",
      "اوداج\n",
      "اودیه\n",
      "اوراد\n",
      "اوراق\n",
      "اورام\n",
      "اورده\n",
      "اوزار\n",
      "اوزان\n",
      "اوساخ\n",
      "اوساط\n",
      "اوصاب\n",
      "اوصاف\n",
      "اوصال\n",
      "اوصیا\n",
      "اوضاح\n",
      "اوضاع\n",
      "اوطار\n",
      "اوطان\n",
      "اوغاد\n",
      "اوقات\n",
      "اوقاف\n",
      "اولاد\n",
      "اولیاء\n",
      "اولیات\n",
      "اوهام\n",
      "اهاجی\n",
      "اهالی\n",
      "اهتار\n",
      "اهداب\n",
      "اهداف\n",
      "اهرام\n",
      "اهله\n",
      "اهوا\n",
      "اهوال\n",
      "ایالات\n",
      "ایام\n",
      "ایامی\n",
      "ایاوین\n",
      "ایتام\n",
      "ایدی\n",
      "ایرادات\n",
      "ایلات\n",
      "ایلیات\n",
      "ایمان\n",
      "ایمان\n",
      "بارد\n",
      "بازماندگان\n",
      "باغات\n",
      "باقی\n",
      "باقیات\n",
      "بثور\n",
      "بثورات\n",
      "بجر\n",
      "بحور\n",
      "بخار\n",
      "بخلا\n",
      "بدایع\n",
      "بدائع\n",
      "بدلا\n",
      "بدود\n",
      "بدور\n",
      "بدیهیات\n",
      "بذور\n",
      "براثن\n",
      "براجم\n",
      "براذین\n",
      "برازخ\n",
      "براطیل\n",
      "براقع\n",
      "براهمه\n",
      "براهین\n",
      "برایا\n",
      "بردگان\n",
      "برکات\n",
      "بروج\n",
      "بروق\n",
      "بساتین\n",
      "بسایط\n",
      "بشایر\n",
      "بصرا\n",
      "بطارقه\n",
      "بطاین\n",
      "بطون\n",
      "بعوث\n",
      "بعول\n",
      "بغات\n",
      "بغال\n",
      "بقاع\n",
      "بقایا\n",
      "بقعه\n",
      "بلاد\n",
      "بلایا\n",
      "بلدان\n",
      "بلغاء\n",
      "بلها\n",
      "بلیات\n",
      "بنات\n",
      "بنادر\n",
      "بنادق\n",
      "بندگان\n",
      "بنکامات\n",
      "بنون\n",
      "بنی\n",
      "بوارد\n",
      "بوارق\n",
      "بواطن\n",
      "بهایم\n",
      "بهایم\n",
      "بیانات\n",
      "بیگانگان\n",
      "بیوت\n",
      "بیوتات\n",
      "پاکات\n",
      "پروانجات\n",
      "پلکان\n",
      "پیکران\n",
      "تابع\n",
      "تباشیر\n",
      "تجار\n",
      "تجارب\n",
      "تجافیف\n",
      "تجاویف\n",
      "تجربیات\n",
      "تجلیات\n",
      "تحاسین\n",
      "تحاویل\n",
      "تحایا\n",
      "تحریکات\n",
      "تحف\n",
      "تحقیقات\n",
      "تحیات\n",
      "تخاریب\n",
      "تخالیت\n",
      "تخوم\n",
      "تدابیر\n",
      "تدارکات\n",
      "تذاکر\n",
      "تراجم\n",
      "تراکمه\n",
      "ترسیمات\n",
      "ترشحات\n",
      "ترشیجات\n",
      "ترقیات\n",
      "ترکیبات\n",
      "تزاویق\n",
      "تساییر\n",
      "تسبیحات\n",
      "تسعیرنامجات\n",
      "تسهیلات\n",
      "تشبیهات\n",
      "تصاریف\n",
      "تصانیف\n",
      "تصاویر\n",
      "تصورات\n",
      "تضاریس\n",
      "تعابیر\n",
      "تعارفات\n",
      "تعاریج\n",
      "تعاریف\n",
      "تعالیق\n",
      "تعالیم\n",
      "تعاویذ\n",
      "تعقیبات\n",
      "تعلیمات\n",
      "تعیینات\n",
      "تغاییر\n",
      "تفاریق\n",
      "تفاسیر\n",
      "تفاصیل\n",
      "تفرعات\n",
      "تفریحات\n",
      "تقادیر\n",
      "تقاریر\n",
      "تقاسیم\n",
      "تقاصیر\n",
      "تقالیب\n",
      "تقالید\n",
      "تقاویم\n",
      "تقسیمات\n",
      "تکالیف\n",
      "تکایا\n",
      "تکمیلات\n",
      "تلال\n",
      "تلامذه\n",
      "تلامیذ\n",
      "تلفات\n",
      "تماثیل\n",
      "تماسیح\n",
      "تنها\n",
      "توابع\n",
      "توابل\n",
      "توابین\n",
      "تواریخ\n",
      "توجهات\n",
      "تولیدات\n",
      "توهمات\n",
      "تهانی\n",
      "تهم\n",
      "تیوس\n",
      "ثعابین\n",
      "ثعالب\n",
      "ثقات\n",
      "ثقب\n",
      "ثقب\n",
      "ثمار\n",
      "ثمرات\n",
      "ثمره\n",
      "ثوابت\n",
      "ثوانی\n",
      "ثیاب\n",
      "جان\n",
      "جبال\n",
      "جبریون\n",
      "جبهات\n",
      "جداول\n",
      "جدر\n",
      "جدر\n",
      "جذور\n",
      "جراثیم\n",
      "جرایح\n",
      "جراید\n",
      "جرایم\n",
      "جروم\n",
      "جریانات\n",
      "جزایر\n",
      "جزوات\n",
      "جسور\n",
      "جلساء\n",
      "جلساء\n",
      "جماجم\n",
      "جمال\n",
      "جمال\n",
      "جمال\n",
      "جماله\n",
      "جماهیر\n",
      "جمل\n",
      "جمل\n",
      "جمل\n",
      "جملات\n",
      "جنات\n",
      "جنان\n",
      "جنایز\n",
      "جنود\n",
      "جواذب\n",
      "جوارح\n",
      "جواری\n",
      "جواسیس\n",
      "جوامع\n",
      "جوانان\n",
      "جوانب\n",
      "جواهر\n",
      "جواهرات\n",
      "جوایز\n",
      "جهات\n",
      "جهال\n",
      "جهلاء\n",
      "جیران\n",
      "جیران\n",
      "جیوب\n",
      "جیود\n",
      "جیوش\n",
      "چراکسه\n",
      "حادثات\n",
      "حاضرین\n",
      "حالات\n",
      "حبات\n",
      "حبال\n",
      "حبال\n",
      "حبائل\n",
      "حبسیات\n",
      "حبوب\n",
      "حبوس\n",
      "حتوم\n",
      "حجاب\n",
      "حجاب\n",
      "حجاج\n",
      "حجار\n",
      "حجار\n",
      "حجج\n",
      "حجج‌الاسلام\n",
      "حجرات\n",
      "حجیج\n",
      "حدود\n",
      "حراث\n",
      "حراس\n",
      "حرف\n",
      "حرف\n",
      "حرفاء\n",
      "حرکات\n",
      "حروف\n",
      "حروفات\n",
      "حساد\n",
      "حسنات\n",
      "حشرات\n",
      "حصص\n",
      "حصون\n",
      "حضرات\n",
      "حظوظ\n",
      "حفاظ\n",
      "حفاظ\n",
      "حفر\n",
      "حفر\n",
      "حقایق\n",
      "حقن\n",
      "حقن\n",
      "حقوق\n",
      "حقوقات\n",
      "حکام\n",
      "حکم\n",
      "حکم\n",
      "حکم\n",
      "حلفاء\n",
      "حلل\n",
      "حملات\n",
      "حنفاء\n",
      "حواج\n",
      "حواجب\n",
      "حواحز\n",
      "حوادث\n",
      "حواس\n",
      "حواشی\n",
      "حور\n",
      "حیات\n",
      "حیل\n",
      "خاطرات\n",
      "خالصجات\n",
      "خاله\n",
      "خبایا\n",
      "خبایث\n",
      "خبرگان\n",
      "خدام\n",
      "خدایع\n",
      "خدم\n",
      "خدمات\n",
      "خدمت\n",
      "خدمت‌کاران\n",
      "خدمه\n",
      "خدود\n",
      "خدور\n",
      "خراید\n",
      "خزان\n",
      "خزان\n",
      "خزائن\n",
      "خصال\n",
      "خصام\n",
      "خصایص\n",
      "خصماء\n",
      "خصوصیات\n",
      "خصوم\n",
      "خطاب\n",
      "خطاب\n",
      "خطاب\n",
      "خطایا\n",
      "خطباء\n",
      "خطط\n",
      "خطوات\n",
      "خطوط\n",
      "خلال\n",
      "خلال\n",
      "خلال\n",
      "خلایق\n",
      "خلع\n",
      "خلع\n",
      "خلع\n",
      "خلفاء\n",
      "خنادق\n",
      "خنازیر\n",
      "خواتم\n",
      "خواتیم\n",
      "خواتین\n",
      "خوارج\n",
      "خواطر\n",
      "خواقین\n",
      "خوانین\n",
      "خیام\n",
      "خیوط\n",
      "خیول\n",
      "\n",
      "دانشگاهی\n",
      "دراویش\n",
      "دراهم\n",
      "درجات\n",
      "درر\n",
      "درق\n",
      "دروس\n",
      "دزدان\n",
      "دساتیر\n",
      "دساکر\n",
      "دسایس\n",
      "دعات\n",
      "دعاوی\n",
      "دفاتر\n",
      "دفعات\n",
      "دقایق\n",
      "دلالات\n",
      "دلایل\n",
      "دماء\n",
      "دماء\n",
      "دواب\n",
      "دواب\n",
      "دواجات\n",
      "دواعی\n",
      "دواوین\n",
      "دواهی\n",
      "دول\n",
      "دول\n",
      "دول\n",
      "دوندگان\n",
      "دهاقین\n",
      "دهالیز\n",
      "دهریون\n",
      "دهگان\n",
      "دهگان\n",
      "دهنیات\n",
      "دهور\n",
      "دیار\n",
      "دیار\n",
      "دیانات\n",
      "دیدگان\n",
      "دیور\n",
      "دیون\n",
      "دیون\n",
      "ذرات\n",
      "ذراری\n",
      "ذراریح\n",
      "ذرایع\n",
      "ذریات\n",
      "ذکور\n",
      "ذمائم\n",
      "ذموم\n",
      "ذنوب\n",
      "ذوات‌الاذناب\n",
      "ذیول\n",
      "ذئاب\n",
      "راکبین\n",
      "رایات\n",
      "ربایب\n",
      "ربوب\n",
      "رتب\n",
      "رجال\n",
      "رحال\n",
      "رحال\n",
      "رخوت\n",
      "رذایل\n",
      "رذول\n",
      "رسا\n",
      "رسائل\n",
      "رسل\n",
      "رسوم\n",
      "رسومات\n",
      "رشحات\n",
      "رعایا\n",
      "رغائب\n",
      "رفاف\n",
      "رفقا\n",
      "رفوف\n",
      "رقاع\n",
      "رقاع\n",
      "رقباء\n",
      "رقوم\n",
      "رکعات\n",
      "رماح\n",
      "رمال\n",
      "رمال\n",
      "رنود\n",
      "روابط\n",
      "روات\n",
      "رواتب\n",
      "رواحل\n",
      "روافض\n",
      "روایا\n",
      "روایات\n",
      "روایح\n",
      "روحانیون\n",
      "روحیات\n",
      "روزنامجات\n",
      "روضات\n",
      "رهان\n",
      "رؤساء\n",
      "ریاح\n",
      "ریاحین\n",
      "ریاض\n",
      "رئوس\n",
      "زارعین\n",
      "زایرین\n",
      "زحمات\n",
      "زخارف\n",
      "زعماء\n",
      "زکوات\n",
      "زلازل\n",
      "زمان\n",
      "زمر\n",
      "زندگان\n",
      "زوار\n",
      "زوار\n",
      "زوایا\n",
      "زواید\n",
      "زوجات\n",
      "زهاد\n",
      "زهور\n",
      "زیارات\n",
      "ساعات\n",
      "سال\n",
      "سبال\n",
      "سبایا\n",
      "سبایک\n",
      "سبائک\n",
      "سبحات\n",
      "سبل\n",
      "سبل\n",
      "ستم‌دیدگان\n",
      "ستور\n",
      "ستور\n",
      "سجال\n",
      "سجایا\n",
      "سجدات\n",
      "سجلات\n",
      "سجوف\n",
      "سحره\n",
      "سدنه\n",
      "سدود\n",
      "سرا\n",
      "سراری\n",
      "سران\n",
      "سراویل\n",
      "سرایا\n",
      "سرایر\n",
      "سرحدات\n",
      "سرقات\n",
      "سرناها\n",
      "سریات\n",
      "سطوات\n",
      "سطوح\n",
      "سطور\n",
      "سعات\n",
      "سعدا\n",
      "سعود\n",
      "سفاین\n",
      "سفائن\n",
      "سفته‌جات\n",
      "سفراء\n",
      "سفره\n",
      "سفلاء\n",
      "سفلگان\n",
      "سفلیات\n",
      "سفن\n",
      "سفن\n",
      "سفهاء\n",
      "سقات\n",
      "سقالبه\n",
      "سقالبه\n",
      "سقام\n",
      "سقوف\n",
      "سکنات\n",
      "سکنه\n",
      "سلاجقه\n",
      "سلاسل\n",
      "سلاطین\n",
      "سلایق\n",
      "سلائق\n",
      "سلق\n",
      "سلق\n",
      "سمات\n",
      "سماک\n",
      "سماک\n",
      "سماک\n",
      "سماک\n",
      "سماوات\n",
      "سمایم\n",
      "سمائم\n",
      "سموات\n",
      "سموت\n",
      "سموم\n",
      "سموم\n",
      "سمومات\n",
      "سنابک\n",
      "سنابل\n",
      "سناجق\n",
      "سنن\n",
      "سنن\n",
      "سنوات\n",
      "سنون\n",
      "سنون\n",
      "سنه\n",
      "سنین\n",
      "سوابق\n",
      "سواتر\n",
      "سواحل\n",
      "سواقی\n",
      "سوالب\n",
      "سوالف\n",
      "سوام\n",
      "سوانح\n",
      "سوانح\n",
      "سوایم\n",
      "سوائم\n",
      "سور\n",
      "سور\n",
      "سور\n",
      "سور\n",
      "سورات\n",
      "سهام\n",
      "سهام\n",
      "سهل\n",
      "سهوب\n",
      "سهول\n",
      "سهویات\n",
      "سی\n",
      "سیادات\n",
      "سیارات\n",
      "سیاط\n",
      "سیدات\n",
      "سیر\n",
      "سیر\n",
      "سیر\n",
      "سیوف\n",
      "شایعات\n",
      "شخصیات\n",
      "شرار\n",
      "شرایط\n",
      "شرایع\n",
      "شرایین\n",
      "شرر\n",
      "شرف\n",
      "شرف\n",
      "شرفاء\n",
      "شرکاء\n",
      "شروط\n",
      "شعب\n",
      "شعب\n",
      "شعبات\n",
      "شعراء\n",
      "شفاه\n",
      "شقایق\n",
      "شقوق\n",
      "شکاکیون\n",
      "شمائم\n",
      "شناگران\n",
      "شنایع\n",
      "شوارب\n",
      "شوارع\n",
      "شواهد\n",
      "شوائب\n",
      "شوایب\n",
      "شهب\n",
      "شهداء\n",
      "شهوات\n",
      "شهود\n",
      "شهور\n",
      "شؤون\n",
      "شیاطین\n",
      "شیخ\n",
      "شیرینیجات\n",
      "شیوخ\n",
      "شئونات\n",
      "صبایا\n",
      "صحابه\n",
      "صحاری\n",
      "صحایف\n",
      "صحف\n",
      "صراصر\n",
      "صرر\n",
      "صغایر\n",
      "صفات\n",
      "صفوف\n",
      "صلات\n",
      "صلات\n",
      "صلحاء\n",
      "صلوات\n",
      "صم\n",
      "صنادید\n",
      "صناع\n",
      "صنوف\n",
      "صواعق\n",
      "صوامع\n",
      "صور\n",
      "صور\n",
      "صیغ\n",
      "ضایعات\n",
      "ضباط\n",
      "ضباط\n",
      "ضحایاء\n",
      "ضرایب\n",
      "ضرایح\n",
      "ضربات\n",
      "ضروب\n",
      "ضروس\n",
      "ضعفاء\n",
      "ضفادع\n",
      "ضمایر\n",
      "ضمایم\n",
      "ضوابط\n",
      "ضیاع\n",
      "ضیاع\n",
      "ضیوف\n",
      "طاعات\n",
      "طالمات\n",
      "طباع\n",
      "طبایع\n",
      "طرایف\n",
      "طرایق\n",
      "طرائف\n",
      "طرائق\n",
      "طرر\n",
      "طرف\n",
      "طرف\n",
      "طرف\n",
      "طرق\n",
      "طعم\n",
      "طعم\n",
      "طغات\n",
      "طلاب\n",
      "طلاسم\n",
      "طلال\n",
      "طلایی\n",
      "طلل\n",
      "طلل\n",
      "طلول\n",
      "طواحن\n",
      "طواحین\n",
      "طواغی\n",
      "طواغیت\n",
      "طوامیر\n",
      "طوایر\n",
      "طوایل\n",
      "طوائر\n",
      "طوائل\n",
      "طیبات\n",
      "طیور\n",
      "ظرایف\n",
      "ظرفاء\n",
      "ظروف\n",
      "ظلال\n",
      "ظلام\n",
      "ظلام\n",
      "ظلامات\n",
      "ظلمات\n",
      "ظلمه\n",
      "ظنون\n",
      "ظواهر\n",
      "ظهراء\n",
      "ظهور\n",
      "ظهور\n",
      "عادات\n",
      "عاشق\n",
      "عاطفات\n",
      "عایدات\n",
      "عباد\n",
      "عباد\n",
      "عبارات\n",
      "عبده\n",
      "عبر\n",
      "عبید\n",
      "عبید\n",
      "عتبات\n",
      "عجایب\n",
      "عجائب\n",
      "عجزه\n",
      "عداد\n",
      "عرایض\n",
      "عرایک\n",
      "عرائض\n",
      "عرائک\n",
      "عرصات\n",
      "عرفاء\n",
      "عروق\n",
      "عریضجات\n",
      "عزاب\n",
      "عساکر\n",
      "عشاق\n",
      "عشایر\n",
      "عشائر\n",
      "عشرات\n",
      "عشقیات\n",
      "عصاة\n",
      "عصات\n",
      "عصافیر\n",
      "عصور\n",
      "عضلات\n",
      "عطایاء\n",
      "عظام\n",
      "عقارب\n",
      "عقاید\n",
      "عقائد\n",
      "عقد\n",
      "عقد\n",
      "عقد\n",
      "عقلاء\n",
      "عقود\n",
      "عقود\n",
      "عقول\n",
      "علامات\n",
      "علایق\n",
      "علایم\n",
      "علائق\n",
      "علائم\n",
      "علل\n",
      "علماء\n",
      "علوم\n",
      "عمال\n",
      "عمایم\n",
      "عمائم\n",
      "عملجات\n",
      "عمله\n",
      "عناصر\n",
      "عناکب\n",
      "عناوین\n",
      "عوارض\n",
      "عواطف\n",
      "عواقب\n",
      "عوالم\n",
      "عوالمات\n",
      "عوام\n",
      "عوامل\n",
      "عواید\n",
      "عوایق\n",
      "عوائد\n",
      "عوائق\n",
      "عیوب\n",
      "عیوبات\n",
      "عیون\n",
      "غاب\n",
      "غاب\n",
      "غارات\n",
      "غائبین\n",
      "غرامات\n",
      "غرایب\n",
      "غرایز\n",
      "غرائب\n",
      "غرائز\n",
      "غربیون\n",
      "غرف\n",
      "غرفات\n",
      "غرماء\n",
      "غریب\n",
      "غزات\n",
      "غزلیات\n",
      "غزوات\n",
      "غضاریف\n",
      "غلات\n",
      "غلان\n",
      "غلمان\n",
      "غنایم\n",
      "غواشی\n",
      "غوامض\n",
      "غوایل\n",
      "غوائل\n",
      "غوکان\n",
      "غیوب\n",
      "فارسیان\n",
      "فتاوی\n",
      "فتن\n",
      "فتوح\n",
      "فتیان\n",
      "فجایع\n",
      "فحول\n",
      "فراعنه\n",
      "فرامین\n",
      "فراید\n",
      "فرایض\n",
      "فرج\n",
      "فرج\n",
      "فرج\n",
      "فرستادگان\n",
      "فرضیات\n",
      "فرق\n",
      "فرق\n",
      "فروج\n",
      "فروشندگان\n",
      "فروع\n",
      "فروعات\n",
      "فصحاء\n",
      "فصول\n",
      "فضایح\n",
      "فضلاء\n",
      "فضلات\n",
      "فقراء\n",
      "فقرات\n",
      "فقهاء\n",
      "فلاسفه\n",
      "فلکیون\n",
      "فلوس\n",
      "فلوس\n",
      "فنون\n",
      "فواجع\n",
      "فواحش\n",
      "فوارس\n",
      "فواصل\n",
      "فواکه\n",
      "فواید\n",
      "فهارس\n",
      "فیوض\n",
      "قابضات\n",
      "قار\n",
      "قبالجات\n",
      "قبایل\n",
      "قبور\n",
      "قبوض\n",
      "قتال\n",
      "قتال\n",
      "قرا\n",
      "قراء\n",
      "قراطیس\n",
      "قرایح\n",
      "قراین\n",
      "قرود\n",
      "قروض\n",
      "قرون\n",
      "قری\n",
      "قسوس\n",
      "قشور\n",
      "قصاید\n",
      "قصبات\n",
      "قصص\n",
      "قصور\n",
      "قضایاء\n",
      "قطاع\n",
      "قطاع\n",
      "قطاع‌الطریق\n",
      "قطرات\n",
      "قطع\n",
      "قطع\n",
      "قطعات\n",
      "قلاع\n",
      "قلاع\n",
      "قلاید\n",
      "قلل\n",
      "قلوب\n",
      "قنادیل\n",
      "قناطر\n",
      "قناطیر\n",
      "قنوات\n",
      "قوا\n",
      "قوافل\n",
      "قوافی\n",
      "قوانین\n",
      "قیم\n",
      "قیم\n",
      "قیود\n",
      "کارخانجات\n",
      "کارندگان\n",
      "کبار\n",
      "کبائر\n",
      "کبراء\n",
      "کتاب\n",
      "کتاب\n",
      "کتائب\n",
      "کتب\n",
      "کتب\n",
      "کثافات\n",
      "کرات\n",
      "کرات\n",
      "کرات\n",
      "کرادیس\n",
      "کرامات\n",
      "کروبیون\n",
      "کسان\n",
      "کسبه\n",
      "کسور\n",
      "کشتگان\n",
      "کشفیات\n",
      "کشندگان\n",
      "کعاب\n",
      "کعوب\n",
      "کفار\n",
      "کفره\n",
      "کلاب\n",
      "کلبیون\n",
      "کلمات\n",
      "کلمات\n",
      "کلوخ\n",
      "کلوخ‌اندازان\n",
      "کنایات\n",
      "کنوز\n",
      "کواعب\n",
      "کواکب\n",
      "کور\n",
      "کور\n",
      "کور\n",
      "کور\n",
      "کهان\n",
      "کهنه\n",
      "کهنه\n",
      "کهوف\n",
      "کیان\n",
      "کیان\n",
      "کیان\n",
      "کیفیات\n",
      "گردانندگان\n",
      "گمرکات\n",
      "گم‌شدگان\n",
      "گیرندگان\n",
      "گیسوان\n",
      "لاادرییون\n",
      "لثات\n",
      "لحوم\n",
      "لذات\n",
      "لطمات\n",
      "لعب\n",
      "لعب\n",
      "لغات\n",
      "لغویون\n",
      "لفائف\n",
      "لمعات\n",
      "لواحق\n",
      "لوازم\n",
      "لوایح\n",
      "لیالی\n",
      "لئام\n",
      "ماديان\n",
      "ماديان\n",
      "ماديون\n",
      "ماکيانها\n",
      "مانویون\n",
      "مآت\n",
      "مآخذ\n",
      "مآرب\n",
      "مباحث\n",
      "مباحثات\n",
      "مبادلات\n",
      "مبادی\n",
      "مبادی\n",
      "مبارزات\n",
      "مبالغ\n",
      "مبانی\n",
      "مباینات\n",
      "مبلغین\n",
      "مبهمات\n",
      "متشابهات\n",
      "متعلقات\n",
      "متوفیات\n",
      "متون\n",
      "مجاری\n",
      "مجازات\n",
      "مجازات\n",
      "مجالس\n",
      "مجامر\n",
      "مجامع\n",
      "مجانین\n",
      "مجسمات\n",
      "مجسمه\n",
      "مجلات\n",
      "مجلسیان\n",
      "محاربات\n",
      "محارم\n",
      "محاسبات\n",
      "محاسن\n",
      "محاضر\n",
      "محافل\n",
      "محاکم\n",
      "محاکمات\n",
      "محال\n",
      "محامد\n",
      "محامل\n",
      "محاورات\n",
      "محتویات\n",
      "محصولات\n",
      "محلات\n",
      "محلات\n",
      "محمولات\n",
      "محن\n",
      "مخابرات\n",
      "مخادیم\n",
      "مخارج\n",
      "مخارج\n",
      "مخازن\n",
      "مخاطرات\n",
      "مخترعات\n",
      "مخدرات\n",
      "مخدرات\n",
      "مخزن\n",
      "مخلوقات\n",
      "مخیلات\n",
      "مداخل\n",
      "مداخلات\n",
      "مدارج\n",
      "مدارس\n",
      "مدارک\n",
      "مدایح\n",
      "مداین\n",
      "مدن\n",
      "مذابح\n",
      "مذاکرات\n",
      "مذاهب\n",
      "مرابطات\n",
      "مرات\n",
      "مراتب\n",
      "مراتع\n",
      "مراثی\n",
      "مراجع\n",
      "مراجعات\n",
      "مراحل\n",
      "مراحم\n",
      "مراسلات\n",
      "مراصد\n",
      "مرافقات\n",
      "مراقبات\n",
      "مراقد\n",
      "مراکب\n",
      "مراکز\n",
      "مراودات\n",
      "مراهم\n",
      "مرایا\n",
      "مرتفعات\n",
      "مرحمت\n",
      "مرسولات\n",
      "مرضا\n",
      "مرضی\n",
      "مرضی\n",
      "مرقومات\n",
      "مروج\n",
      "مروج\n",
      "مزارع\n",
      "مزارع\n",
      "مزامیر\n",
      "مزایا\n",
      "مزایدات\n",
      "مژگان\n",
      "مژگان\n",
      "مساجد\n",
      "مسافات\n",
      "مساکن\n",
      "مساکین\n",
      "مسامع\n",
      "مسامیر\n",
      "مساند\n",
      "مسائل\n",
      "مستحاثات\n",
      "مستدعیات\n",
      "مستعمرات\n",
      "مستملکات\n",
      "مسطحات\n",
      "مسطورجات\n",
      "مسودات\n",
      "مسیحی\n",
      "مسیحیون\n",
      "مسئولین\n",
      "مشاعر\n",
      "مشاعل\n",
      "مشاغل\n",
      "مشاق\n",
      "مشاق\n",
      "مشاورات\n",
      "مشاهدات\n",
      "مشاهده\n",
      "مشایعین\n",
      "مشتقات\n",
      "مشعر\n",
      "مشقات\n",
      "مصابیح\n",
      "مصاحف\n",
      "مصادر\n",
      "مصارف\n",
      "مصاریع\n",
      "مصالح\n",
      "مصالح\n",
      "مصحف\n",
      "مصنوعات\n",
      "مصوبات\n",
      "مضاجع\n",
      "مضار\n",
      "مضارب\n",
      "مضارب\n",
      "مضامین\n",
      "مضرات\n",
      "مطابخ\n",
      "مطابع\n",
      "مطارق\n",
      "مطالب\n",
      "مطالب\n",
      "مطالبات\n",
      "مطالع\n",
      "مطالعات\n",
      "مطامح\n",
      "مطامع\n",
      "مطایبات\n",
      "مظالم\n",
      "مظاهر\n",
      "مظنه\n",
      "معابد\n",
      "معابر\n",
      "معاجین\n",
      "معادن\n",
      "معاذیر\n",
      "معارضات\n",
      "معارف\n",
      "معارک\n",
      "معاریف\n",
      "معاصی\n",
      "معالم\n",
      "معاملات\n",
      "معانی\n",
      "معاییر\n",
      "معتمدین\n",
      "معصومین\n",
      "معلقات\n",
      "مغارات\n",
      "مغاربه\n",
      "مغان\n",
      "مغاور\n",
      "مفاتیح\n",
      "مفاخر\n",
      "مفارش\n",
      "مفارق\n",
      "مفاسد\n",
      "مفاصل\n",
      "مفاهیم\n",
      "مقابر\n",
      "مقاتل\n",
      "مقاتل\n",
      "مقادیر\n",
      "مقاربات\n",
      "مقاصد\n",
      "مقاطع\n",
      "مقاعد\n",
      "مقالات\n",
      "مقامات\n",
      "مقاومات\n",
      "مقایسات\n",
      "مقتضیات\n",
      "مقنطرات\n",
      "مقولات\n",
      "مکاتب\n",
      "مکاتب\n",
      "مکاتبات\n",
      "مکاتیب\n",
      "مکارم\n",
      "مکاسب\n",
      "مکاشفات\n",
      "مکالمات\n",
      "مکامن\n",
      "مکانات\n",
      "مکائل\n",
      "مکنونات\n",
      "مکیفات\n",
      "ملا\n",
      "ملاحده\n",
      "ملاحظات\n",
      "ملاحم\n",
      "ملازمات\n",
      "ملاعب\n",
      "ملاعین\n",
      "ملتزمین\n",
      "ملحمه\n",
      "ملفوفات\n",
      "ملکات\n",
      "ملل\n",
      "ملوک\n",
      "ممالک\n",
      "ممامیک\n",
      "منابر\n",
      "منابع\n",
      "مناجیق\n",
      "منادیل\n",
      "منازعات\n",
      "منازل\n",
      "مناسبات\n",
      "مناسک\n",
      "مناصب\n",
      "مناطق\n",
      "مناظر\n",
      "مناظر\n",
      "مناظرات\n",
      "مناظره\n",
      "منافذ\n",
      "منافع\n",
      "مناقب\n",
      "مناقشات\n",
      "مناهج\n",
      "مناهی\n",
      "مناهیج\n",
      "منایا\n",
      "منسوجات\n",
      "منظومات\n",
      "منهیات\n",
      "منی\n",
      "منی\n",
      "مواثیق\n",
      "مواد\n",
      "موارد\n",
      "مواریث\n",
      "موازین\n",
      "مواسم\n",
      "مواصلات\n",
      "مواضع\n",
      "مواطن\n",
      "مواعد\n",
      "مواقع\n",
      "مواقع\n",
      "مواقف\n",
      "مواکب\n",
      "موالی\n",
      "موالید\n",
      "موانع\n",
      "مواهب\n",
      "موتا\n",
      "موتی\n",
      "موجبات\n",
      "موجودات\n",
      "موفقیات\n",
      "موقوفات\n",
      "مهالک\n",
      "مهره‌داران\n",
      "مهمات\n",
      "مؤخرات\n",
      "مؤسسات\n",
      "میادین\n",
      "میامین\n",
      "میاه\n",
      "میثاق\n",
      "میوجات\n",
      "مئات\n",
      "نادرات\n",
      "نایبات\n",
      "نای‌ها\n",
      "نبلاء\n",
      "نبهاء\n",
      "نتایج\n",
      "نجایب\n",
      "نجوم\n",
      "نحل\n",
      "نحل\n",
      "نحور\n",
      "نحوس\n",
      "نخاریب\n",
      "ندام\n",
      "نذور\n",
      "نرگان\n",
      "نزلاء\n",
      "نزلات\n",
      "نساخ\n",
      "نساخ\n",
      "نساطره\n",
      "نساک\n",
      "نسایج\n",
      "نسخ\n",
      "نسخ\n",
      "نسوج\n",
      "نسور\n",
      "نشریات\n",
      "نصاح\n",
      "نصارا\n",
      "نصایح\n",
      "نصحاء\n",
      "نصراء\n",
      "نطق\n",
      "نطق\n",
      "نظار\n",
      "نظریات\n",
      "نعال\n",
      "نعم\n",
      "نعمات\n",
      "نغمات\n",
      "نفوس\n",
      "نقاط\n",
      "نقایص\n",
      "نقایض\n",
      "نقباء\n",
      "نقرات\n",
      "نقط\n",
      "نقله\n",
      "نقود\n",
      "نقوش\n",
      "نقول\n",
      "نکبات\n",
      "نکت\n",
      "نمرات\n",
      "نموس\n",
      "نواب\n",
      "نوابت\n",
      "نوابغ\n",
      "نوادر\n",
      "نوادگان\n",
      "نواسیر\n",
      "نواصب\n",
      "نواصی\n",
      "نوافل\n",
      "نواقص\n",
      "نواقیس\n",
      "نوامی\n",
      "نوامیس\n",
      "نواهی\n",
      "نوائب\n",
      "نوشتجات\n",
      "نهضات\n",
      "نیات\n",
      "نیران\n",
      "وابستگان\n",
      "واقعات\n",
      "واقعیات\n",
      "وجنات\n",
      "وجوه\n",
      "وحوش\n",
      "ودایع\n",
      "وراث\n",
      "ورثه\n",
      "وزراء\n",
      "وساوس\n",
      "وسایل\n",
      "وسائط\n",
      "وصایاء\n",
      "وظایف\n",
      "وعاظ\n",
      "وعود\n",
      "وقایع\n",
      "وکلاء\n",
      "ولاة\n",
      "ولات\n",
      "ولایات\n",
      "هجویات\n",
      "هزاهز\n",
      "همم\n",
      "هموم\n",
      "هنود\n",
      "هواجس\n",
      "هوام\n",
      "هیاکل\n"
     ]
    }
   ],
   "source": [
    "w = open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\noun-forms.txt', \n",
    "         'w', encoding='utf-8')\n",
    "\n",
    "Nouns = set()\n",
    "Plurals = set()\n",
    "\n",
    "\n",
    "def addSuff(sing, suffix):\n",
    "    if sing[-1] == 'ه' and suffix == 'ها':\n",
    "        return True\n",
    "    if sing[-1] == 'ه' and suffix == 'ان':\n",
    "        suffix = '\\u200c' +  'گان'\n",
    "        sing = sing[:-1]\n",
    "    plur = sing + suffix\n",
    "    plur_tagged = plur + '#' + sing + '#N+PL'\n",
    "    if plur_tagged not in Nouns:\n",
    "        Nouns.add(plur_tagged)\n",
    "        w.write(plur_tagged+'\\n') \n",
    "    \n",
    "    sing_tagged = sing + '#' + sing + '#N+SG'\n",
    "    if sing_tagged not in Nouns:\n",
    "        Nouns.add(sing_tagged)\n",
    "        w.write(sing_tagged+'\\n')\n",
    "         \n",
    "\n",
    "\n",
    "with open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\noun-plural.txt', \n",
    "          'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        sing, plur = line.strip('\\n').split('#')\n",
    "        \n",
    "        if plur not in Plurals:\n",
    "            Plurals.add(plur)\n",
    "        sing_tagged = sing + '#' + sing + '#N+SG'\n",
    "        if sing_tagged not in Nouns:\n",
    "            Nouns.add(sing_tagged)\n",
    "            w.write(sing_tagged+'\\n')\n",
    "        plur_tagged = plur + '#' + sing + '#N+PL'\n",
    "        if plur_tagged not in Nouns:\n",
    "            Nouns.add(plur_tagged)\n",
    "            w.write(plur_tagged+'\\n')\n",
    "\n",
    "with open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\word-N.txt', \n",
    "          'r', encoding='utf-8') as f:    \n",
    "    for line in f:\n",
    "        sing = line.strip('\\n')\n",
    "        if sing in Plurals:\n",
    "            print(sing)\n",
    "            continue\n",
    "            \n",
    "        suf = '\\u200c' + 'ها'\n",
    "        suffices = ['ها', 'ان', suf]\n",
    "        \n",
    "        for suffix in suffices:\n",
    "            if len(sing)>=1:\n",
    "                addSuff(sing, suffix)\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "w.close()\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get superlative adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#'превосх. ст. от'\n",
    "\n",
    "\n",
    "adj = ''\n",
    "superl = ''\n",
    "state = 0\n",
    "Adjs = {}\n",
    "\n",
    "def getPersian(line):\n",
    "    match = p.search(line)\n",
    "    if match and match.group() != None:\n",
    "        return match.group().rstrip().strip('\\u200c')\n",
    "    else:\n",
    "        print(line)\n",
    "        return None\n",
    "\n",
    "def addAdj(adj, superl):\n",
    "    \n",
    "    adj = adj.strip('\\u200c')\n",
    "    superl = superl.strip('\\u200c')\n",
    "    \n",
    "    if adj in Adjs.keys() and superl not in Adjs[adj]:\n",
    "\n",
    "        Adjs[adj].append(superl)\n",
    "        w.write(str(adj)+'#'+str(superl)+'\\n')\n",
    "    elif adj not in Adjs.keys():\n",
    "        Adjs[adj] = []\n",
    "        Adjs[adj].append(superl)\n",
    "       \n",
    "        w.write(str(adj)+'#'+str(superl)+'\\n')\n",
    "\n",
    "w = open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\adj-superl.txt', 'w', encoding='utf-8')\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\rubinchik.txt\", 'r', encoding='utf-8') as f:\n",
    "\n",
    "    for line in f:\n",
    "        if ad.is_arabic(line.strip()) and state == 0: \n",
    "            state = 1\n",
    "            \n",
    "            superl = line.strip().strip('\\u200c')\n",
    "            #print('state1')\n",
    "        elif len(line) > 2 and line.strip()[0] == '[' and line.strip()[-1] == ']' and state == 1:\n",
    "            state = 2\n",
    "            #print('state2')\n",
    "        elif ad.is_cyrillic(line.strip()) and state == 2 and 'прил' in line:\n",
    "            #print('state3')\n",
    "            state = 3\n",
    "           \n",
    "        elif state == 3 and 'превосх. ст. от' in line:\n",
    "            \n",
    "            if getPersian(line):\n",
    "                adj = getPersian(line) \n",
    "            \n",
    "            \n",
    "            addAdj(adj, superl)\n",
    "            state = 0\n",
    "            adj = ''\n",
    "            superl = ''\n",
    "            \n",
    "        else:\n",
    "            state = 0\n",
    "            #print('state0')\n",
    "            adj = ''\n",
    "            superl = ''     \n",
    "\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate adjective forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\adj-forms.txt', \n",
    "         'w', encoding='utf-8')\n",
    "\n",
    "Adjs = set()\n",
    "Plurals = set()\n",
    "\n",
    "\n",
    "def addSuff(sing, suffix, tag):\n",
    "    if sing[-1] == 'ه':\n",
    "        suffix = '\\u200c' + suffix\n",
    "    form_tagged = sing + suffix +'#' + sing + '#ADJ+'+tag\n",
    "    if form_tagged not in Adjs:\n",
    "        w.write(form_tagged+'\\n')\n",
    "        Adjs.add(form_tagged)\n",
    "    sing_tagged = sing +'#' + sing + '#ADJ+POS'\n",
    "    if sing_tagged not in Adjs:\n",
    "        w.write(sing_tagged+'\\n')\n",
    "        Adjs.add(sing_tagged)\n",
    "\n",
    "         \n",
    "\n",
    "\n",
    "with open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\adj-superl.txt', \n",
    "          'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        adj, superl = line.strip('\\n').split('#')\n",
    "        \n",
    "        #if plur not in Plurals:\n",
    "        #    Plurals.add(plur)\n",
    "        adj_tagged = adj + '#' + adj + '#ADJ+POS'\n",
    "        if adj_tagged not in Adjs:\n",
    "            Adjs.add(adj_tagged)\n",
    "            w.write(adj_tagged+'\\n')\n",
    "        superl_tagged = superl + '#' + adj + '#ADJ+SUPER+AR'\n",
    "        if superl_tagged not in Adjs:\n",
    "            Adjs.add(superl_tagged)\n",
    "            w.write(superl_tagged+'\\n')\n",
    "\n",
    "with open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\word-ADJ.txt', \n",
    "          'r', encoding='utf-8') as f:    \n",
    "    for line in f:\n",
    "        adj = line.strip('\\n')\n",
    "        #if adj in Plurals:\n",
    "        #    print(sing)\n",
    "        #    continue\n",
    "            \n",
    "        comp = 'تر'\n",
    "        sup = 'ترین'\n",
    "        \n",
    "        if len(adj)>=1:\n",
    "            addSuff(adj, comp, 'COMP')\n",
    "            addSuff(adj, sup, 'SUPER')\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "w.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMPLE. Get words from Rubinchik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#states = {(1,'word'), (2,'trans'), (3,'pos')}\n",
    "auto = {}\n",
    "pos = set()\n",
    "#poslist = \n",
    "state = 0\n",
    "word = ['word', 'pos']\n",
    "Vocab = {}\n",
    "\n",
    "with open(\"./rubinchik/rubinchik.txt\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if ad.is_arabic(line.strip()) and state == 0: \n",
    "            state = 1\n",
    "            word[0] = line.strip()\n",
    "            #print(line)\n",
    "        elif line.strip()[0] == '[' and line.strip()[-1] == ']' and state == 1:\n",
    "            state = 2\n",
    "            #print(line)\n",
    "        elif ad.is_cyrillic(line.strip()) and state == 2: \n",
    "            #if line.split('., ')[0].strip(' \\\\n') in poslist:\n",
    "            state = 3\n",
    "            word[1] = line.split('., ')[0].strip(' \\\\n')\n",
    "            pos.add(word[1])\n",
    "            Vocab[word[0]] = word[1]\n",
    "            state = 0   \n",
    "                #print(word[1])\n",
    "        else:\n",
    "            state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pos\n",
    "with open('./rubinchik/rub_wordlist.txt', 'w', encoding='utf-8') as w:\n",
    "    dicSorted = sorted(Vocab.items(), key=lambda tup: tup[0], reverse=False)\n",
    "    for word in dicSorted:\n",
    "        w.write(word[0]+'\\t'+str(word[1])+'\\n')\n",
    "        #i+=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get full words with POS from Rubinchik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-06dd5d1cd550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "#states = {(1,'word'), (2,'trans'), (3,'pos')}\n",
    "auto = {}\n",
    "allPOS = set()\n",
    "#poslist = \n",
    "state = 0\n",
    "word = ''\n",
    "pos = ''\n",
    "WORDS = {}\n",
    "Other = {}\n",
    "\n",
    "POSlist = ('N','ADJ','V','ADV','NUM','PRO','PP','P','CON','PART','PARTC','NOM','INT','MOD','PS','VVOD')\n",
    "\n",
    "w = open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\word-pos.txt', 'w', encoding='utf-8')\n",
    "wn = open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\word-N.txt', 'w', encoding='utf-8')\n",
    "wa = open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\word-ADJ.txt', 'w', encoding='utf-8')\n",
    "wv = open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\word-V.txt', 'w', encoding='utf-8')\n",
    "wr = open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\word-pos-unchange.txt', 'w', encoding='utf-8')\n",
    "\n",
    "\n",
    "def addWord(word, pos):\n",
    "    word = word.strip('\\u200c').strip('\\n')\n",
    "    #pos = pos.strip('\\u200c').strip('\\n')\n",
    "    allPOS.add(pos)\n",
    "    if word in WORDS.keys():# and pos not in Nouns[noun]:    \n",
    "        WORDS[word].append(pos)\n",
    "        w.write(str(word)+'#'+str(pos)+'\\n')\n",
    "    #elif noun not in Nouns.keys():\n",
    "    else:\n",
    "        #Nouns[noun] = []\n",
    "        #Nouns[noun].append(plural)\n",
    "        WORDS[word] = []\n",
    "        WORDS[word].append(pos)\n",
    "        w.write(str(word)+'#'+str(pos)+'\\n')\n",
    "        \n",
    "    if pos == 'N':\n",
    "        wn.write(str(word)+'\\n')\n",
    "    elif pos == 'V':\n",
    "        wv.write(str(word)+'\\n')\n",
    "    elif pos == 'ADJ':\n",
    "        wa.write(str(word)+'\\n')\n",
    "    else:\n",
    "        wr.write(str(word)+'#'+str(pos)+'\\n')\n",
    "\n",
    "with open(\"C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\rubinchik.txt\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if ad.is_arabic(line.strip()) and state == 0: \n",
    "            state = 1\n",
    "            word = line.strip()\n",
    "            #print(line)\n",
    "        elif len(line) > 2 and line.strip()[0] == '[' and line.strip()[-1] == ']' and state == 1:\n",
    "            state = 2\n",
    "            #print(line)\n",
    "        elif ad.is_cyrillic(line.strip()) and state == 2: \n",
    "            \n",
    "            pos = line.split('., ')[0].strip(' \\n').strip('\\n')\n",
    "            \n",
    "            #if line.split('., ')[0].strip(' \\\\n') in poslist:\n",
    "            state = 3\n",
    "            if pos.startswith('сущ'):\n",
    "                pos = 'N'\n",
    "            elif pos.startswith('прил'):\n",
    "                pos = 'ADJ'\n",
    "            elif pos.startswith('гл'):\n",
    "                pos = 'V'\n",
    "            elif pos.startswith('нар'):\n",
    "                pos = 'ADV'\n",
    "            elif pos.startswith('числ'):\n",
    "                pos = 'NUM'\n",
    "            elif pos.startswith('мест'):\n",
    "                pos = 'PRO'\n",
    "            elif pos.startswith('предл. отым.'):\n",
    "                pos = 'PP'\n",
    "            elif pos.startswith('предл'):\n",
    "                pos = 'P'\n",
    "            elif pos.startswith('союз'):\n",
    "                pos = 'CON'  \n",
    "            elif pos.startswith('част'):\n",
    "                pos = 'PART' \n",
    "            elif pos.startswith('прич'):\n",
    "                pos = 'PARTC'\n",
    "            elif pos.startswith('имя'):\n",
    "                pos = 'NOM'\n",
    "            elif pos.startswith('межд'):\n",
    "                pos = 'INT'\n",
    "            elif pos.startswith('мод. сл.'):\n",
    "                pos = 'MOD'\n",
    "            elif pos.startswith('сл.-предл.'):\n",
    "                pos = 'PS'\n",
    "            elif pos.startswith('вводн'):\n",
    "                pos = 'VVOD'\n",
    "            elif 'прил' in line:\n",
    "                pos = 'ADJ'\n",
    "            elif 'гл' in line:\n",
    "                pos = 'V'\n",
    "            elif 'нар' in line:\n",
    "                pos = 'ADV'\n",
    "            elif 'числ' in line:\n",
    "                pos = 'NUM'\n",
    "            elif 'мест' in line:\n",
    "                pos = 'PRO'\n",
    "            elif 'предл. отым.' in line:\n",
    "                pos = 'PP'\n",
    "            elif 'предл' in line:\n",
    "                pos = 'P'\n",
    "            elif 'союз' in line:\n",
    "                pos = 'CON'  \n",
    "            elif 'част' in line:\n",
    "                pos = 'PART' \n",
    "            elif 'прич' in line:\n",
    "                pos = 'PARTC'\n",
    "            elif 'имя' in line:\n",
    "                pos = 'NOM'\n",
    "            elif 'межд' in line:\n",
    "                pos = 'INT'\n",
    "            elif 'мод. сл.' in line:\n",
    "                pos = 'MOD'\n",
    "            elif 'сл.-предл.' in line:\n",
    "                pos = 'PS'\n",
    "            elif 'вводн' in line:\n",
    "                pos = 'VVOD'\n",
    "            else:\n",
    "                Other[word] = line\n",
    "            \n",
    "            \n",
    "            #allPOS.add(pos)\n",
    "            if pos in POSlist:\n",
    "                addWord(word, pos)\n",
    "            state = 0   \n",
    "                #print(word[1])\n",
    "        else:\n",
    "            state = 0\n",
    "            \n",
    "w.close()\n",
    "\n",
    "\n",
    " #'дееприч','предикат.',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ',\n",
       " 'ADV',\n",
       " 'CON',\n",
       " 'INT',\n",
       " 'MOD',\n",
       " 'N',\n",
       " 'NOM',\n",
       " 'NUM',\n",
       " 'P',\n",
       " 'PART',\n",
       " 'PARTC',\n",
       " 'PP',\n",
       " 'PRO',\n",
       " 'PS',\n",
       " 'V',\n",
       " 'VVOD'}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allPOS)\n",
    "allPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52201"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Other)\n",
    "#Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5969"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi = [w for w in WORDS.keys() if len(WORDS[w]) > 1]\n",
    "len(multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write single-pos words and separate words with |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46232"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single = [w for w in WORDS.keys() if len(WORDS[w]) == 1]\n",
    "len(single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check4multi(word):\n",
    "    back = []\n",
    "    if '|' not in word:\n",
    "        return False\n",
    "    else:\n",
    "        s = word\n",
    "        if '\\u200c' in word:\n",
    "            s = word.replace('\\u200c', '$')\n",
    "        words = s.split('|')\n",
    "        \n",
    "        for w in words:\n",
    "            new = w.replace('$', '\\u200c')\n",
    "            back.append(new)\n",
    "        return back\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f = open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\word-pos-single-sep.txt', 'w', encoding='utf-8')\n",
    "for w in single:\n",
    "    if not check4multi(w):\n",
    "        f.write(str(w)+'#')\n",
    "        f.write(WORDS[w][0]+'\\n')\n",
    "    else:\n",
    "        for word in check4multi(w):\n",
    "            f.write(str(word)+'#')\n",
    "            f.write(WORDS[w][0]+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قیم ['N', 'N']\n"
     ]
    }
   ],
   "source": [
    "print(multi[1000], WORDS[multi[1000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write multi-pos words and separate words with |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi = [w for w in WORDS.keys() if len(WORDS[w]) > 1]\n",
    "len(multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check4multi(word):\n",
    "    back = []\n",
    "    if '|' not in word:\n",
    "        return False\n",
    "    else:\n",
    "        s = word\n",
    "        if '\\u200c' in word:\n",
    "            s = word.replace('\\u200c', '$')\n",
    "        words = s.split('|')\n",
    "        \n",
    "        for w in words:\n",
    "            new = w.replace('$', '\\u200c')\n",
    "            back.append(new)\n",
    "        return back\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f = open('C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\word-pos-multi_sep.txt', 'w', encoding='utf-8')\n",
    "for w in multi:\n",
    "    if not check4multi(w):\n",
    "        f.write(str(w)+'#')\n",
    "        for pos in WORDS[w][:-1]:\n",
    "            f.write(pos+'-')\n",
    "        f.write(WORDS[w][-1]+'\\n')\n",
    "    else:\n",
    "        for word in check4multi(w):\n",
    "            f.write(str(word)+'#')\n",
    "            for pos in WORDS[w][:-1]:\n",
    "                f.write(pos+'-')\n",
    "            f.write(WORDS[w][-1]+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ОНВ آزار‌ [āzār]\n",
    "#ОНВ آزما(ی) [āzmā(y)]\n",
    "#гл. ОНВ آژن [āžan]\n",
    "#ОНВ гл. آشکوخ [āškux] и اشکوخ [aškux]\n",
    "#1) ОНВ гл. آفریدن"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "Parent module '' not loaded, cannot perform relative import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bade5fc600f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0municode_literals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefault_verbs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizerI\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: Parent module '' not loaded, cannot perform relative import"
     ]
    }
   ],
   "source": [
    "#from __future__ import unicode_literals\n",
    "#import hazm\n",
    "#normalizer = Normalizer()\n",
    "#normalizer.normalize('اصلاح نويسه ها و استفاده از نیم‌فاصله پردازش را آسان مي كند')\n",
    "\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "import re, codecs\n",
    "from .utils import default_verbs\n",
    "from nltk.tokenize.api import TokenizerI\n",
    "\n",
    "\n",
    "class WordTokenizer(TokenizerI):\n",
    "\t\"\"\"\n",
    "\t>>> tokenizer = WordTokenizer()\n",
    "\t>>> tokenizer.tokenize('این جمله (خیلی) پیچیده نیست!!!')\n",
    "\t['این', 'جمله', '(', 'خیلی', ')', 'پیچیده', 'نیست', '!!!']\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, verbs_file=default_verbs, join_verb_parts=True):\n",
    "\t\tself._join_verb_parts = join_verb_parts\n",
    "\t\tself.pattern = re.compile(r'([؟!\\?]+|[:\\.،؛»\\]\\)\\}\"«\\[\\(\\{])')\n",
    "\n",
    "\t\tif join_verb_parts:\n",
    "\t\t\tself.after_verbs = set([\n",
    "\t\t\t\t'ام', 'ای', 'است', 'ایم', 'اید', 'اند', 'بودم', 'بودی', 'بود', 'بودیم', 'بودید', 'بودند', 'باشم', 'باشی', 'باشد', 'باشیم', 'باشید', 'باشند',\n",
    "\t\t\t\t'شده_ام', 'شده_ای', 'شده_است', 'شده_ایم', 'شده_اید', 'شده_اند', 'شده_بودم', 'شده_بودی', 'شده_بود', 'شده_بودیم', 'شده_بودید', 'شده_بودند', 'شده_باشم', 'شده_باشی', 'شده_باشد', 'شده_باشیم', 'شده_باشید', 'شده_باشند',\n",
    "\t\t\t\t'نشده_ام', 'نشده_ای', 'نشده_است', 'نشده_ایم', 'نشده_اید', 'نشده_اند', 'نشده_بودم', 'نشده_بودی', 'نشده_بود', 'نشده_بودیم', 'نشده_بودید', 'نشده_بودند', 'نشده_باشم', 'نشده_باشی', 'نشده_باشد', 'نشده_باشیم', 'نشده_باشید', 'نشده_باشند',\n",
    "\t\t\t\t'شوم', 'شوی', 'شود', 'شویم', 'شوید', 'شوند', 'شدم', 'شدی', 'شد', 'شدیم', 'شدید', 'شدند',\n",
    "\t\t\t\t'نشوم', 'نشوی', 'نشود', 'نشویم', 'نشوید', 'نشوند', 'نشدم', 'نشدی', 'نشد', 'نشدیم', 'نشدید', 'نشدند',\n",
    "\t\t\t\t'می‌شوم', 'می‌شوی', 'می‌شود', 'می‌شویم', 'می‌شوید', 'می‌شوند', 'می‌شدم', 'می‌شدی', 'می‌شد', 'می‌شدیم', 'می‌شدید', 'می‌شدند',\n",
    "\t\t\t\t'نمی‌شوم', 'نمی‌شوی', 'نمی‌شود', 'نمی‌شویم', 'نمی‌شوید', 'نمی‌شوند', 'نمی‌شدم', 'نمی‌شدی', 'نمی‌شد', 'نمی‌شدیم', 'نمی‌شدید', 'نمی‌شدند',\n",
    "\t\t\t\t'خواهم_شد', 'خواهی_شد', 'خواهد_شد', 'خواهیم_شد', 'خواهید_شد', 'خواهند_شد',\n",
    "\t\t\t\t'نخواهم_شد', 'نخواهی_شد', 'نخواهد_شد', 'نخواهیم_شد', 'نخواهید_شد', 'نخواهند_شد',\n",
    "\t\t\t])\n",
    "\n",
    "\t\t\tself.before_verbs = set([\n",
    "\t\t\t\t'خواهم', 'خواهی', 'خواهد', 'خواهیم', 'خواهید', 'خواهند',\n",
    "\t\t\t\t'نخواهم', 'نخواهی', 'نخواهد', 'نخواهیم', 'نخواهید', 'نخواهند'\n",
    "\t\t\t])\n",
    "\n",
    "\t\t\twith codecs.open(verbs_file, encoding='utf8') as verbs_file:\n",
    "\t\t\t\tself.verbs = list(reversed([verb.strip() for verb in verbs_file if verb]))\n",
    "\t\t\t\tself.bons = set([verb.split('#')[0] for verb in self.verbs])\n",
    "\t\t\t\tself.verbe = set([bon +'ه' for bon in self.bons] + ['ن'+ bon +'ه' for bon in self.bons])\n",
    "\n",
    "\tdef tokenize(self, text):\n",
    "\t\ttext = self.pattern.sub(r' \\1 ', text.replace('\\n', ' ').replace('\\t', ' '))\n",
    "\t\ttokens = [word for word in text.split(' ') if word]\n",
    "\t\tif self._join_verb_parts:\n",
    "\t\t\ttokens = self.join_verb_parts(tokens)\n",
    "\t\treturn tokens\n",
    "\n",
    "\tdef join_verb_parts(self, tokens):\n",
    "\t\t\"\"\"\n",
    "\t\t>>> tokenizer = WordTokenizer()\n",
    "\t\t>>> tokenizer.join_verb_parts(['خواهد', 'رفت'])\n",
    "\t\t['خواهد_رفت']\n",
    "\t\t>>> tokenizer.join_verb_parts(['رفته', 'است'])\n",
    "\t\t['رفته_است']\n",
    "\t\t>>> tokenizer.join_verb_parts(['گفته', 'شده', 'است'])\n",
    "\t\t['گفته_شده_است']\n",
    "\t\t>>> tokenizer.join_verb_parts(['گفته', 'خواهد', 'شد'])\n",
    "\t\t['گفته_خواهد_شد']\n",
    "\t\t>>> tokenizer.join_verb_parts(['خسته', 'شدید'])\n",
    "\t\t['خسته', 'شدید']\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tresult = ['']\n",
    "\t\tfor token in reversed(tokens):\n",
    "\t\t\tif token in self.before_verbs or (result[-1] in self.after_verbs and token in self.verbe):\n",
    "\t\t\t\tresult[-1] = token +'_'+ result[-1]\n",
    "\t\t\telse:\n",
    "\t\t\t\tresult.append(token)\n",
    "\t\treturn list(reversed(result[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = r\"C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\collect\\\\poems\\\\\"\n",
    "punct = {'،', '«', '»', ':', '!', '؟', '؛','...', '.', '(',')'}\n",
    "\n",
    "Lemmas = {}\n",
    "\n",
    "with open(path+'corpus_big.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        words = line.split()\n",
    "        for w in words:\n",
    "            word = w\n",
    "            pre, post = '',''\n",
    "            #haypunct = True\n",
    "            tokens = []\n",
    "\n",
    "            if len(word) and word[0] in punct: \n",
    "                pre = word[0]\n",
    "                word = word[1:]\n",
    "                tokens.append(pre)\n",
    "            if len(word) and word[-1] in punct:\n",
    "                post = word[-1]\n",
    "                word = word[:-1]\n",
    "                tokens.append(post)\n",
    "            #if len(word) and word[0] not in punct and word[-1] not in punct:\n",
    "                #haypunct = False\n",
    "                #tokens.append(word)\n",
    "            tokens.append(word)\n",
    "        \n",
    "            for token in tokens:\n",
    "                if token in Lemmas:\n",
    "                    Lemmas[token] += 1\n",
    "                else:\n",
    "                    Lemmas[token] = 1\n",
    "        \n",
    "        \n",
    "with open(path+'frequency_punct1.txt', 'w', encoding='utf-8') as w:\n",
    "    dicSorted = sorted(Lemmas.items(), key=lambda tup: tup[1], reverse=True)\n",
    "    for word in dicSorted:\n",
    "        w.write(word[0]+'\\t'+str(word[1])+'\\n')\n",
    "        #i+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36894"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52612"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "with open(path+'corpus_big.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        words = line.split()\n",
    "        for w in words:\n",
    "            word = w\n",
    "            pre, post = '',''\n",
    "            haypunct = True\n",
    "            tokens = []\n",
    "            while haypunct:\n",
    "                if len(word) and word[0] in punct: \n",
    "                    pre = word[0]\n",
    "                    word = word[1:]\n",
    "                    tokens.append(pre)\n",
    "                if len(word) and word[-1] in punct:\n",
    "                    post = word[-1]\n",
    "                    word = word[:-1]\n",
    "                    tokens.append(post)\n",
    "                if len(word) and word[0] not in punct and word[-1] not in punct:\n",
    "                    haypunct = False\n",
    "                    tokens.append(word)\n",
    "                    \n",
    "                    for token in tokens:\n",
    "                        if token in Lemmas:\n",
    "                            Lemmas[token] += 1\n",
    "                        else:\n",
    "                            Lemmas[token] = 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path+'frequency_punct_alpha.txt', 'w', encoding='utf-8') as w:\n",
    "    dicSorted = sorted(Lemmas.items(), key=lambda tup: tup[0], reverse=False)\n",
    "    for word in dicSorted:\n",
    "        w.write(word[0]+'\\n')\n",
    "        #i+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Corpus = set()\n",
    "with open('BijanKhan_Distinct_Words.txt','r', encoding='utf-8') as corpus:\n",
    "    for line in corpus:\n",
    "        Corpus.add(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76707"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path+'corp_rub_corpus_dif.txt', 'w', encoding='utf-8') as f:\n",
    "    for w in Lemmas:\n",
    "        if w in Vocab:\n",
    "            continue \n",
    "        if w in Corpus:\n",
    "            continue\n",
    "        f.write(w+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بباشد\n",
      "بدادن\n",
      "بدرودن\n",
      "بنوشتن\n",
      "بگرفتیم\n",
      "بگداختن\n",
      "بگشادن\n",
      "باختن\n",
      "ببریدن\n",
      "برفتن\n",
      "بگریختن\n",
      "بدیدن\n",
      "بگفتن\n",
      "بنبشتن\n",
      "بپرداختن\n"
     ]
    }
   ],
   "source": [
    "pre = {'ز','ب','و'}\n",
    "post = {'ست','م','ت','ش'}\n",
    "\n",
    "with open(path+'corp_rub_corpus_dif_cut.txt', 'w', encoding='utf-8') as f:\n",
    "    for w in Lemmas:\n",
    "        if w in Vocab:\n",
    "            continue \n",
    "        if w in Corpus:\n",
    "            continue\n",
    "        word = w\n",
    "        if len(word) and word[0] in pre:\n",
    "            if len(word) and (word[1:] in Vocab or word[1:] in Corpus): \n",
    "                if Vocab[word[1:]] == 'гл.\\n':\n",
    "                    print(word)\n",
    "                else:\n",
    "                    f.write(word[0]+'\\t'+word[1:]+'\\n')\n",
    "        if len(word) and word[-1] in post:\n",
    "            if len(word) and (word[:-1] in Vocab or word[:-1] in Corpus):  \n",
    "                    f.write(word[:-1]+'\\t'+word[-1]+'\\n')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#27148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'гл.\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vocab['افتادن']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
