{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus wordlist"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import re\n",
    "\n",
    "infile = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\collect\\\\corpus_doc2\\\\corpus_frequency.txt'\n",
    "outfile = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\collect\\\\corpus_doc2\\\\wordlist.txt'\n",
    "outfilefreq = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\collect\\\\corpus_doc2\\\\wordlist_freq.txt'\n",
    "\n",
    "#infile = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\\n",
    "\n",
    "corpus = {}\n",
    "\n",
    "delimiters = ['،', '«', '»', ':', '!', '؟', '؛','...', '.', '(',')', '+']\n",
    "\n",
    "def punctsplit_withoutdelim(delimiters, string, maxsplit=0):\n",
    "    \n",
    "    regexPattern = '|'.join(map(re.escape, delimiters))\n",
    "    regexPattern = regexPattern+'| '\n",
    "    #return re.split('('+regexPattern+')', string)\n",
    "    #return re.split(regexPattern, string)\n",
    "    matches = list(filter(None, re.split(regexPattern, string)))\n",
    "    return matches\n",
    "\n",
    "w = open(outfile, 'w', encoding='utf-8')\n",
    "wf = open(outfilefreq, 'w', encoding='utf-8')\n",
    "\n",
    "with open(infile, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, freq = line.strip('\\n').split('\\t')\n",
    "        word = ''.join(punctsplit_withoutdelim(delimiters, word)) #strip \n",
    "        if word not in corpus:\n",
    "            corpus[word] = int(freq)\n",
    "        else:\n",
    "            corpus[word] += int(freq)\n",
    "        \n",
    "for word in sorted(corpus):\n",
    "    w.write(word)\n",
    "    w.write('\\n')\n",
    "    wf.write(word)\n",
    "    wf.write('\\t')\n",
    "    wf.write(str(corpus[word]))\n",
    "    wf.write('\\n')\n",
    "    \n",
    "w.close()\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Forms = {}\n",
    "\n",
    "for stem in stems:\n",
    "    forms(stem)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "#conj + prep + stem + plur + pron + art + ra + cop\n",
    "#conj + prep + stem + plur + pron + art + ke\n",
    "#conj + prep + stem + plur + ez\n",
    "\n",
    "#conj + prep + stem + plur + pron + art + cop + ke\n",
    "#conj + prep + stem + plur + pron + art + ra\n",
    "#conj + prep + stem + plur + ez\n",
    "\n",
    "\n",
    "conjs = {'و': 'CONJ ', '': ''}\n",
    "\n",
    "preps = {'اندر': 'PREP ', 'در': 'PREP ', 'بر': 'PREP ', 'ز': 'PREP ', 'ب': 'PREP ', 'از': 'PREP ', \n",
    "         u'\\u200c'+'به': 'PREP ', '': ''}\n",
    "\n",
    "#stems = set() #get from file\n",
    "\n",
    "#plur = ('ها', 'ان', 'جات', 'ات', 'گان', '')\n",
    "#plurs = {'ها': 'PL', 'ان': 'PL', 'ات': 'PL', '': 'SG'}\n",
    "plursE = {u'\\u200c'+'ها': 'PL', u'\\u200c'+'گان': 'PL', 'ات': 'PL', 'گان': 'PL', '': 'SG'}\n",
    "plursAll = {'ها': 'PL', 'ان': 'PL', '': 'SG', u'\\u200c'+'ها': 'PL'}\n",
    "\n",
    "\n",
    "# u'\\u200c' + pron\n",
    "# stem[:-1] + pron if stem.endswith('ه') or stem.endswith('ة') and plur in {'جات', 'ات', 'گان'}\n",
    "\n",
    "pronsAll = {'م': ' PRO1SG', 'ت': ' PRO2SG', 'ش': ' PRO3SG', 'مان': ' PRO1PL', \n",
    "         'تان': ' PRO2PL', 'شان': ' PRO3PL', '':'', u'\\u200c'+'م': ' PRO1SG', u'\\u200c'+'ت': ' PRO2SG', \n",
    "            u'\\u200c'+'ش': ' PRO3SG', u'\\u200c'+'مان': ' PRO1PL', \n",
    "         u'\\u200c'+'تان': ' PRO2PL', u'\\u200c'+'شان': ' PRO3PL'} \n",
    "pronsE = {u'\\u200c'+'ام': ' PRO1SG', u'\\u200c'+'ات': ' PRO2SG', u'\\u200c'+'اش': ' PRO3SG',\n",
    "          u'\\u200c'+'امان': ' PRO1PL', \n",
    "         u'\\u200c'+'اتان': ' PRO2PL', u'\\u200c'+'اشان': ' PRO3PL', '':''}\n",
    "pronsAIU = {'یم': ' PRO1SG', 'یت': ' PRO2SG', 'یش': ' PRO3SG', 'یمان': ' PRO1PL', \n",
    "         'یتان': ' PRO2PL', 'یشان': ' PRO3PL', '':''}\n",
    "\n",
    "# u'\\u200c' + pron\n",
    "# 'ا' + pron if stem.endswith('ه')\n",
    "# 'ی' + pron if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا')\n",
    "\n",
    "\n",
    "artsAll = {'ی':' YEH', '': ''}\n",
    "artsAIUE = {'یی': ' YEH', 'ئی': ' YEH', u'\\u200c'+'یی': ' YEH', u'\\u200c'+'ئی': ' YEH','': ''}\n",
    "# art = 'یی' if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# art = 'ئی' if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# u'\\u200c' + art\n",
    "\n",
    "ras = {'را': ' POSTP', '': ''}\n",
    "\n",
    "\n",
    "copsE = {u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': ''}\n",
    "\n",
    "copsAll = {'م': ' COP1SG', 'ی': ' COP2SG', 'ست': ' COP3SG', 'یم': ' COP1PL', 'ید': ' COP2PL',\n",
    "       'ند': ' COP3PL', u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': ''}\n",
    "# u'\\u200c' + cop\n",
    "# 'ا' + cop #if stem.endswith('ه')\n",
    "# u'\\u200c' + cop\n",
    "\n",
    "ezsAll = {'ی': ' EZ', '': ''}\n",
    "ezsE = {u'\\u200c'+'ی': ' EZ', '': ''}\n",
    "# if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "kes = {'که': ' CONJ', '':''}  #if gloss.endswith('YEH')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#stems = {'کتاب'}\n",
    "\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "#w = open(path+'Nforms.txt', 'w', encoding='utf-8')\n",
    "\n",
    "#forms = set()\n",
    "k = 0\n",
    "\n",
    "form = ''\n",
    "tag = ''\n",
    "\n",
    "\n",
    "\n",
    "def nounforms(stem):\n",
    "    Forms = {}\n",
    "    n = 0\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "    \n",
    "    for conj in conjs:\n",
    "        conjform = ''\n",
    "        conjtag = ''\n",
    "        conjform += conj\n",
    "        conjtag += conjs[conj]\n",
    "        \n",
    "        for prep in preps:\n",
    "            prepform = ''\n",
    "            preptag = ''\n",
    "            prepform = conjform + prep\n",
    "            preptag = conjtag + preps[prep]\n",
    "            \n",
    "            stemform = prepform + stem\n",
    "            \n",
    "            if (stemform.endswith('ه') or stemform.endswith('ة')):\n",
    "                plurs = plursE\n",
    "            else:\n",
    "                plurs = plursAll\n",
    "                \n",
    "            for plur in plurs:\n",
    "                \n",
    "                plurform = ''\n",
    "                plurtag = ''\n",
    "                \n",
    "                if plur == 'ات' or plur == 'گان':\n",
    "                    stemform = stemform[:-1]\n",
    "                \n",
    "                plurform = stemform + plur\n",
    "                plurtag = preptag + plurs[plur]\n",
    "                \n",
    "    \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    ezs = ezsAll\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    ezs = ezsE\n",
    "                else:\n",
    "                    ezs = {'':''}\n",
    "                # if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "                # u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "                for ez in ezs:\n",
    "                    ezform = ''\n",
    "                    eztag = ''\n",
    "                    ezform = plurform + ez\n",
    "                    eztag = plurtag + ezs[ez]\n",
    "                    \n",
    "                    #forms.add((ezform, eztag))\n",
    "                    \n",
    "                    if ezform not in Forms:\n",
    "                        Forms[ezform] = set()\n",
    "                        Forms[ezform].add(eztag)\n",
    "                        n += 1\n",
    "                    else:\n",
    "                        Forms[ezform].add(eztag)\n",
    "                        n += 1\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    prons = pronsAIU\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    prons = pronsE\n",
    "                else:\n",
    "                    prons = pronsAll\n",
    "                \n",
    "                for pron in prons:\n",
    "                    pronform = ''\n",
    "                    prontag = ''\n",
    "                    pronform = plurform + pron\n",
    "                    prontag = plurtag + prons[pron]\n",
    "                    \n",
    "                    if pronform.endswith('ی') or pronform.endswith('و') or pronform.endswith('ا') or pronform.endswith('ه') or pronform.endswith('ة'):\n",
    "                        arts = artsAIUE\n",
    "                    else:\n",
    "                        arts = artsAll\n",
    "                \n",
    "                    for art in arts:\n",
    "                        artform = ''\n",
    "                        arttag = ''\n",
    "                        artform = pronform + art\n",
    "                        arttag = prontag + arts[art]\n",
    "                        \n",
    "                        if 'YEH' in arttag:\n",
    "                            for ke in kes:\n",
    "                                keform = ''\n",
    "                                ketag = ''\n",
    "                                keform = artform + ke\n",
    "                                ketag = arttag + kes[ke]\n",
    "\n",
    "                                #forms.add((keform, ketag))\n",
    "                                \n",
    "                                if keform not in Forms:\n",
    "                                    Forms[keform] = set()\n",
    "                                    Forms[keform].add(ketag)\n",
    "                                    n += 1\n",
    "                                else:\n",
    "                                    Forms[keform].add(ketag)\n",
    "                                    n += 1\n",
    "                                \n",
    "                        \n",
    "                        for ra in ras:\n",
    "                            raform = ''\n",
    "                            ratag = ''\n",
    "                            \n",
    "                            raform = artform + ra\n",
    "                            ratag = arttag + ras[ra]\n",
    "                            \n",
    "                            if (raform.endswith('ه') or raform.endswith('ة')):\n",
    "                                cops = copsE\n",
    "                            else:\n",
    "                                cops = copsAll\n",
    "                                \n",
    "                            for cop in cops:\n",
    "                                copform = ''\n",
    "                                coptag = ''\n",
    "                                copform = raform + cop\n",
    "                                coptag = ratag + cops[cop]\n",
    "                                \n",
    "                                #forms.add((copform, coptag))\n",
    "                                \n",
    "                                if copform not in Forms:\n",
    "                                    Forms[copform] = set()\n",
    "                                    Forms[copform].add(coptag)\n",
    "                                    n += 1\n",
    "                                else:\n",
    "                                    Forms[copform].add(coptag)\n",
    "                                    n += 1\n",
    "                                \n",
    "                            \n",
    "                        \n",
    "    return (Forms, n)\n",
    "#w.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#lemma = 'کتاب'\n",
    "lemma = 'خانه'\n",
    "#lemma = 'آزادی'\n",
    "F, n = nounforms(lemma)\n",
    "print(len(F))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "CorpusTagged = {}\n",
    "Forms = {}\n",
    "\n",
    "pos = 'N'\n",
    "k = 0\n",
    "\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\'\n",
    "filename = 'word-N.txt'\n",
    "file = ''.join((path,filename))\n",
    "\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        Forms = {}\n",
    "        lemma = line.strip('\\n')\n",
    "        k += 1\n",
    "        if k%100 == 0:\n",
    "            print(k)\n",
    "        Forms = nounforms(lemma)\n",
    "        \n",
    "        for form in Forms:\n",
    "            if form in corpus:\n",
    "                if form not in CorpusTagged:\n",
    "                    CorpusTagged[form] = {pos: {}}\n",
    "                    if lemma not in CorpusTagged[form][pos]:\n",
    "                        CorpusTagged[form][pos][lemma] = Forms[form]\n",
    "                    else:\n",
    "                        CorpusTagged[form][pos][lemma] |= Forms[form]\n",
    "                else:\n",
    "                    if lemma not in CorpusTagged[form][pos]:\n",
    "                        CorpusTagged[form][pos][lemma] = Forms[form]\n",
    "                    else:\n",
    "                        CorpusTagged[form][pos][lemma] |= Forms[form]\n",
    "                        \n",
    "                        \n",
    "#CorpusTagged[form] = {pos: {lemma: set(tags)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(CorpusTagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1= {1,2}\n",
    "l2 = {3,4, 1, 5}\n",
    "l2 |= l1\n",
    "l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TAG NON ARABIC NOUNS WITH ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#conj + prep + stem + plur + pron + art + ra + cop\n",
    "#conj + prep + stem + plur + pron + art + ke\n",
    "#conj + prep + stem + plur + ez\n",
    "\n",
    "#conj + prep + stem + plur + pron + art + cop + ke\n",
    "#conj + prep + stem + plur + pron + art + ra\n",
    "#conj + prep + stem + plur + ez\n",
    "\n",
    "\n",
    "conjs = {'و': 'CONJ ', '': ''}\n",
    "\n",
    "preps = {'اندر': 'PREP ', 'در': 'PREP ', 'بر': 'PREP ', 'ز': 'PREP ', 'ب': 'PREP ', 'از': 'PREP ', \n",
    "         u'\\u200c'+'به': 'PREP ', '': ''}\n",
    "\n",
    "#stems = set() #get from file\n",
    "\n",
    "#plur = ('ها', 'ان', 'جات', 'ات', 'گان', '')\n",
    "#plurs = {'ها': 'PL', 'ان': 'PL', 'ات': 'PL', '': 'SG'}\n",
    "plursE = {u'\\u200c'+'ها': 'PL', u'\\u200c'+'گان': 'PL', 'ات': 'PL', 'گان': 'PL', '': 'SG'}\n",
    "plursAll = {'ها': 'PL', 'ان': 'PL', '': 'SG', u'\\u200c'+'ها': 'PL'}\n",
    "\n",
    "\n",
    "# u'\\u200c' + pron\n",
    "# stem[:-1] + pron if stem.endswith('ه') or stem.endswith('ة') and plur in {'جات', 'ات', 'گان'}\n",
    "\n",
    "pronsAll = {'م': ' PRO1SG', 'ت': ' PRO2SG', 'ش': ' PRO3SG', 'مان': ' PRO1PL', \n",
    "         'تان': ' PRO2PL', 'شان': ' PRO3PL', '':'', u'\\u200c'+'م': ' PRO1SG', u'\\u200c'+'ت': ' PRO2SG', \n",
    "            u'\\u200c'+'ش': ' PRO3SG', u'\\u200c'+'مان': ' PRO1PL', \n",
    "         u'\\u200c'+'تان': ' PRO2PL', u'\\u200c'+'شان': ' PRO3PL'} \n",
    "pronsE = {u'\\u200c'+'ام': ' PRO1SG', u'\\u200c'+'ات': ' PRO2SG', u'\\u200c'+'اش': ' PRO3SG',\n",
    "          u'\\u200c'+'امان': ' PRO1PL', \n",
    "         u'\\u200c'+'اتان': ' PRO2PL', u'\\u200c'+'اشان': ' PRO3PL', '':'',\n",
    "         'م': ' PRO1SG', 'ت': ' PRO2SG', 'ش': ' PRO3SG', 'مان': ' PRO1PL', \n",
    "         'تان': ' PRO2PL', 'شان': ' PRO3PL', u'\\u200c'+'م': ' PRO1SG', u'\\u200c'+'ت': ' PRO2SG', \n",
    "            u'\\u200c'+'ش': ' PRO3SG', u'\\u200c'+'مان': ' PRO1PL', \n",
    "         u'\\u200c'+'تان': ' PRO2PL', u'\\u200c'+'شان': ' PRO3PL'\n",
    "         \n",
    "         }\n",
    "pronsAIU = {'یم': ' PRO1SG', 'یت': ' PRO2SG', 'یش': ' PRO3SG', 'یمان': ' PRO1PL', \n",
    "         'یتان': ' PRO2PL', 'یشان': ' PRO3PL', '':'',\n",
    "           'م': ' PRO1SG', 'ت': ' PRO2SG', 'ش': ' PRO3SG', 'مان': ' PRO1PL', \n",
    "         'تان': ' PRO2PL', 'شان': ' PRO3PL', u'\\u200c'+'م': ' PRO1SG', u'\\u200c'+'ت': ' PRO2SG', \n",
    "            u'\\u200c'+'ش': ' PRO3SG', u'\\u200c'+'مان': ' PRO1PL', \n",
    "         u'\\u200c'+'تان': ' PRO2PL', u'\\u200c'+'شان': ' PRO3PL'\n",
    "           \n",
    "           }\n",
    "\n",
    "# u'\\u200c' + pron\n",
    "# 'ا' + pron if stem.endswith('ه')\n",
    "# 'ی' + pron if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا')\n",
    "\n",
    "\n",
    "artsAll = {'ی':' YEH', '': ''}\n",
    "artsAIUE = {'یی': ' YEH', 'ئی': ' YEH', u'\\u200c'+'یی': ' YEH', u'\\u200c'+'ئی': ' YEH','': ''}\n",
    "# art = 'یی' if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# art = 'ئی' if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# u'\\u200c' + art\n",
    "\n",
    "ras = {'را': ' POSTP', '': ''}\n",
    "\n",
    "\n",
    "copsE = {u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': '',\n",
    "        \n",
    "          'ستم': ' COP1SG', 'ستی': ' COP2SG',  'ستیم': ' COP1PL', 'ستید': ' COP2PL',\n",
    "       'ستند': ' COP3PL', u'\\u200c'+'هستم': ' COP1SG', u'\\u200c'+'هستی': ' COP2SG', u'\\u200c'+'هست': ' COP3SG', \n",
    "         u'\\u200c'+'هستیم': ' COP1PL', u'\\u200c'+'هستید': ' COP2PL',\n",
    "       u'\\u200c'+'هستند': ' COP3PL', u'\\u200c'+'ستم': ' COP1SG', u'\\u200c'+'ستی': ' COP2SG',  \n",
    "         u'\\u200c'+'ستیم': ' COP1PL', u'\\u200c'+'ستید': ' COP2PL', u'\\u200c'+'ستند': ' COP3PL'\n",
    "        \n",
    "        }\n",
    "\n",
    "copsAll = {'م': ' COP1SG', 'ی': ' COP2SG', 'ست': ' COP3SG', 'یم': ' COP1PL', 'ید': ' COP2PL',\n",
    "       'ند': ' COP3PL', u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': '',\n",
    "          \n",
    "           'ستم': ' COP1SG', 'ستی': ' COP2SG',  'ستیم': ' COP1PL', 'ستید': ' COP2PL',\n",
    "       'ستند': ' COP3PL', u'\\u200c'+'هستم': ' COP1SG', u'\\u200c'+'هستی': ' COP2SG', u'\\u200c'+'هست': ' COP3SG', \n",
    "         u'\\u200c'+'هستیم': ' COP1PL', u'\\u200c'+'هستید': ' COP2PL',\n",
    "       u'\\u200c'+'هستند': ' COP3PL', u'\\u200c'+'ستم': ' COP1SG', u'\\u200c'+'ستی': ' COP2SG',  \n",
    "         u'\\u200c'+'ستیم': ' COP1PL', u'\\u200c'+'ستید': ' COP2PL', u'\\u200c'+'ستند': ' COP3PL'\n",
    "          \n",
    "          \n",
    "          }\n",
    "# u'\\u200c' + cop\n",
    "# 'ا' + cop #if stem.endswith('ه')\n",
    "# u'\\u200c' + cop\n",
    "\n",
    "ezsAll = {'ی': ' EZ', '': ''}\n",
    "ezsE = {u'\\u200c'+'ی': ' EZ', '': ''}\n",
    "# if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "kes = {'که': ' CONJ', '':''}  #if gloss.endswith('YEH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stems = {'کتاب'}\n",
    "\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "#w = open(path+'Nforms.txt', 'w', encoding='utf-8')\n",
    "\n",
    "#forms = set()\n",
    "k = 0\n",
    "\n",
    "form = ''\n",
    "tag = ''\n",
    "\n",
    "#conj + prep + stem + plur + pron + art + cop + ke\n",
    "#conj + prep + stem + plur + pron + art + ra\n",
    "#conj + prep + stem + plur + ez\n",
    "\n",
    "\n",
    "def nounforms(stem):\n",
    "    Forms = {}\n",
    "    pos = 'N'\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "    \n",
    "    for conj in conjs:\n",
    "        conjform = ''\n",
    "        conjtag = ''\n",
    "        conjform += conj\n",
    "        conjtag += conjs[conj]\n",
    "        \n",
    "        for prep in preps:\n",
    "            prepform = ''\n",
    "            preptag = ''\n",
    "            prepform = conjform + prep\n",
    "            preptag = conjtag + preps[prep]\n",
    "            \n",
    "            stemform = prepform + stem\n",
    "            \n",
    "            if (stemform.endswith('ه') or stemform.endswith('ة')):\n",
    "                plurs = plursE\n",
    "            else:\n",
    "                plurs = plursAll\n",
    "                \n",
    "            for plur in plurs:\n",
    "                \n",
    "                plurform = ''\n",
    "                plurtag = ''\n",
    "                \n",
    "                plurstemform = stemform\n",
    "                if plur == 'ات' or plur == 'گان':\n",
    "                    plurstemform = stemform[:-1]\n",
    "                \n",
    "                plurform = plurstemform + plur\n",
    "                plurtag = preptag + plurs[plur]\n",
    "                \n",
    "    \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    ezs = ezsAll\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    ezs = ezsE\n",
    "                else:\n",
    "                    ezs = {'':''}\n",
    "                # if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "                # u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "                for ez in ezs:\n",
    "                    ezform = ''\n",
    "                    eztag = ''\n",
    "                    ezform = plurform + ez\n",
    "                    eztag = plurtag + ezs[ez]\n",
    "                    \n",
    "                    #forms.add((ezform, eztag))\n",
    "                    \n",
    "                    if ezform in corpus:\n",
    "                        addform(ezform, eztag, stem, pos)\n",
    "                \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    prons = pronsAIU\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    prons = pronsE\n",
    "                else:\n",
    "                    prons = pronsAll\n",
    "                \n",
    "                for pron in prons:\n",
    "                    pronform = ''\n",
    "                    prontag = ''\n",
    "                    pronform = plurform + pron\n",
    "                    prontag = plurtag + prons[pron]\n",
    "                    \n",
    "                    if pronform.endswith('ی') or pronform.endswith('و') or pronform.endswith('ا') or pronform.endswith('ه') or pronform.endswith('ة'):\n",
    "                        arts = artsAIUE\n",
    "                    else:\n",
    "                        arts = artsAll\n",
    "                \n",
    "                    for art in arts:\n",
    "                        artform = ''\n",
    "                        arttag = ''\n",
    "                        artform = pronform + art\n",
    "                        arttag = prontag + arts[art]\n",
    "                        \n",
    "                        if (artform.endswith('ه') or artform.endswith('ة')):\n",
    "                                cops = copsE\n",
    "                        else:\n",
    "                            cops = copsAll\n",
    "                                \n",
    "                        for cop in cops:\n",
    "                            copform = ''\n",
    "                            coptag = ''\n",
    "                            copform = artform + cop\n",
    "                            coptag = arttag + cops[cop]\n",
    "                        \n",
    "                        \n",
    "                            #if 'YEH' in arttag:\n",
    "                            for ke in kes:\n",
    "                                keform = ''\n",
    "                                ketag = ''\n",
    "                                keform = copform + ke\n",
    "                                ketag = coptag + kes[ke]\n",
    "\n",
    "                                #forms.add((keform, ketag))\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                if keform in corpus:\n",
    "                                    addform(keform, ketag, stem, pos)\n",
    "                        \n",
    "                        for ra in ras:\n",
    "                            raform = ''\n",
    "                            ratag = ''\n",
    "                            \n",
    "                            raform = artform + ra\n",
    "                            ratag = arttag + ras[ra]\n",
    "                            \n",
    "                            if raform in corpus:\n",
    "                                addform(raform, ratag, stem, pos)\n",
    "                                \n",
    "                            \n",
    "def addform(form, tag, lemm, pos):\n",
    "    if form not in CorpusTagged:\n",
    "        CorpusTagged[form] = {pos: {}}\n",
    "        if lemm not in CorpusTagged[form][pos]:\n",
    "            CorpusTagged[form][pos][lemm] = {tag}\n",
    "        else:\n",
    "            CorpusTagged[form][pos][lemm].add(tag)\n",
    "    else:\n",
    "        if pos not in CorpusTagged[form]:\n",
    "            CorpusTagged[form][pos] = {}\n",
    "            if lemm not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][lemm] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][lemm].add(tag)\n",
    "        else:\n",
    "            if lemm not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][lemm] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][lemm].add(tag) \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = set()\n",
    "corpusfile = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\collect\\\\corpus_doc2\\\\wordlist.txt'\n",
    "with open(corpusfile, 'r', encoding='utf-8') as c:\n",
    "    for line in c:\n",
    "        word = line.strip('\\n')\n",
    "        corpus.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n",
      "30700\n",
      "30800\n",
      "30900\n",
      "31000\n",
      "31100\n",
      "31200\n",
      "31300\n",
      "31400\n",
      "31500\n",
      "31600\n",
      "31700\n",
      "31800\n",
      "31900\n",
      "32000\n",
      "32100\n",
      "32200\n",
      "32300\n",
      "32400\n",
      "32500\n",
      "32600\n",
      "32700\n",
      "32800\n",
      "32900\n",
      "33000\n",
      "33100\n",
      "33200\n",
      "33300\n",
      "33400\n",
      "33500\n",
      "33600\n",
      "33700\n",
      "33800\n",
      "33900\n",
      "34000\n",
      "34100\n",
      "34200\n",
      "34300\n",
      "34400\n",
      "34500\n",
      "34600\n",
      "34700\n",
      "34800\n",
      "34900\n",
      "35000\n",
      "35100\n",
      "35200\n",
      "35300\n",
      "35400\n",
      "35500\n",
      "35600\n",
      "35700\n",
      "35800\n",
      "35900\n",
      "36000\n",
      "36100\n",
      "36200\n",
      "36300\n",
      "36400\n",
      "36500\n",
      "36600\n",
      "36700\n",
      "36800\n",
      "36900\n",
      "37000\n",
      "37100\n",
      "37200\n",
      "37300\n",
      "37400\n",
      "37500\n",
      "37600\n",
      "37700\n",
      "37800\n",
      "37900\n",
      "38000\n",
      "38100\n",
      "38200\n",
      "38300\n",
      "38400\n",
      "38500\n",
      "38600\n",
      "38700\n",
      "38800\n",
      "38900\n",
      "39000\n",
      "39100\n",
      "39200\n",
      "39300\n",
      "39400\n",
      "39500\n",
      "39600\n"
     ]
    }
   ],
   "source": [
    "CorpusTagged = {}\n",
    "Forms = {}\n",
    "\n",
    "pos = 'N'\n",
    "k = 0\n",
    "\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "filename = 'nouns_full.txt' #'nouns.txt'\n",
    "file = ''.join((path,filename))\n",
    "\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    with open(path+'nforms_500', 'w', encoding='utf-8') as w:\n",
    "        for line in f:\n",
    "            Forms = {}\n",
    "            lemma = line.strip('\\n')\n",
    "            k += 1\n",
    "            if k%100 == 0:\n",
    "                print(k)\n",
    "            if lemma:\n",
    "                nounforms(lemma)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51045"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CorpusTagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add function from other POS\n",
    "writeCorpusTagged(filename)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#import json, io\n",
    "\n",
    "#with open('TaggedWords_noun1.txt', 'w', encoding='utf-8') as f: \n",
    "#    json.dumps(corpus, f, ensure_ascii=False)\n",
    "with open('TaggedWords_noun1.txt', 'w', encoding='utf-8') as w: \n",
    "    for form in CorpusTagged:\n",
    "        w.write(form)\n",
    "        w.write('\\tN\\t')\n",
    "        for lemma in CorpusTagged[form]['N']:\n",
    "            w.write(lemma)\n",
    "            w.write('+')\n",
    "            for tag in CorpusTagged[form]['N'][lemma]:\n",
    "                w.write(tag)\n",
    "                w.write('#')\n",
    "            w.write('@')\n",
    "        w.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'آ': {'N': {'آ': {'SG'}}},\n",
       " 'آب': {'N': {'آب': {'SG'}}},\n",
       " 'آباء': {'N': {'آباء': {'SG'}}},\n",
       " 'آبادان': {'N': {'آبادان': {'SG'}}},\n",
       " 'آبادانش': {'N': {'آبادان': {'SG PRO3SG'}}},\n",
       " 'آبادانند': {'N': {'آبادان': {'SG COP3PL'}}},\n",
       " 'آبادانی': {'N': {'آبادان': {'SG COP2SG', 'SG YEH'}, 'آبادانی': {'SG'}}},\n",
       " 'آبادگان': {'N': {'آباده': {'PL'}}},\n",
       " 'آبادی': {'N': {'آبادی': {'SG'}}},\n",
       " 'آبادیان': {'N': {'آبادی': {'PL'}}},\n",
       " 'آبادیم': {'N': {'آبادی': {'SG COP1SG'}}},\n",
       " 'آبان': {'N': {'آب': {'PL'}, 'آبان': {'SG'}}},\n",
       " 'آبانش': {'N': {'آب': {'PL PRO3SG'}, 'آبان': {'SG PRO3SG'}}},\n",
       " 'آبانها': {'N': {'آبان': {'PL'}}},\n",
       " 'آبانی': {'N': {'آب': {'PL COP2SG', 'PL YEH'},\n",
       "   'آبان': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آبان\\u200cها': {'N': {'آبان': {'PL'}}},\n",
       " 'آبت': {'N': {'آب': {'SG PRO2SG'}}},\n",
       " 'آبتان': {'N': {'آب': {'SG PRO2PL'}}},\n",
       " 'آبخانه': {'N': {'آبخانه': {'SG'}}},\n",
       " 'آبخور': {'N': {'آبخور': {'SG'}}},\n",
       " 'آبخورت': {'N': {'آبخور': {'SG PRO2SG'}}},\n",
       " 'آبخورد': {'N': {'آبخورد': {'SG'}}},\n",
       " 'آبخوردش': {'N': {'آبخورد': {'SG PRO3SG'}}},\n",
       " 'آبخوردی': {'N': {'آبخورد': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آبدار': {'N': {'آبدار': {'SG'}}},\n",
       " 'آبدارت': {'N': {'آبدار': {'SG PRO2SG'}}},\n",
       " 'آبدارست': {'N': {'آبدار': {'SG COP3SG'}}},\n",
       " 'آبدارش': {'N': {'آبدار': {'SG PRO3SG'}}},\n",
       " 'آبدارم': {'N': {'آبدار': {'SG COP1SG', 'SG PRO1SG'}}},\n",
       " 'آبداری': {'N': {'آبدار': {'SG COP2SG', 'SG YEH'}, 'آبداری': {'SG'}}},\n",
       " 'آبدان': {'N': {'آبدان': {'SG'}}},\n",
       " 'آبدانی': {'N': {'آبدان': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آبدست': {'N': {'آبدست': {'SG'}}},\n",
       " 'آبدستان': {'N': {'آبدست': {'PL'}, 'آبدستان': {'SG'}}},\n",
       " 'آبدستم': {'N': {'آبدست': {'SG COP1SG', 'SG PRO1SG'}}},\n",
       " 'آبدستی': {'N': {'آبدست': {'SG COP2SG', 'SG YEH'}, 'آبدستی': {'SG'}}},\n",
       " 'آبدندانم': {'N': {'آبدندان': {'SG COP1SG', 'SG PRO1SG'}}},\n",
       " 'آبده': {'N': {'آبده': {'SG'}}},\n",
       " 'آبرا': {'N': {'آب': {'SG POSTP'}}},\n",
       " 'آبرو': {'N': {'آبرو': {'SG'}}},\n",
       " 'آبروئی': {'N': {'آبرو': {'SG YEH'}}},\n",
       " 'آبروان': {'N': {'آبرو': {'PL'}}},\n",
       " 'آبروی': {'N': {'آبرو': {'SG COP2SG', 'SG EZ'}}},\n",
       " 'آبرویت': {'N': {'آبرو': {'SG PRO2SG'}}},\n",
       " 'آبرویش': {'N': {'آبرو': {'SG PRO3SG'}}},\n",
       " 'آبرویم': {'N': {'آبرو': {'SG COP1PL', 'SG PRO1SG'}}},\n",
       " 'آبرویی': {'N': {'آبرو': {'SG YEH'}}},\n",
       " 'آبریز': {'N': {'آبریز': {'SG'}}},\n",
       " 'آبریزی': {'N': {'آبریز': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آبست': {'N': {'آب': {'SG COP3SG'}, 'آبست': {'SG'}}},\n",
       " 'آبستان': {'N': {'آبست': {'PL'}}},\n",
       " 'آبستست': {'N': {'آبست': {'SG COP3SG'}}},\n",
       " 'آبستنی': {'N': {'آبستنی': {'SG'}}},\n",
       " 'آبستنیم': {'N': {'آبستنی': {'SG COP1SG'}}},\n",
       " 'آبستنی\\u200cست': {'N': {'آبستنی': {'SG COP3SG'}}},\n",
       " 'آبستنی\\u200cها': {'N': {'آبستنی': {'PL'}}},\n",
       " 'آبستی': {'N': {'آبست': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آبش': {'N': {'آب': {'SG PRO3SG'}, 'آبش': {'SG'}}},\n",
       " 'آبشار': {'N': {'آبشار': {'SG'}}},\n",
       " 'آبشان': {'N': {'آب': {'SG PRO3PL'}, 'آبش': {'PL'}}},\n",
       " 'آبشخور': {'N': {'آبشخور': {'SG'}}},\n",
       " 'آبشخورت': {'N': {'آبشخور': {'SG PRO2SG'}}},\n",
       " 'آبشخورست': {'N': {'آبشخور': {'SG COP3SG'}}},\n",
       " 'آبشخورش': {'N': {'آبشخور': {'SG PRO3SG'}}},\n",
       " 'آبشخورم': {'N': {'آبشخور': {'SG COP1SG', 'SG PRO1SG'}}},\n",
       " 'آبشخوری': {'N': {'آبشخور': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آبله': {'N': {'آبله': {'SG'}}},\n",
       " 'آبله\\u200cای': {'N': {'آبله': {'SG COP2SG'}}},\n",
       " 'آبله\\u200cی': {'N': {'آبله': {'SG COP2SG', 'SG EZ'}}},\n",
       " 'آبم': {'N': {'آب': {'SG COP1SG', 'SG PRO1SG'}}},\n",
       " 'آبمی': {'N': {'آب': {'SG PRO1SG COP2SG', 'SG PRO1SG YEH'}}},\n",
       " 'آبند': {'N': {'آب': {'SG COP3PL'}}},\n",
       " 'آبنوس': {'N': {'آبنوس': {'SG'}}},\n",
       " 'آبنوست': {'N': {'آبنوس': {'SG PRO2SG'}}},\n",
       " 'آبنوسش': {'N': {'آبنوس': {'SG PRO3SG'}}},\n",
       " 'آبنوسم': {'N': {'آبنوس': {'SG COP1SG', 'SG PRO1SG'}}},\n",
       " 'آبنوسی': {'N': {'آبنوس': {'SG COP2SG', 'SG YEH'}, 'آبنوسی': {'SG'}}},\n",
       " 'آبها': {'N': {'آب': {'PL'}}},\n",
       " 'آبهاست': {'N': {'آب': {'PL COP3SG'}}},\n",
       " 'آبهای': {'N': {'آب': {'PL COP2SG', 'PL EZ'}}},\n",
       " 'آبکش': {'N': {'آبک': {'SG PRO3SG'}, 'آبکش': {'SG'}}},\n",
       " 'آبکند': {'N': {'آبک': {'SG COP3PL'}, 'آبکند': {'SG'}}},\n",
       " 'آبکندی': {'N': {'آبکند': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آبکی': {'N': {'آبک': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آبگیر': {'N': {'آبگیر': {'SG'}}},\n",
       " 'آبگیران': {'N': {'آبگیر': {'PL'}}},\n",
       " 'آبگیرست': {'N': {'آبگیر': {'SG COP3SG'}}},\n",
       " 'آبگیرش': {'N': {'آبگیر': {'SG PRO3SG'}}},\n",
       " 'آبگیرها': {'N': {'آبگیر': {'PL'}}},\n",
       " 'آبگیرهای': {'N': {'آبگیر': {'PL COP2SG', 'PL EZ'}}},\n",
       " 'آبگیری': {'N': {'آبگیر': {'SG COP2SG', 'SG YEH'}, 'آبگیری': {'SG'}}},\n",
       " 'آبگینه': {'N': {'آبگینه': {'SG'}}},\n",
       " 'آبگینه\\u200cای': {'N': {'آبگینه': {'SG COP2SG'}}},\n",
       " 'آبگینه\\u200cست': {'N': {'آبگینه': {'SG COP3SG'}}},\n",
       " 'آبگینه\\u200cها': {'N': {'آبگینه': {'PL'}}},\n",
       " 'آبگینه\\u200cی': {'N': {'آبگینه': {'SG COP2SG', 'SG EZ'}}},\n",
       " 'آبی': {'N': {'آب': {'SG COP2SG', 'SG YEH'}, 'آبی': {'SG'}}},\n",
       " 'آبیار': {'N': {'آبیار': {'SG'}}},\n",
       " 'آبیاری': {'N': {'آبیار': {'SG COP2SG', 'SG YEH'}, 'آبیاری': {'SG'}}},\n",
       " 'آبیست': {'N': {'آب': {'SG YEH COP3SG'}, 'آبی': {'SG COP3SG'}}},\n",
       " 'آبیم': {'N': {'آب': {'SG COP1PL', 'SG YEH COP1SG'}, 'آبی': {'SG COP1SG'}}},\n",
       " 'آبیی': {'N': {'آب': {'SG YEH COP2SG'}, 'آبی': {'SG COP2SG', 'SG EZ'}}},\n",
       " 'آبی\\u200cای': {'N': {'آب': {'SG YEH COP2SG'}, 'آبی': {'SG COP2SG'}}},\n",
       " 'آبی\\u200cست': {'N': {'آب': {'SG YEH COP3SG'}, 'آبی': {'SG COP3SG'}}},\n",
       " 'آب\\u200cام': {'N': {'آب': {'SG COP1SG'}}},\n",
       " 'آب\\u200cجو': {'N': {'آب\\u200cجو': {'SG'}}},\n",
       " 'آب\\u200cخورد': {'N': {'آب\\u200cخورد': {'SG'}}},\n",
       " 'آب\\u200cخوردش': {'N': {'آب\\u200cخورد': {'SG PRO3SG'}}},\n",
       " 'آب\\u200cخورش': {'N': {'آب\\u200cخورش': {'SG'}}},\n",
       " 'آب\\u200cمان': {'N': {'آب': {'SG PRO1PL'}}},\n",
       " 'آب\\u200cها': {'N': {'آب': {'PL'}}},\n",
       " 'آب\\u200cهای': {'N': {'آب': {'PL COP2SG', 'PL EZ'}}},\n",
       " 'آب\\u200cگیر': {'N': {'آب\\u200cگیر': {'SG'}}},\n",
       " 'آت': {'N': {'آ': {'SG PRO2SG'}}},\n",
       " 'آتا': {'N': {'آتا': {'SG'}}},\n",
       " 'آتش': {'N': {'آتش': {'SG'}}},\n",
       " 'آتشان': {'N': {'آتش': {'PL'}}},\n",
       " 'آتشبار': {'N': {'آتشبار': {'SG'}}},\n",
       " 'آتشت': {'N': {'آتش': {'SG PRO2SG'}}},\n",
       " 'آتشتان': {'N': {'آتش': {'SG PRO2PL'}}},\n",
       " 'آتشخانه': {'N': {'آتشخانه': {'SG'}}},\n",
       " 'آتشخانه\\u200cی': {'N': {'آتشخانه': {'SG COP2SG', 'SG EZ'}}},\n",
       " 'آتشدان': {'N': {'آتشدان': {'SG'}}},\n",
       " 'آتشست': {'N': {'آتش': {'SG COP3SG'}}},\n",
       " 'آتشش': {'N': {'آتش': {'SG PRO3SG'}}},\n",
       " 'آتششان': {'N': {'آتش': {'SG PRO3PL'}}},\n",
       " 'آتشم': {'N': {'آتش': {'SG COP1SG', 'SG PRO1SG'}}},\n",
       " 'آتشند': {'N': {'آتش': {'SG COP3PL'}}},\n",
       " 'آتشها': {'N': {'آتش': {'PL'}}},\n",
       " 'آتشهای': {'N': {'آتش': {'PL COP2SG', 'PL EZ'}}},\n",
       " 'آتشگاه': {'N': {'آتشگاه': {'SG'}}},\n",
       " 'آتشگه': {'N': {'آتشگه': {'SG'}}},\n",
       " 'آتشی': {'N': {'آتش': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آتشیست': {'N': {'آتش': {'SG YEH COP3SG'}}},\n",
       " 'آتشیم': {'N': {'آتش': {'SG COP1PL', 'SG YEH COP1SG'}}},\n",
       " 'آتشیی': {'N': {'آتش': {'SG YEH COP2SG'}}},\n",
       " 'آتشی\\u200cاند': {'N': {'آتش': {'SG YEH COP3PL'}}},\n",
       " 'آتشی\\u200cست': {'N': {'آتش': {'SG YEH COP3SG'}}},\n",
       " 'آتش\\u200cافروز': {'N': {'آتش\\u200cافروز': {'SG'}}},\n",
       " 'آتش\\u200cام': {'N': {'آتش': {'SG COP1SG'}}},\n",
       " 'آتش\\u200cاند': {'N': {'آتش': {'SG COP3PL'}}},\n",
       " 'آتش\\u200cبار': {'N': {'آتش\\u200cبار': {'SG'}}},\n",
       " 'آتش\\u200cخوار': {'N': {'آتش\\u200cخوار': {'SG'}}},\n",
       " 'آتش\\u200cزبان': {'N': {'آتش\\u200cزبان': {'SG'}}},\n",
       " 'آتش\\u200cزنه': {'N': {'آتش\\u200cزنه': {'SG'}}},\n",
       " 'آتش\\u200cزنه\\u200cای': {'N': {'آتش\\u200cزنه': {'SG COP2SG'}}},\n",
       " 'آتش\\u200cزنه\\u200cست': {'N': {'آتش\\u200cزنه': {'SG COP3SG'}}},\n",
       " 'آتش\\u200cزنه\\u200cی': {'N': {'آتش\\u200cزنه': {'SG COP2SG', 'SG EZ'}}},\n",
       " 'آتش\\u200cست': {'N': {'آتش': {'SG COP3SG'}}},\n",
       " 'آتش\\u200cفشان': {'N': {'آتش\\u200cفشان': {'SG'}}},\n",
       " 'آتش\\u200cفشانی': {'N': {'آتش\\u200cفشان': {'SG COP2SG', 'SG YEH'},\n",
       "   'آتش\\u200cفشانی': {'SG'}}},\n",
       " 'آتش\\u200cنشانی': {'N': {'آتش\\u200cنشان': {'SG COP2SG', 'SG YEH'},\n",
       "   'آتش\\u200cنشانی': {'SG'}}},\n",
       " 'آتش\\u200cها': {'N': {'آتش': {'PL'}}},\n",
       " 'آتش\\u200cهای': {'N': {'آتش': {'PL COP2SG', 'PL EZ'}}},\n",
       " 'آتش\\u200cپاره\\u200cای': {'N': {'آتش\\u200cپاره': {'SG COP2SG'}}},\n",
       " 'آتش\\u200cپاره\\u200cی': {'N': {'آتش\\u200cپاره': {'SG COP2SG', 'SG EZ'}}},\n",
       " 'آتش\\u200cپرست': {'N': {'آتش\\u200cپرست': {'SG'}}},\n",
       " 'آتش\\u200cپرستان': {'N': {'آتش\\u200cپرست': {'PL'}}},\n",
       " 'آتش\\u200cپرستی': {'N': {'آتش\\u200cپرست': {'SG COP2SG', 'SG YEH'},\n",
       "   'آتش\\u200cپرستی': {'SG'}}},\n",
       " 'آتش\\u200cکده': {'N': {'آتش\\u200cکده': {'SG'}}},\n",
       " 'آتش\\u200cکش': {'N': {'آتش\\u200cکش': {'SG'}}},\n",
       " 'آتش\\u200cکشی': {'N': {'آتش\\u200cکش': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آتش\\u200cکشی\\u200cام': {'N': {'آتش\\u200cکش': {'SG YEH COP1SG'}}},\n",
       " 'آتش\\u200cکنی': {'N': {'آتش\\u200cکن': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آتش\\u200cگه': {'N': {'آتش\\u200cگه': {'SG'}}},\n",
       " 'آتل': {'N': {'آتل': {'SG'}}},\n",
       " 'آتی': {'N': {'آ': {'SG PRO2SG COP2SG', 'SG PRO2SG YEH'}}},\n",
       " 'آثار': {'N': {'آثار': {'SG'}}},\n",
       " 'آثارت': {'N': {'آثار': {'SG PRO2SG'}}},\n",
       " 'آثارست': {'N': {'آثار': {'SG COP3SG'}}},\n",
       " 'آثارش': {'N': {'آثار': {'SG PRO3SG'}}},\n",
       " 'آثارم': {'N': {'آثار': {'SG COP1SG', 'SG PRO1SG'}}},\n",
       " 'آثاری': {'N': {'آثار': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آثام': {'N': {'آثام': {'SG'}}},\n",
       " 'آجال': {'N': {'آجال': {'SG'}}},\n",
       " 'آجام': {'N': {'آجام': {'SG'}}},\n",
       " 'آجر': {'N': {'آجر': {'SG'}}},\n",
       " 'آجرت': {'N': {'آجر': {'SG PRO2SG'}}},\n",
       " 'آجل': {'N': {'آجل': {'SG'}}},\n",
       " 'آجلست': {'N': {'آجل': {'SG COP3SG'}}},\n",
       " 'آجلش': {'N': {'آجل': {'SG PRO3SG'}}},\n",
       " 'آجیده': {'N': {'آجیده': {'SG'}}},\n",
       " 'آحاد': {'N': {'آحاد': {'SG'}}},\n",
       " 'آحادست': {'N': {'آحاد': {'SG COP3SG'}}},\n",
       " 'آحادم': {'N': {'آحاد': {'SG COP1SG', 'SG PRO1SG'}}},\n",
       " 'آحادی': {'N': {'آحاد': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آحادیم': {'N': {'آحاد': {'SG COP1PL', 'SG YEH COP1SG'}}},\n",
       " 'آخال': {'N': {'آخال': {'SG'}}},\n",
       " 'آخته': {'N': {'آخته': {'SG'}}},\n",
       " 'آخته\\u200cای': {'N': {'آخته': {'SG COP2SG'}}},\n",
       " 'آخته\\u200cست': {'N': {'آخته': {'SG COP3SG'}}},\n",
       " 'آخر': {'N': {'آخر': {'SG'}}},\n",
       " 'آخرالزمان': {'N': {'آخرالزمان': {'SG'}}},\n",
       " 'آخرالزمانست': {'N': {'آخرالزمان': {'SG COP3SG'}}},\n",
       " 'آخرالزمانم': {'N': {'آخرالزمان': {'SG COP1SG', 'SG PRO1SG'}}},\n",
       " 'آخرالزمانی': {'N': {'آخرالزمان': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آخران': {'N': {'آخر': {'PL'}}},\n",
       " 'آخراندیشی': {'N': {'آخراندیشی': {'SG'}}},\n",
       " 'آخرت': {'N': {'آخر': {'SG PRO2SG'}, 'آخرت': {'SG'}}},\n",
       " 'آخرتت': {'N': {'آخرت': {'SG PRO2SG'}}},\n",
       " 'آخرتست': {'N': {'آخر': {'SG PRO2SG COP3SG'}, 'آخرت': {'SG COP3SG'}}},\n",
       " 'آخرتش': {'N': {'آخرت': {'SG PRO3SG'}}},\n",
       " 'آخرتیم': {'N': {'آخر': {'SG PRO2SG COP1PL', 'SG PRO2SG YEH COP1SG'},\n",
       "   'آخرت': {'SG COP1PL', 'SG YEH COP1SG'}}},\n",
       " 'آخرزمان': {'N': {'آخرزمان': {'SG'}}},\n",
       " 'آخرزمانست': {'N': {'آخرزمان': {'SG COP3SG'}}},\n",
       " 'آخرست': {'N': {'آخر': {'SG COP3SG'}}},\n",
       " 'آخرش': {'N': {'آخر': {'SG PRO3SG'}}},\n",
       " 'آخرم': {'N': {'آخر': {'SG COP1SG', 'SG PRO1SG'}}},\n",
       " 'آخرند': {'N': {'آخر': {'SG COP3PL'}}},\n",
       " 'آخرهای': {'N': {'آخر': {'PL COP2SG', 'PL EZ'}}},\n",
       " 'آخری': {'N': {'آخر': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آخریان': {'N': {'آخریان': {'SG'}}},\n",
       " 'آخریست': {'N': {'آخر': {'SG YEH COP3SG'}}},\n",
       " 'آخشیج': {'N': {'آخشیج': {'SG'}}},\n",
       " 'آخشیجان': {'N': {'آخشیج': {'PL'}}},\n",
       " 'آخور': {'N': {'آخور': {'SG'}}},\n",
       " 'آخورت': {'N': {'آخور': {'SG PRO2SG'}}},\n",
       " 'آخورش': {'N': {'آخور': {'SG PRO3SG'}}},\n",
       " 'آخوری': {'N': {'آخور': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آداب': {'N': {'آداب': {'SG'}}},\n",
       " 'آدابش': {'N': {'آداب': {'SG PRO3SG'}}},\n",
       " 'آدابی': {'N': {'آداب': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آدر': {'N': {'آدر': {'SG'}}},\n",
       " 'آدم': {'N': {'آدم': {'SG'}}},\n",
       " 'آدمت': {'N': {'آدم': {'SG PRO2SG'}}},\n",
       " 'آدمست': {'N': {'آدم': {'SG COP3SG'}}},\n",
       " 'آدمش': {'N': {'آدم': {'SG PRO3SG'}}},\n",
       " 'آدمم': {'N': {'آدم': {'SG COP1SG', 'SG PRO1SG'}}},\n",
       " 'آدمند': {'N': {'آدم': {'SG COP3PL'}}},\n",
       " 'آدمی': {'N': {'آدم': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آدمید': {'N': {'آدم': {'SG COP2PL'}}},\n",
       " 'آدمیست': {'N': {'آدم': {'SG YEH COP3SG'}}},\n",
       " 'آدمیم': {'N': {'آدم': {'SG COP1PL', 'SG YEH COP1SG'}}},\n",
       " 'آدمیند': {'N': {'آدم': {'SG YEH COP3PL'}}},\n",
       " 'آدمیی': {'N': {'آدم': {'SG YEH COP2SG'}}},\n",
       " 'آدمی\\u200cام': {'N': {'آدم': {'SG YEH COP1SG'}}},\n",
       " 'آدمی\\u200cاند': {'N': {'آدم': {'SG YEH COP3PL'}}},\n",
       " 'آدمی\\u200cست': {'N': {'آدم': {'SG YEH COP3SG'}}},\n",
       " 'آدم\\u200cام': {'N': {'آدم': {'SG COP1SG'}}},\n",
       " 'آدم\\u200cاند': {'N': {'آدم': {'SG COP3PL'}}},\n",
       " 'آرا': {'N': {'آ': {'SG POSTP'}}},\n",
       " 'آست': {'N': {'آ': {'SG COP3SG'}}},\n",
       " 'آش': {'N': {'آ': {'SG PRO3SG'}}},\n",
       " 'آشی': {'N': {'آ': {'SG PRO3SG COP2SG', 'SG PRO3SG YEH'}}},\n",
       " 'آند': {'N': {'آ': {'SG COP3PL'}}},\n",
       " 'آچار': {'N': {'آچار': {'SG'}}},\n",
       " 'آچارش': {'N': {'آچار': {'SG PRO3SG'}}},\n",
       " 'آکه': {'N': {'آ': {'SG CONJ'}}},\n",
       " 'آی': {'N': {'آ': {'SG COP2SG', 'SG YEH'}}},\n",
       " 'آید': {'N': {'آ': {'SG COP2PL'}}},\n",
       " 'آیم': {'N': {'آ': {'SG COP1PL', 'SG YEH COP1SG'}}},\n",
       " 'آیند': {'N': {'آ': {'SG YEH COP3PL'}}},\n",
       " 'آیی': {'N': {'آ': {'SG YEH COP2SG'}}},\n",
       " 'آیید': {'N': {'آ': {'SG YEH COP2PL'}}},\n",
       " 'آییم': {'N': {'آ': {'SG YEH COP1PL'}}},\n",
       " 'ازآتش': {'N': {'آتش': {'PREP SG'}}},\n",
       " 'اندرآ': {'N': {'آ': {'PREP SG'}}},\n",
       " 'اندرآب': {'N': {'آب': {'PREP SG'}}},\n",
       " 'اندرآی': {'N': {'آ': {'PREP SG COP2SG', 'PREP SG YEH'}}},\n",
       " 'اندرآید': {'N': {'آ': {'PREP SG COP2PL'}}},\n",
       " 'اندرآیم': {'N': {'آ': {'PREP SG COP1PL', 'PREP SG YEH COP1SG'}}},\n",
       " 'اندرآیند': {'N': {'آ': {'PREP SG YEH COP3PL'}}},\n",
       " 'اندرآیی': {'N': {'آ': {'PREP SG YEH COP2SG'}}},\n",
       " 'اندرآییم': {'N': {'آ': {'PREP SG YEH COP1PL'}}},\n",
       " 'برآ': {'N': {'آ': {'PREP SG'}}},\n",
       " 'برآب': {'N': {'آب': {'PREP SG'}}},\n",
       " 'برآبش': {'N': {'آب': {'PREP SG PRO3SG'}, 'آبش': {'PREP SG'}}},\n",
       " 'برآبی': {'N': {'آب': {'PREP SG COP2SG', 'PREP SG YEH'}, 'آبی': {'PREP SG'}}},\n",
       " 'برآتش': {'N': {'آتش': {'PREP SG'}}},\n",
       " 'برآتشت': {'N': {'آتش': {'PREP SG PRO2SG'}}},\n",
       " 'برآتشست': {'N': {'آتش': {'PREP SG COP3SG'}}},\n",
       " 'برآتشم': {'N': {'آتش': {'PREP SG COP1SG', 'PREP SG PRO1SG'}}},\n",
       " 'برآتشی': {'N': {'آتش': {'PREP SG COP2SG', 'PREP SG YEH'}}},\n",
       " 'برآثار': {'N': {'آثار': {'PREP SG'}}},\n",
       " 'برآخر': {'N': {'آخر': {'PREP SG'}}},\n",
       " 'برآند': {'N': {'آ': {'PREP SG COP3PL'}}},\n",
       " 'برآی': {'N': {'آ': {'PREP SG COP2SG', 'PREP SG YEH'}}},\n",
       " 'برآید': {'N': {'آ': {'PREP SG COP2PL'}}},\n",
       " 'برآیم': {'N': {'آ': {'PREP SG COP1PL', 'PREP SG YEH COP1SG'}}},\n",
       " 'برآیند': {'N': {'آ': {'PREP SG YEH COP3PL'}}},\n",
       " 'برآیی': {'N': {'آ': {'PREP SG YEH COP2SG'}}},\n",
       " 'برآیید': {'N': {'آ': {'PREP SG YEH COP2PL'}}},\n",
       " 'برآییم': {'N': {'آ': {'PREP SG YEH COP1PL'}}},\n",
       " 'درآ': {'N': {'آ': {'PREP SG'}}},\n",
       " 'درآب': {'N': {'آب': {'PREP SG'}}},\n",
       " 'درآبادی': {'N': {'آبادی': {'PREP SG'}}},\n",
       " 'درآبم': {'N': {'آب': {'PREP SG COP1SG', 'PREP SG PRO1SG'}}},\n",
       " 'درآبی': {'N': {'آب': {'PREP SG COP2SG', 'PREP SG YEH'}, 'آبی': {'PREP SG'}}},\n",
       " 'درآتش': {'N': {'آتش': {'PREP SG'}}},\n",
       " 'درآتشیم': {'N': {'آتش': {'PREP SG COP1PL', 'PREP SG YEH COP1SG'}}},\n",
       " 'درآی': {'N': {'آ': {'PREP SG COP2SG', 'PREP SG YEH'}}},\n",
       " 'درآید': {'N': {'آ': {'PREP SG COP2PL'}}},\n",
       " 'درآیم': {'N': {'آ': {'PREP SG COP1PL', 'PREP SG YEH COP1SG'}}},\n",
       " 'درآیند': {'N': {'آ': {'PREP SG YEH COP3PL'}}},\n",
       " 'درآیی': {'N': {'آ': {'PREP SG YEH COP2SG'}}},\n",
       " 'درآیید': {'N': {'آ': {'PREP SG YEH COP2PL'}}},\n",
       " 'درآییم': {'N': {'آ': {'PREP SG YEH COP1PL'}}},\n",
       " 'زآب': {'N': {'آب': {'PREP SG'}}},\n",
       " 'زآتش': {'N': {'آتش': {'PREP SG'}}},\n",
       " 'زآتشی': {'N': {'آتش': {'PREP SG COP2SG', 'PREP SG YEH'}}},\n",
       " 'زآتش\\u200cانگیز': {'N': {'آتش\\u200cانگیز': {'PREP SG'}}},\n",
       " 'زآداب': {'N': {'آداب': {'PREP SG'}}},\n",
       " 'زآدم': {'N': {'آدم': {'PREP SG'}}},\n",
       " 'وآب': {'N': {'آب': {'CONJ SG'}}},\n",
       " 'وآبی': {'N': {'آب': {'CONJ SG COP2SG', 'CONJ SG YEH'}, 'آبی': {'CONJ SG'}}},\n",
       " 'وآتانی': {'N': {'آ': {'CONJ SG PRO2PL COP2SG', 'CONJ SG PRO2PL YEH'}}},\n",
       " 'وآتش': {'N': {'آتش': {'CONJ SG'}}},\n",
       " 'وآخر': {'N': {'آخر': {'CONJ SG'}}},\n",
       " 'وآخرش': {'N': {'آخر': {'CONJ SG PRO3SG'}}},\n",
       " 'وآید': {'N': {'آ': {'CONJ SG COP2PL'}}},\n",
       " 'وآیم': {'N': {'آ': {'CONJ SG COP1PL', 'CONJ SG YEH COP1SG'}}}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tag arabic words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate copus CorpusTagged2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#stems = {'کتاب'}\n",
    "\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "#w = open(path+'Nforms.txt', 'w', encoding='utf-8')\n",
    "\n",
    "#forms = set()\n",
    "k = 0\n",
    "\n",
    "form = ''\n",
    "tag = ''\n",
    "\n",
    "#conj + prep + stem + plur + pron + art + cop + ke\n",
    "#conj + prep + stem + plur + pron + art + ra\n",
    "#conj + prep + stem + plur + ez\n",
    "\n",
    "\n",
    "def nounformsArab2(stem):\n",
    "    Forms = {}\n",
    "    pos = 'N'\n",
    "    \n",
    "    stems = {}\n",
    "    stems = {stem: 'SG'}\n",
    "    for pl in arab[stem]:\n",
    "        stems[pl] = 'PL'\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "    \n",
    "    for conj in conjs:\n",
    "        conjform = ''\n",
    "        conjtag = ''\n",
    "        conjform += conj\n",
    "        conjtag += conjs[conj]\n",
    "        \n",
    "        for prep in preps:\n",
    "            prepform = ''\n",
    "            preptag = ''\n",
    "            prepform = conjform + prep\n",
    "            preptag = conjtag + preps[prep]\n",
    "            \n",
    "            \n",
    "        \n",
    "                \n",
    "            for stemform in stems:\n",
    "                plurform = ''\n",
    "                plurtag = ''\n",
    "                plurform = prepform + stemform\n",
    "                plurtag = preptag +stems[stemform]\n",
    "            \n",
    "                \n",
    "                \n",
    "    \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    ezs = ezsAll\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    ezs = ezsE\n",
    "                else:\n",
    "                    ezs = {'':''}\n",
    "                # if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "                # u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "                for ez in ezs:\n",
    "                    ezform = ''\n",
    "                    eztag = ''\n",
    "                    ezform = plurform + ez\n",
    "                    eztag = plurtag + ezs[ez]\n",
    "                    \n",
    "                    #forms.add((ezform, eztag))\n",
    "                    \n",
    "                    if ezform in corpus:\n",
    "                        if ezform not in CorpusTagged2:\n",
    "                            CorpusTagged2[ezform] = {pos: {}}\n",
    "                            if stem not in CorpusTagged2[ezform][pos]:\n",
    "                                CorpusTagged2[ezform][pos][stem] = {eztag}\n",
    "                            else:\n",
    "                                CorpusTagged2[ezform][pos][stem].add(eztag)\n",
    "                        else:\n",
    "                            if stem not in CorpusTagged2[ezform][pos]:\n",
    "                                CorpusTagged2[ezform][pos][stem] = {eztag}\n",
    "                            else:\n",
    "                                CorpusTagged2[ezform][pos][stem].add(eztag)\n",
    "                    '''\n",
    "                    if ezform not in Forms:\n",
    "                        Forms[ezform] = set()\n",
    "                        Forms[ezform].add(eztag)\n",
    "                    else:\n",
    "                        Forms[ezform].add(eztag)\n",
    "                    '''\n",
    "                    \n",
    "                \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    prons = pronsAIU\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    prons = pronsE\n",
    "                else:\n",
    "                    prons = pronsAll\n",
    "                \n",
    "                for pron in prons:\n",
    "                    pronform = ''\n",
    "                    prontag = ''\n",
    "                    pronform = plurform + pron\n",
    "                    prontag = plurtag + prons[pron]\n",
    "                    \n",
    "                    if pronform.endswith('ی') or pronform.endswith('و') or pronform.endswith('ا') or pronform.endswith('ه') or pronform.endswith('ة'):\n",
    "                        arts = artsAIUE\n",
    "                    else:\n",
    "                        arts = artsAll\n",
    "                \n",
    "                    for art in arts:\n",
    "                        artform = ''\n",
    "                        arttag = ''\n",
    "                        artform = pronform + art\n",
    "                        arttag = prontag + arts[art]\n",
    "                        \n",
    "                        if (artform.endswith('ه') or artform.endswith('ة')):\n",
    "                                cops = copsE\n",
    "                        else:\n",
    "                            cops = copsAll\n",
    "                                \n",
    "                        for cop in cops:\n",
    "                            copform = ''\n",
    "                            coptag = ''\n",
    "                            copform = artform + cop\n",
    "                            coptag = arttag + cops[cop]\n",
    "                        \n",
    "                        \n",
    "                            #if 'YEH' in arttag:\n",
    "                            for ke in kes:\n",
    "                                keform = ''\n",
    "                                ketag = ''\n",
    "                                keform = copform + ke\n",
    "                                ketag = coptag + kes[ke]\n",
    "\n",
    "                                #forms.add((keform, ketag))\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                if keform in corpus:\n",
    "                                    if keform not in CorpusTagged2:\n",
    "                                        CorpusTagged2[keform] = {pos: {}}\n",
    "                                        if stem not in CorpusTagged2[keform][pos]:\n",
    "                                            CorpusTagged2[keform][pos][stem] = {ketag}\n",
    "                                        else:\n",
    "                                            CorpusTagged2[keform][pos][stem].add(ketag)\n",
    "                                    else:\n",
    "                                        if stem not in CorpusTagged2[keform][pos]:\n",
    "                                            CorpusTagged2[keform][pos][stem] = {ketag}\n",
    "                                        else:\n",
    "                                            CorpusTagged2[keform][pos][stem].add(ketag)\n",
    "                                '''\n",
    "                                if keform not in Forms:\n",
    "                                    Forms[keform] = set()\n",
    "                                    Forms[keform].add(ketag)\n",
    "                                else:\n",
    "                                    Forms[keform].add(ketag)\n",
    "                                '''\n",
    "                        \n",
    "                        for ra in ras:\n",
    "                            raform = ''\n",
    "                            ratag = ''\n",
    "                            \n",
    "                            raform = artform + ra\n",
    "                            ratag = arttag + ras[ra]\n",
    "                            \n",
    "                            if raform in corpus:\n",
    "                                if raform not in CorpusTagged2:\n",
    "                                    CorpusTagged2[raform] = {pos: {}}\n",
    "                                    if stem not in CorpusTagged2[raform][pos]:\n",
    "                                        CorpusTagged2[raform][pos][stem] = {ratag}\n",
    "                                    else:\n",
    "                                        CorpusTagged2[raform][pos][stem].add(ratag)\n",
    "                                else:\n",
    "                                    if stem not in CorpusTagged2[raform][pos]:\n",
    "                                        CorpusTagged2[raform][pos][stem] = {ratag}\n",
    "                                    else:\n",
    "                                        CorpusTagged2[raform][pos][stem].add(ratag)\n",
    "                                \n",
    "                                #forms.add((copform, coptag))\n",
    "                                '''\n",
    "                                if copform not in Forms:\n",
    "                                    Forms[copform] = set()\n",
    "                                    Forms[copform].add(coptag)\n",
    "                                else:\n",
    "                                    Forms[copform].add(coptag)\n",
    "                                '''\n",
    "                                \n",
    "                            \n",
    "                        \n",
    "    #return Forms\n",
    "#w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "add arab to the previous corpus CorpusTagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "\n",
    "k = 0\n",
    "\n",
    "form = ''\n",
    "tag = ''\n",
    "\n",
    "#conj + prep + stem + plur + pron + art + cop + ke\n",
    "#conj + prep + stem + plur + pron + art + ra\n",
    "#conj + prep + stem + plur + ez\n",
    "\n",
    "\n",
    "def nounformsArab(stem):\n",
    "    Forms = {}\n",
    "    pos = 'N'\n",
    "    \n",
    "    stems = {}\n",
    "    stems = {stem: 'SG'}\n",
    "    for pl in arab[stem]:\n",
    "        stems[pl] = 'PL'\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "    \n",
    "    for conj in conjs:\n",
    "        conjform = ''\n",
    "        conjtag = ''\n",
    "        conjform += conj\n",
    "        conjtag += conjs[conj]\n",
    "        \n",
    "        for prep in preps:\n",
    "            prepform = ''\n",
    "            preptag = ''\n",
    "            prepform = conjform + prep\n",
    "            preptag = conjtag + preps[prep]\n",
    "            \n",
    "            \n",
    "        \n",
    "                \n",
    "            for stemform in stems:\n",
    "                plurform = ''\n",
    "                plurtag = ''\n",
    "                plurform = prepform + stemform\n",
    "                plurtag = preptag +stems[stemform]\n",
    "            \n",
    "                \n",
    "                \n",
    "    \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    ezs = ezsAll\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    ezs = ezsE\n",
    "                else:\n",
    "                    ezs = {'':''}\n",
    "                # if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "                # u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "                for ez in ezs:\n",
    "                    ezform = ''\n",
    "                    eztag = ''\n",
    "                    ezform = plurform + ez\n",
    "                    eztag = plurtag + ezs[ez]\n",
    "                    \n",
    "                    #forms.add((ezform, eztag))\n",
    "                    \n",
    "                    if ezform in corpus:\n",
    "                        addform(ezform, eztag, stem, pos)\n",
    "                    \n",
    "                \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    prons = pronsAIU\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    prons = pronsE\n",
    "                else:\n",
    "                    prons = pronsAll\n",
    "                \n",
    "                for pron in prons:\n",
    "                    pronform = ''\n",
    "                    prontag = ''\n",
    "                    pronform = plurform + pron\n",
    "                    prontag = plurtag + prons[pron]\n",
    "                    \n",
    "                    if pronform.endswith('ی') or pronform.endswith('و') or pronform.endswith('ا') or pronform.endswith('ه') or pronform.endswith('ة'):\n",
    "                        arts = artsAIUE\n",
    "                    else:\n",
    "                        arts = artsAll\n",
    "                \n",
    "                    for art in arts:\n",
    "                        artform = ''\n",
    "                        arttag = ''\n",
    "                        artform = pronform + art\n",
    "                        arttag = prontag + arts[art]\n",
    "                        \n",
    "                        if (artform.endswith('ه') or artform.endswith('ة')):\n",
    "                                cops = copsE\n",
    "                        else:\n",
    "                            cops = copsAll\n",
    "                                \n",
    "                        for cop in cops:\n",
    "                            copform = ''\n",
    "                            coptag = ''\n",
    "                            copform = artform + cop\n",
    "                            coptag = arttag + cops[cop]\n",
    "                        \n",
    "                        \n",
    "                            #if 'YEH' in arttag:\n",
    "                            for ke in kes:\n",
    "                                keform = ''\n",
    "                                ketag = ''\n",
    "                                keform = copform + ke\n",
    "                                ketag = coptag + kes[ke]\n",
    "\n",
    "                                #forms.add((keform, ketag))\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                if keform in corpus:\n",
    "                                    addform(keform, ketag, stem, pos)\n",
    "                        \n",
    "                        for ra in ras:\n",
    "                            raform = ''\n",
    "                            ratag = ''\n",
    "                            \n",
    "                            raform = artform + ra\n",
    "                            ratag = arttag + ras[ra]\n",
    "                            \n",
    "                            if raform in corpus:\n",
    "                                addform(raform, ratag, stem, pos)\n",
    "                                \n",
    "                            \n",
    "                        \n",
    "    #return Forms\n",
    "#w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n"
     ]
    }
   ],
   "source": [
    "#CorpusTagged2 = {}\n",
    "#CorpusTagged = {}\n",
    "arab = {}\n",
    "pos = 'N'\n",
    "k = 0\n",
    "\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "filename = 'arabplurals.txt'\n",
    "file = ''.join((path,filename))\n",
    "\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    #with open(path+'nforms_500', 'w', encoding='utf-8') as w:\n",
    "    for line in f:\n",
    "        #Forms = {}\n",
    "        sg, pl = line.strip('\\n').split('\\t')\n",
    "        if sg not in arab:\n",
    "            arab[sg] = set()\n",
    "            arab[sg].add(pl)\n",
    "        else:\n",
    "            arab[sg].add(pl)\n",
    "        k += 1\n",
    "        if k%100 == 0:\n",
    "            print(k)\n",
    "\n",
    "        #nounforms(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CorpusTagged2 = {}\n",
    "for word in arab:\n",
    "    nounformsArab(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52037"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CorpusTagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add function\n",
    "\n",
    "writeCorpusTagged(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11712"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(CorpusTagged2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "with open('TaggedWords_noun2.txt', 'w', encoding='utf-8') as w: \n",
    "    for form in sorted(CorpusTagged):\n",
    "        w.write(form)\n",
    "        w.write('\\tN\\t')\n",
    "        for lemma in CorpusTagged[form]['N']:\n",
    "            w.write(lemma)\n",
    "            w.write('+')\n",
    "            for tag in CorpusTagged[form]['N'][lemma]:\n",
    "                w.write(tag)\n",
    "                w.write('#')\n",
    "            w.write('@')\n",
    "        w.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Yay nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nouns1 = set()\n",
    "Nouns2 = set()\n",
    "\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\'\n",
    "filename = 'word-pos.txt'\n",
    "file = ''.join((path,filename))\n",
    "\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, pos = line.strip('\\n').split('#')\n",
    "        if pos == 'N':\n",
    "            Nouns2.add(word)\n",
    "            \n",
    "\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "filename = 'nouns.txt'\n",
    "file = ''.join((path,filename))\n",
    "\n",
    "with open(file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word = line.strip('\\n')\n",
    "        Nouns1.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38238"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Nouns1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38046"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Nouns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39170"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Nouns2 | Nouns1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yay = Nouns2 - Nouns1\n",
    "len(Nouns2 - Nouns1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yay2= set()\n",
    "for line in yay:\n",
    "    if '.'  in line:\n",
    "        continue\n",
    "    if '|' in line:\n",
    "        words = line.split('|')\n",
    "        for word in words:\n",
    "            yay2.add(word)\n",
    "    else:\n",
    "        yay2.add(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1405"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yay2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yay3 = yay2 - Nouns1\n",
    "len(yay3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38640"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allnouns = Nouns1 | yay3\n",
    "len(allnouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "filename = 'nouns_full.txt'\n",
    "file = ''.join((path,filename))\n",
    "\n",
    "with open(file, 'w', encoding='utf-8') as w:\n",
    "    for word in sorted(allnouns):\n",
    "        w.write(word)\n",
    "        w.write('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word in yay3:\n",
    "    nounforms(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52310"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CorpusTagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TaggedWords_noun3.txt', 'w', encoding='utf-8') as w: \n",
    "    for form in sorted(CorpusTagged):\n",
    "        w.write(form)\n",
    "        w.write('\\tN\\t')\n",
    "        for lemma in CorpusTagged[form]['N']:\n",
    "            w.write(lemma)\n",
    "            w.write('+')\n",
    "            for tag in CorpusTagged[form]['N'][lemma]:\n",
    "                w.write(tag)\n",
    "                w.write('#')\n",
    "            w.write('@')\n",
    "        w.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAG ADJECTIVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conj + prep + stem + plur + pron + art + cop + ke\n",
    "#conj + prep + stem + plur + pron + art + ra\n",
    "#conj + prep + stem + plur + ez\n",
    "\n",
    "#conj + prep + stem + COMP + pron + art + cop+ ke\n",
    "#conj + prep + stem + COMP + pron + art + ra\n",
    "#conj + prep + stem + COMP + ez\n",
    "\n",
    "conjs = {'و': 'CONJ ', '': ''}\n",
    "\n",
    "preps = {'اندر': 'PREP ', 'در': 'PREP ', 'بر': 'PREP ', 'ز': 'PREP ', 'ب': 'PREP ', 'از': 'PREP ', \n",
    "         u'\\u200c'+'به': 'PREP ', '': ''}\n",
    "\n",
    "#stems = set() #get from file\n",
    "\n",
    "#plur = ('ها', 'ان', 'جات', 'ات', 'گان', '')\n",
    "#plurs = {'ها': 'PL', 'ان': 'PL', 'ات': 'PL', '': 'SG'}\n",
    "plursE = {u'\\u200c'+'ها': 'PL', u'\\u200c'+'گان': 'PL', 'ات': 'PL', 'گان': 'PL', '': 'SG'}\n",
    "plursAll = {'ها': 'PL', 'ان': 'PL', '': 'SG', u'\\u200c'+'ها': 'PL'}\n",
    "\n",
    "\n",
    "comps = {'': 'POS', 'تر': 'COMP', 'ترین': 'SUP', u'\\u200c'+'تر': 'COMP', u'\\u200c'+'ترین': 'SUP'}\n",
    "\n",
    "\n",
    "\n",
    "# u'\\u200c' + pron\n",
    "# stem[:-1] + pron if stem.endswith('ه') or stem.endswith('ة') and plur in {'جات', 'ات', 'گان'}\n",
    "'''\n",
    "pronsAll = {'م': ' PRO1SG', 'ت': ' PRO2SG', 'ش': ' PRO3SG', 'مان': ' PRO1PL', \n",
    "         'تان': ' PRO2PL', 'شان': ' PRO3PL', '':'', u'\\u200c'+'م': ' PRO1SG', u'\\u200c'+'ت': ' PRO2SG', \n",
    "            u'\\u200c'+'ش': ' PRO3SG', u'\\u200c'+'مان': ' PRO1PL', \n",
    "         u'\\u200c'+'تان': ' PRO2PL', u'\\u200c'+'شان': ' PRO3PL'} \n",
    "pronsE = {u'\\u200c'+'ام': ' PRO1SG', u'\\u200c'+'ات': ' PRO2SG', u'\\u200c'+'اش': ' PRO3SG',\n",
    "          u'\\u200c'+'امان': ' PRO1PL', \n",
    "         u'\\u200c'+'اتان': ' PRO2PL', u'\\u200c'+'اشان': ' PRO3PL', '':'',\n",
    "         'م': ' PRO1SG', 'ت': ' PRO2SG', 'ش': ' PRO3SG', 'مان': ' PRO1PL', \n",
    "         'تان': ' PRO2PL', 'شان': ' PRO3PL', u'\\u200c'+'م': ' PRO1SG', u'\\u200c'+'ت': ' PRO2SG', \n",
    "            u'\\u200c'+'ش': ' PRO3SG', u'\\u200c'+'مان': ' PRO1PL', \n",
    "         u'\\u200c'+'تان': ' PRO2PL', u'\\u200c'+'شان': ' PRO3PL'\n",
    "         \n",
    "         }\n",
    "pronsAIU = {'یم': ' PRO1SG', 'یت': ' PRO2SG', 'یش': ' PRO3SG', 'یمان': ' PRO1PL', \n",
    "         'یتان': ' PRO2PL', 'یشان': ' PRO3PL', '':'',\n",
    "           'م': ' PRO1SG', 'ت': ' PRO2SG', 'ش': ' PRO3SG', 'مان': ' PRO1PL', \n",
    "         'تان': ' PRO2PL', 'شان': ' PRO3PL', u'\\u200c'+'م': ' PRO1SG', u'\\u200c'+'ت': ' PRO2SG', \n",
    "            u'\\u200c'+'ش': ' PRO3SG', u'\\u200c'+'مان': ' PRO1PL', \n",
    "         u'\\u200c'+'تان': ' PRO2PL', u'\\u200c'+'شان': ' PRO3PL'\n",
    "           \n",
    "           }\n",
    "'''\n",
    "# u'\\u200c' + pron\n",
    "# 'ا' + pron if stem.endswith('ه')\n",
    "# 'ی' + pron if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا')\n",
    "\n",
    "\n",
    "artsAll = {'ی':' YEH', '': ''}\n",
    "artsAIUE = {'یی': ' YEH', 'ئی': ' YEH', u'\\u200c'+'یی': ' YEH', u'\\u200c'+'ئی': ' YEH','': ''}\n",
    "# art = 'یی' if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# art = 'ئی' if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# u'\\u200c' + art\n",
    "\n",
    "ras = {'را': ' POSTP', '': ''}\n",
    "'''\n",
    "copsE = {u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': '',\n",
    "        \n",
    "          'ستم': ' COP1SG', 'ستی': ' COP2SG',  'ستیم': ' COP1PL', 'ستید': ' COP2PL',\n",
    "       'ستند': ' COP3PL', u'\\u200c'+'هستم': ' COP1SG', u'\\u200c'+'هستی': ' COP2SG', u'\\u200c'+'هست': ' COP3SG', \n",
    "         u'\\u200c'+'هستیم': ' COP1PL', u'\\u200c'+'هستید': ' COP2PL',\n",
    "       u'\\u200c'+'هستند': ' COP3PL', u'\\u200c'+'ستم': ' COP1SG', u'\\u200c'+'ستی': ' COP2SG',  \n",
    "         u'\\u200c'+'ستیم': ' COP1PL', u'\\u200c'+'ستید': ' COP2PL', u'\\u200c'+'ستند': ' COP3PL'\n",
    "        \n",
    "        }\n",
    "\n",
    "copsAll = {'م': ' COP1SG', 'ی': ' COP2SG', 'ست': ' COP3SG', 'یم': ' COP1PL', 'ید': ' COP2PL',\n",
    "       'ند': ' COP3PL', u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': '',\n",
    "          \n",
    "           'ستم': ' COP1SG', 'ستی': ' COP2SG',  'ستیم': ' COP1PL', 'ستید': ' COP2PL',\n",
    "       'ستند': ' COP3PL', u'\\u200c'+'هستم': ' COP1SG', u'\\u200c'+'هستی': ' COP2SG', u'\\u200c'+'هست': ' COP3SG', \n",
    "         u'\\u200c'+'هستیم': ' COP1PL', u'\\u200c'+'هستید': ' COP2PL',\n",
    "       u'\\u200c'+'هستند': ' COP3PL', u'\\u200c'+'ستم': ' COP1SG', u'\\u200c'+'ستی': ' COP2SG',  \n",
    "         u'\\u200c'+'ستیم': ' COP1PL', u'\\u200c'+'ستید': ' COP2PL', u'\\u200c'+'ستند': ' COP3PL'\n",
    "          \n",
    "          }\n",
    "'''\n",
    "# u'\\u200c' + cop\n",
    "# 'ا' + cop #if stem.endswith('ه')\n",
    "# u'\\u200c' + cop\n",
    "\n",
    "ezsAll = {'ی': ' EZ', '': ''}\n",
    "ezsE = {u'\\u200c'+'ی': ' EZ', '': ''}\n",
    "# if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "kes = {'که': ' CONJ', '':''}  #if gloss.endswith('YEH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "\n",
    "k = 0\n",
    "\n",
    "form = ''\n",
    "tag = ''\n",
    "\n",
    "#conj + prep + stem + plur + pron + art + cop + ke\n",
    "#conj + prep + stem + plur + pron + art + ra\n",
    "#conj + prep + stem + plur + ez\n",
    "\n",
    "#conj + prep + stem + COMP + pron + art + cop+ ke\n",
    "#conj + prep + stem + COMP + pron + art + ra\n",
    "#conj + prep + stem + COMP + ez\n",
    "\n",
    "pos = 'AJ'\n",
    "\n",
    "def adjforms(stem):\n",
    "    Forms = {}\n",
    "    pos = 'AJ'\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "    \n",
    "    for conj in conjs:\n",
    "        conjform = ''\n",
    "        conjtag = ''\n",
    "        conjform += conj\n",
    "        conjtag += conjs[conj]\n",
    "        \n",
    "        for prep in preps:\n",
    "            prepform = ''\n",
    "            preptag = ''\n",
    "            prepform = conjform + prep\n",
    "            preptag = conjtag + preps[prep]\n",
    "            \n",
    "            stemform = prepform + stem\n",
    "            \n",
    "            for comp in comps:\n",
    "                compform = ''\n",
    "                comptag = ''\n",
    "                \n",
    "                compform = stemform + comp\n",
    "                comptag = preptag + comps[comp]\n",
    "                \n",
    "                \n",
    "    \n",
    "                if compform.endswith('ی') or compform.endswith('و') or compform.endswith('ا'):\n",
    "                    ezs = ezsAll\n",
    "                elif (compform.endswith('ه') or compform.endswith('ة')):\n",
    "                    ezs = ezsE\n",
    "                else:\n",
    "                    ezs = {'':''}\n",
    "                # if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "                # u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "                for ez in ezs:\n",
    "                    ezform = ''\n",
    "                    eztag = ''\n",
    "                    ezform = compform + ez\n",
    "                    eztag = comptag + ezs[ez]\n",
    "                    \n",
    "                    #forms.add((ezform, eztag))\n",
    "                    \n",
    "                    if ezform in corpus:\n",
    "                        addform(ezform, eztag, stem, pos)\n",
    "                        \n",
    "                if compform.endswith('ی') or compform.endswith('و') or compform.endswith('ا'):\n",
    "                    prons = pronsAIU\n",
    "                elif (compform.endswith('ه') or compform.endswith('ة')):\n",
    "                    prons = pronsE\n",
    "                else:\n",
    "                    prons = pronsAll\n",
    "                \n",
    "                for pron in prons:\n",
    "                    pronform = ''\n",
    "                    prontag = ''\n",
    "                    pronform = compform + pron\n",
    "                    prontag = comptag + prons[pron]\n",
    "                    \n",
    "                    if pronform.endswith('ی') or pronform.endswith('و') or pronform.endswith('ا') or pronform.endswith('ه') or pronform.endswith('ة'):\n",
    "                        arts = artsAIUE\n",
    "                    else:\n",
    "                        arts = artsAll\n",
    "                \n",
    "                    for art in arts:\n",
    "                        artform = ''\n",
    "                        arttag = ''\n",
    "                        artform = pronform + art\n",
    "                        arttag = prontag + arts[art]\n",
    "                        \n",
    "                        if (artform.endswith('ه') or artform.endswith('ة')):\n",
    "                                cops = copsE\n",
    "                        else:\n",
    "                            cops = copsAll\n",
    "                                \n",
    "                        for cop in cops:\n",
    "                            copform = ''\n",
    "                            coptag = ''\n",
    "                            copform = artform + cop\n",
    "                            coptag = arttag + cops[cop]\n",
    "                        \n",
    "                        \n",
    "                            #if 'YEH' in arttag:\n",
    "                            for ke in kes:\n",
    "                                keform = ''\n",
    "                                ketag = ''\n",
    "                                keform = copform + ke\n",
    "                                ketag = coptag + kes[ke]\n",
    "\n",
    "                                #forms.add((keform, ketag))\n",
    "                                \n",
    "                                \n",
    "                                if keform in corpus:\n",
    "                                    addform(keform, ketag, stem, pos)\n",
    "                                   \n",
    "                        \n",
    "                        for ra in ras:\n",
    "                            raform = ''\n",
    "                            ratag = ''\n",
    "                            \n",
    "                            raform = artform + ra\n",
    "                            ratag = arttag + ras[ra]\n",
    "                            \n",
    "                            if raform in corpus:\n",
    "                                addform(raform, ratag, stem, pos)\n",
    "                                \n",
    "                                \n",
    "def addform(form, tag, stem, pos):\n",
    "    if form not in CorpusTagged:\n",
    "        CorpusTagged[form] = {pos: {}}\n",
    "        if stem not in CorpusTagged[form][pos]:\n",
    "            CorpusTagged[form][pos][stem] = {tag}\n",
    "        else:\n",
    "            CorpusTagged[form][pos][stem].add(tag)\n",
    "    else:\n",
    "        if pos not in CorpusTagged[form]:\n",
    "            CorpusTagged[form][pos] = {}\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag)\n",
    "        else:\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag)                            \n",
    "                        \n",
    "    #return Forms\n",
    "#w.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#stems = {'کتاب'}\n",
    "\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "#w = open(path+'Nforms.txt', 'w', encoding='utf-8')\n",
    "\n",
    "#forms = set()\n",
    "k = 0\n",
    "\n",
    "form = ''\n",
    "tag = ''\n",
    "\n",
    "#conj + prep + stem + plur + pron + art + cop + ke\n",
    "#conj + prep + stem + plur + pron + art + ra\n",
    "#conj + prep + stem + plur + ez\n",
    "\n",
    "#conj + prep + stem + COMP + pron + art + cop+ ke\n",
    "#conj + prep + stem + COMP + pron + art + ra\n",
    "#conj + prep + stem + COMP + ez\n",
    "\n",
    "pos = 'AJ'\n",
    "\n",
    "def adjforms3(stem):\n",
    "    Forms = {}\n",
    "    pos = 'AJ2'\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "    \n",
    "    for conj in conjs:\n",
    "        conjform = ''\n",
    "        conjtag = ''\n",
    "        conjform += conj\n",
    "        conjtag += conjs[conj]\n",
    "        \n",
    "        for prep in preps:\n",
    "            prepform = ''\n",
    "            preptag = ''\n",
    "            prepform = conjform + prep\n",
    "            preptag = conjtag + preps[prep]\n",
    "            \n",
    "            stemform = prepform + stem\n",
    "            \n",
    "            for comp in comps:\n",
    "                compform = ''\n",
    "                comptag = ''\n",
    "                \n",
    "                compform = stemform + comp\n",
    "                comptag = preptag + comps[comp]\n",
    "                \n",
    "                \n",
    "    \n",
    "                if compform.endswith('ی') or compform.endswith('و') or compform.endswith('ا'):\n",
    "                    ezs = ezsAll\n",
    "                elif (compform.endswith('ه') or compform.endswith('ة')):\n",
    "                    ezs = ezsE\n",
    "                else:\n",
    "                    ezs = {'':''}\n",
    "                # if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "                # u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "                for ez in ezs:\n",
    "                    ezform = ''\n",
    "                    eztag = ''\n",
    "                    ezform = compform + ez\n",
    "                    eztag = comptag + ezs[ez]\n",
    "                    \n",
    "                    #forms.add((ezform, eztag))\n",
    "                    \n",
    "                    if ezform in corpus:\n",
    "                        addform3(ezform, eztag, stem)\n",
    "                        '''\n",
    "                        if ezform not in CorpusTagged3:\n",
    "                            CorpusTagged3[ezform] = {pos: {}}\n",
    "                            if stem not in CorpusTagged3[ezform][pos]:\n",
    "                                CorpusTagged3[ezform][pos][stem] = {eztag}\n",
    "                            else:\n",
    "                                CorpusTagged3[ezform][pos][stem].add(eztag)\n",
    "                        else:\n",
    "                            if stem not in CorpusTagged3[ezform][pos]:\n",
    "                                CorpusTagged3[ezform][pos][stem] = {eztag}\n",
    "                            else:\n",
    "                                CorpusTagged3[ezform][pos][stem].add(eztag)\n",
    "                                \n",
    "                        '''\n",
    "                   \n",
    "                    \n",
    "                \n",
    "                if compform.endswith('ی') or compform.endswith('و') or compform.endswith('ا'):\n",
    "                    prons = pronsAIU\n",
    "                elif (compform.endswith('ه') or compform.endswith('ة')):\n",
    "                    prons = pronsE\n",
    "                else:\n",
    "                    prons = pronsAll\n",
    "                \n",
    "                for pron in prons:\n",
    "                    pronform = ''\n",
    "                    prontag = ''\n",
    "                    pronform = compform + pron\n",
    "                    prontag = comptag + prons[pron]\n",
    "                    \n",
    "                    if pronform.endswith('ی') or pronform.endswith('و') or pronform.endswith('ا') or pronform.endswith('ه') or pronform.endswith('ة'):\n",
    "                        arts = artsAIUE\n",
    "                    else:\n",
    "                        arts = artsAll\n",
    "                \n",
    "                    for art in arts:\n",
    "                        artform = ''\n",
    "                        arttag = ''\n",
    "                        artform = pronform + art\n",
    "                        arttag = prontag + arts[art]\n",
    "                        \n",
    "                        if (artform.endswith('ه') or artform.endswith('ة')):\n",
    "                                cops = copsE\n",
    "                        else:\n",
    "                            cops = copsAll\n",
    "                                \n",
    "                        for cop in cops:\n",
    "                            copform = ''\n",
    "                            coptag = ''\n",
    "                            copform = artform + cop\n",
    "                            coptag = arttag + cops[cop]\n",
    "                        \n",
    "                        \n",
    "                            #if 'YEH' in arttag:\n",
    "                            for ke in kes:\n",
    "                                keform = ''\n",
    "                                ketag = ''\n",
    "                                keform = copform + ke\n",
    "                                ketag = coptag + kes[ke]\n",
    "\n",
    "                                #forms.add((keform, ketag))\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                if keform in corpus:\n",
    "                                    addform3(keform, ketag, stem)\n",
    "                                    \n",
    "                                    '''\n",
    "                                    if keform not in CorpusTagged3:\n",
    "                                        CorpusTagged3[keform] = {pos: {}}\n",
    "                                        if stem not in CorpusTagged3[keform][pos]:\n",
    "                                            CorpusTagged3[keform][pos][stem] = {ketag}\n",
    "                                        else:\n",
    "                                            CorpusTagged3[keform][pos][stem].add(ketag)\n",
    "                                    else:\n",
    "                                        if pos not in CorpusTagged3[keform]:\n",
    "                                            CorpusTagged3[keform][pos] = {}\n",
    "                                            if stem not in CorpusTagged3[keform][pos]:\n",
    "                                                CorpusTagged3[keform][pos][stem] = {ketag}\n",
    "                                            else:\n",
    "                                                CorpusTagged3[keform][pos][stem].add(ketag)\n",
    "                                        else:\n",
    "                                            if stem not in CorpusTagged3[keform][pos]:\n",
    "                                                CorpusTagged3[keform][pos][stem] = {ketag}\n",
    "                                            else:\n",
    "                                                CorpusTagged3[keform][pos][stem].add(ketag)\n",
    "                                    '''\n",
    "                                    \n",
    "                        \n",
    "                        for ra in ras:\n",
    "                            raform = ''\n",
    "                            ratag = ''\n",
    "                            \n",
    "                            raform = artform + ra\n",
    "                            ratag = arttag + ras[ra]\n",
    "                            \n",
    "                            if raform in corpus:\n",
    "                                addform3(raform, ratag, stem)\n",
    "                            '''\n",
    "                                if raform not in CorpusTagged3:\n",
    "                                    CorpusTagged3[raform] = {pos: {}}\n",
    "                                    if stem not in CorpusTagged3[raform][pos]:\n",
    "                                        CorpusTagged3[raform][pos][stem] = {ratag}\n",
    "                                    else:\n",
    "                                        CorpusTagged3[raform][pos][stem].add(ratag)\n",
    "                                else:\n",
    "                                    if pos not in CorpusTagged3[raform]:\n",
    "                                        CorpusTagged3[raform][pos] = {}\n",
    "                                    else:\n",
    "                                        if stem not in CorpusTagged3[raform][pos]:\n",
    "                                            CorpusTagged3[raform][pos][stem] = {ratag}\n",
    "                                        else:\n",
    "                                            CorpusTagged3[raform][pos][stem].add(ratag)\n",
    "                            '''\n",
    "                                #forms.add((copform, coptag))\n",
    "                              \n",
    "                                \n",
    "                            \n",
    "def addform3(form, tag, stem):\n",
    "    if form not in CorpusTagged3:\n",
    "        CorpusTagged3[form] = {pos: {}}\n",
    "        if stem not in CorpusTagged3[form][pos]:\n",
    "            CorpusTagged3[form][pos][stem] = {tag}\n",
    "        else:\n",
    "            CorpusTagged3[form][pos][stem].add(tag)\n",
    "    else:\n",
    "        if pos not in CorpusTagged3[form]:\n",
    "            CorpusTagged3[form][pos] = {}\n",
    "            if stem not in CorpusTagged3[form][pos]:\n",
    "                CorpusTagged3[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged3[form][pos][stem].add(tag)\n",
    "        else:\n",
    "            if stem not in CorpusTagged3[form][pos]:\n",
    "                CorpusTagged3[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged3[form][pos][stem].add(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CorpusTagged3 = {}\n",
    "adjforms3('بزرگ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CorpusTagged3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'بزرگ': {'AJ': {'بزرگ': {'POS'}}, 'AJ2': {'بزرگ': {'POS'}}},\n",
       " 'بزرگت': {'AJ': {'بزرگ': {'POS PRO2SG'}}, 'AJ2': {'بزرگ': {'POS PRO2SG'}}},\n",
       " 'بزرگتر': {'AJ': {'بزرگ': {'COMP'}}, 'AJ2': {'بزرگ': {'COMP'}}},\n",
       " 'بزرگتری': {'AJ': {'بزرگ': {'COMP COP2SG', 'COMP YEH'}},\n",
       "  'AJ2': {'بزرگ': {'COMP COP2SG', 'COMP YEH'}}},\n",
       " 'بزرگست': {'AJ': {'بزرگ': {'POS COP3SG'}}, 'AJ2': {'بزرگ': {'POS COP3SG'}}},\n",
       " 'بزرگش': {'AJ': {'بزرگ': {'POS PRO3SG'}}, 'AJ2': {'بزرگ': {'POS PRO3SG'}}},\n",
       " 'بزرگم': {'AJ': {'بزرگ': {'POS COP1SG', 'POS PRO1SG'}},\n",
       "  'AJ2': {'بزرگ': {'POS COP1SG', 'POS PRO1SG'}}},\n",
       " 'بزرگند': {'AJ': {'بزرگ': {'POS COP3PL'}}, 'AJ2': {'بزرگ': {'POS COP3PL'}}},\n",
       " 'بزرگی': {'AJ': {'بزرگ': {'POS COP2SG', 'POS YEH'}},\n",
       "  'AJ2': {'بزرگ': {'POS COP2SG', 'POS YEH'}}},\n",
       " 'بزرگیست': {'AJ': {'بزرگ': {'POS YEH COP3SG'}},\n",
       "  'AJ2': {'بزرگ': {'POS YEH COP3SG'}}},\n",
       " 'بزرگیم': {'AJ': {'بزرگ': {'POS COP1PL', 'POS YEH COP1SG'}},\n",
       "  'AJ2': {'بزرگ': {'POS COP1PL', 'POS YEH COP1SG'}}},\n",
       " 'بزرگیی': {'AJ': {'بزرگ': {'POS YEH COP2SG'}},\n",
       "  'AJ2': {'بزرگ': {'POS YEH COP2SG'}}},\n",
       " 'بزرگ\\u200cتر': {'AJ': {'بزرگ': {'COMP'}}, 'AJ2': {'بزرگ': {'COMP'}}},\n",
       " 'وبزرگی': {'AJ': {'بزرگ': {'CONJ POS COP2SG', 'CONJ POS YEH'}},\n",
       "  'AJ2': {'بزرگ': {'CONJ POS COP2SG', 'CONJ POS YEH'}}}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CorpusTagged3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\'\n",
    "CorpusTagged = {}\n",
    "with open(path+'word-ADJ_PARTC.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        k += 1\n",
    "        if k%100 == 0:\n",
    "            print(k)\n",
    "        word = line.strip('\\n')\n",
    "        adjforms(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59183"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CorpusTagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeCorpusTagged(filename):\n",
    "    filepath = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "    with open(filepath+filename, 'w', encoding='utf-8') as w:\n",
    "        for form in sorted(CorpusTagged):\n",
    "            w.write(form+'\\t')\n",
    "            npos = 0\n",
    "            for pos in CorpusTagged[form]:\n",
    "                npos += 1\n",
    "                if npos == 1:\n",
    "                    w.write(pos+'$')\n",
    "                else:\n",
    "                    w.write('&' + pos+'$')\n",
    "                nlem = 0\n",
    "                for lemma in CorpusTagged[form][pos]:\n",
    "                    nlem+=1\n",
    "                    if nlem == 1:\n",
    "                        w.write(lemma)\n",
    "                        w.write('+')\n",
    "                    else:\n",
    "                        w.write('*')\n",
    "                        w.write(lemma)\n",
    "                        w.write('+')\n",
    "                    ntag = 0\n",
    "                    for tag in CorpusTagged[form][pos][lemma]:\n",
    "                        ntag += 1\n",
    "                        w.write(tag)\n",
    "                        if ntag != len(CorpusTagged[form][pos][lemma])\n",
    "                            w.write('#')\n",
    "                    #w.write('@')\n",
    "            w.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add function\n",
    "filename = 'adjs_tagged_new.txt'\n",
    "writeCorpusTagged(filename)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with open('TaggedWords_n-aj1.txt', 'w', encoding='utf-8') as w: \n",
    "    for form in sorted(CorpusTagged):\n",
    "        w.write(form+'\\t')\n",
    "        for pos in CorpusTagged[form]:\n",
    "            w.write(pos+'$')\n",
    "            for lemma in CorpusTagged[form][pos]:\n",
    "                w.write(lemma)\n",
    "                w.write('+')\n",
    "                for tag in CorpusTagged[form][pos][lemma]:\n",
    "                    w.write(tag)\n",
    "                    w.write('#')\n",
    "                #w.write('@')\n",
    "        w.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AJ': {'': {'POS PRO3SG COP3SG'}},\n",
       " 'N': {'': {'SG PRO3SG COP3SG'},\n",
       "  'شأن': {'PL COP3SG'},\n",
       "  'شست': {'SG'},\n",
       "  'ناشنوائیان': {'PL PRO3SG COP3SG'}}}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CorpusTagged['شست']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAG ADVERBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PRES conj + (pref) + na mi be + present + termPres + pron\n",
    "IMP conj + (pref) + na mi be + present + (i, id) +pron\n",
    "IRREAL conj + (pref) + na mi be + present + termPres + (i, id) +pron\n",
    "PAST conj + na mi be + past + termPast\n",
    "PERF conj + na mi be + past + termPP + termPerf+ pron\n",
    "PERF2 conj + na mi be + past + termPP + termPerf2+ pron\n",
    "IRREALPAST conj + (pref) + na mi be + past + termPast + (i, id) +pron\n",
    "PP conj + na mi be + past + termPP+ pron\n",
    "INF conj + na mi be + past + termINF+ pron\n",
    "\n",
    "conjs = {'و': 'CONJ', '': ''}\n",
    "nas = {'': 'POS', 'ن': 'NEG', u'\\u200c'+'نه': 'NEG', 'م':'NEG'}\n",
    "mis = {'': '', 'می': 'MI', 'همی':'MI', u'\\u200c'+'می': 'MI', u'\\u200c'+'همی':'MI'}\n",
    "be = {'':'', 'ب':'BE', u'\\u200c'+'به':'BE'}\n",
    "\n",
    "pres = verbs[past]\n",
    "\n",
    "termPres = {'م':'1SG', 'ی': '2SG', 'د':'3SG', 'یم': '1PL', 'ید':'2PL', 'ند': '3PL'}\n",
    "termPresAIU = {'یم':'1SG', 'یی': '2SG', 'ید':'3SG', 'ییم': '1PL', 'یید':'2PL', 'یند': '3PL'}\n",
    "\n",
    "termPast = {'م':'1SG', 'ی': '2SG', '':'3SG', 'یم': '1PL', 'ید':'2PL', 'ند': '3PL'}\n",
    "#termPresAIU = {'یم':'1SG', 'یی': '2SG', 'ید':'3SG', 'ییم': '1PL', 'یید':'2PL', 'یند': '3PL'}\n",
    "\n",
    "termPerf = {u'\\u200c'+'ام': ' 1SG PERF', u'\\u200c'+'ای': ' 2SG PERF', u'\\u200c'+'ست': ' 3SG PERF', \n",
    "         u'\\u200c'+'ایم': ' 1PL PERF', u'\\u200c'+'اید': ' 2PL PERF',u'\\u200c'+'است': ' 3SG PERF',\n",
    "       u'\\u200c'+'اند': ' 3PL PERF',  u'\\u200c'+'ئی': ' 2SG PERF'}\n",
    "\n",
    "termPerf2 = {u'\\u200c'+'استم': ' 1SG PERF2',u'\\u200c'+'ستم': ' 1SG PERF2', u'\\u200c'+'استی': ' 2SG PERF2', \n",
    "             u'\\u200c'+'ستی': ' 2SG PERF2',u'\\u200c'+'استیم': ' 1PL PERF2',u'\\u200c'+'ستیم': ' 1PL PERF2',\n",
    "             u'\\u200c'+'ستید': ' 2PL PERF2', u'\\u200c'+'استید': ' 2PL PERF2',\n",
    "       u'\\u200c'+'ستند': ' 3PL PERF2', u'\\u200c'+'استند': ' 3PL PERF2'}\n",
    "\n",
    "‌ستم\n",
    "\n",
    "شوریده‌ئیست\n",
    "شوریده‌ایست\n",
    "\n",
    "ازین\n",
    "رشته‌ایست\n",
    "\n",
    "copsAll = {'م': ' COP1SG', 'ی': ' COP2SG', 'ست': ' COP3SG', 'یم': ' COP1PL', 'ید': ' COP2PL',\n",
    "       'ند': ' COP3PL', u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': ''}\n",
    "\n",
    "comps = {'': 'POS', 'تر': 'COMP', 'ترین': 'SUP', u'\\u200c'+'تر': 'COMP', u'\\u200c'+'ترین': 'SUP'}\n",
    "\n",
    "\n",
    "\n",
    "# u'\\u200c' + pron\n",
    "# stem[:-1] + pron if stem.endswith('ه') or stem.endswith('ة') and plur in {'جات', 'ات', 'گان'}\n",
    "\n",
    "pronsAll = {'م': ' PRO1SG', 'ت': ' PRO2SG', 'ش': ' PRO3SG', 'مان': ' PRO1PL', \n",
    "         'تان': ' PRO2PL', 'شان': ' PRO3PL', '':'', u'\\u200c'+'م': ' PRO1SG', u'\\u200c'+'ت': ' PRO2SG', \n",
    "            u'\\u200c'+'ش': ' PRO3SG', u'\\u200c'+'مان': ' PRO1PL', \n",
    "         u'\\u200c'+'تان': ' PRO2PL', u'\\u200c'+'شان': ' PRO3PL'} \n",
    "pronsE = {u'\\u200c'+'ام': ' PRO1SG', u'\\u200c'+'ات': ' PRO2SG', u'\\u200c'+'اش': ' PRO3SG',\n",
    "          u'\\u200c'+'امان': ' PRO1PL', \n",
    "         u'\\u200c'+'اتان': ' PRO2PL', u'\\u200c'+'اشان': ' PRO3PL', '':''}\n",
    "pronsAIU = {'یم': ' PRO1SG', 'یت': ' PRO2SG', 'یش': ' PRO3SG', 'یمان': ' PRO1PL', \n",
    "         'یتان': ' PRO2PL', 'یشان': ' PRO3PL', '':''}\n",
    "\n",
    "# u'\\u200c' + pron\n",
    "# 'ا' + pron if stem.endswith('ه')\n",
    "# 'ی' + pron if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا')\n",
    "\n",
    "\n",
    "artsAll = {'ی':' YEH', '': ''}\n",
    "artsAIUE = {'یی': ' YEH', 'ئی': ' YEH', u'\\u200c'+'یی': ' YEH', u'\\u200c'+'ئی': ' YEH','': ''}\n",
    "# art = 'یی' if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# art = 'ئی' if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# u'\\u200c' + art\n",
    "\n",
    "ras = {'را': ' POSTP', '': ''}\n",
    "\n",
    "\n",
    "copsE = {u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': ''}\n",
    "\n",
    "copsAll = {'م': ' COP1SG', 'ی': ' COP2SG', 'ست': ' COP3SG', 'یم': ' COP1PL', 'ید': ' COP2PL',\n",
    "       'ند': ' COP3PL', u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': ''}\n",
    "# u'\\u200c' + cop\n",
    "# 'ا' + cop #if stem.endswith('ه')\n",
    "# u'\\u200c' + cop\n",
    "\n",
    "ezsAll = {'ی': ' EZ', '': ''}\n",
    "ezsE = {u'\\u200c'+'ی': ' EZ', '': ''}\n",
    "# if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "kes = {'که': ' CONJ', '':''}  #if gloss.endswith('YEH')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
