{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = {u'\\u064B', u'\\u064E', u'\\u064F', u'\\u0650', u'\\u0651', u'\\u0652',\n",
    "         u'\\u0653', u'\\u0654', u'\\u0655', 'ء', u'\\u0674'}\n",
    "replace = {u'\\u0629':'ه', 'ة':'ه', u'\\u0676': 'و', u'\\u0678': 'ی', u'\\u0672': 'ا',\n",
    "           u'\\u0624': 'و', u'\\u0626': 'ی', u'\\u0623': 'ا', u'\\u0625': 'ا'}\n",
    "\n",
    "def clean(word):\n",
    "    newword = ''\n",
    "    for char in word:\n",
    "        newchar = char\n",
    "        if char in chars:\n",
    "            continue\n",
    "        elif char in replace:\n",
    "            newchar = replace[char]\n",
    "        newword += newchar\n",
    "    return newword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "موبدا\n",
      "متعاقب\n"
     ]
    }
   ],
   "source": [
    "print(clean('مؤبداً'))\n",
    "print(clean('متعاقبِ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\rubinchik\\\\'\n",
    "filename = 'word-pos-unchange.txt'\n",
    "inputfile = ''.join((path,filename))\n",
    "\n",
    "adverbs = set() #ADV\n",
    "intjs = set() #INT\n",
    "partcs = set() #PARTC\n",
    "prons = set() #PRO\n",
    "conjs = set() #CON\n",
    "preps = set() #P\n",
    "nums = set() #NUM\n",
    "rest = set()\n",
    "#NOM\n",
    "#PS\n",
    "#VVOD\n",
    "\n",
    "with open(inputfile, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, pos = line.strip('\\n').split('#')\n",
    "        wordclean = clean(word)\n",
    "        if pos == 'ADV':\n",
    "            adverbs.add(word)\n",
    "            adverbs.add(wordclean)\n",
    "        elif pos == 'INT':\n",
    "            intjs.add(word)\n",
    "            intjs.add(wordclean)\n",
    "        elif pos == 'PARTC':\n",
    "            partcs.add(word)\n",
    "            partcs.add(wordclean)\n",
    "        elif pos == 'PRO':\n",
    "            prons.add(word)\n",
    "            prons.add(wordclean)\n",
    "        elif pos == 'CON':\n",
    "            conjs.add(word)\n",
    "            conjs.add(wordclean)\n",
    "        elif pos == 'P':\n",
    "            preps.add(word)\n",
    "            preps.add(wordclean)\n",
    "        elif pos == 'NUM':\n",
    "            nums.add(word)\n",
    "            nums.add(wordclean)\n",
    "        else:\n",
    "            rest.add(word)\n",
    "            rest.add(wordclean)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = set()\n",
    "corpusfile = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\collect\\\\corpus_doc2\\\\wordlist.txt'\n",
    "with open(corpusfile, 'r', encoding='utf-8') as c:\n",
    "    for line in c:\n",
    "        word = line.strip('\\n')\n",
    "        corpus.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conjs = {'و': 'CONJ ', '': ''}\n",
    "\n",
    "preps = {'اندر': 'PREP ', 'در': 'PREP ', 'بر': 'PREP ', 'ز': 'PREP ', 'ب': 'PREP ', 'از': 'PREP ', \n",
    "         u'\\u200c'+'به': 'PREP ', '': ''}\n",
    "\n",
    "#stems = set() #get from file\n",
    "\n",
    "#plur = ('ها', 'ان', 'جات', 'ات', 'گان', '')\n",
    "#plurs = {'ها': 'PL', 'ان': 'PL', 'ات': 'PL', '': 'SG'}\n",
    "plursE = {u'\\u200c'+'ها': 'PL', u'\\u200c'+'گان': 'PL', 'ات': 'PL', 'گان': 'PL', '': 'SG'}\n",
    "plursAll = {'ها': 'PL', 'ان': 'PL', '': 'SG', u'\\u200c'+'ها': 'PL'}\n",
    "\n",
    "\n",
    "comps = {'': 'POS', 'تر': 'COMP', 'ترین': 'SUP', u'\\u200c'+'تر': 'COMP', u'\\u200c'+'ترین': 'SUP'}\n",
    "\n",
    "\n",
    "\n",
    "# u'\\u200c' + pron\n",
    "# stem[:-1] + pron if stem.endswith('ه') or stem.endswith('ة') and plur in {'جات', 'ات', 'گان'}\n",
    "\n",
    "pronsAll = {'م': ' PRO1SG', 'ت': ' PRO2SG', 'ش': ' PRO3SG', 'مان': ' PRO1PL', \n",
    "         'تان': ' PRO2PL', 'شان': ' PRO3PL', '':'', u'\\u200c'+'م': ' PRO1SG', u'\\u200c'+'ت': ' PRO2SG', \n",
    "            u'\\u200c'+'ش': ' PRO3SG', u'\\u200c'+'مان': ' PRO1PL', \n",
    "         u'\\u200c'+'تان': ' PRO2PL', u'\\u200c'+'شان': ' PRO3PL'} \n",
    "pronsE = {u'\\u200c'+'ام': ' PRO1SG', u'\\u200c'+'ات': ' PRO2SG', u'\\u200c'+'اش': ' PRO3SG',\n",
    "          u'\\u200c'+'امان': ' PRO1PL', \n",
    "         u'\\u200c'+'اتان': ' PRO2PL', u'\\u200c'+'اشان': ' PRO3PL', '':'',\n",
    "         'م': ' PRO1SG', 'ت': ' PRO2SG', 'ش': ' PRO3SG', 'مان': ' PRO1PL', \n",
    "         'تان': ' PRO2PL', 'شان': ' PRO3PL', u'\\u200c'+'م': ' PRO1SG', u'\\u200c'+'ت': ' PRO2SG', \n",
    "            u'\\u200c'+'ش': ' PRO3SG', u'\\u200c'+'مان': ' PRO1PL', \n",
    "         u'\\u200c'+'تان': ' PRO2PL', u'\\u200c'+'شان': ' PRO3PL'\n",
    "         \n",
    "         }\n",
    "pronsAIU = {'یم': ' PRO1SG', 'یت': ' PRO2SG', 'یش': ' PRO3SG', 'یمان': ' PRO1PL', \n",
    "         'یتان': ' PRO2PL', 'یشان': ' PRO3PL', '':'',\n",
    "           'م': ' PRO1SG', 'ت': ' PRO2SG', 'ش': ' PRO3SG', 'مان': ' PRO1PL', \n",
    "         'تان': ' PRO2PL', 'شان': ' PRO3PL', u'\\u200c'+'م': ' PRO1SG', u'\\u200c'+'ت': ' PRO2SG', \n",
    "            u'\\u200c'+'ش': ' PRO3SG', u'\\u200c'+'مان': ' PRO1PL', \n",
    "         u'\\u200c'+'تان': ' PRO2PL', u'\\u200c'+'شان': ' PRO3PL'\n",
    "           \n",
    "           }\n",
    "\n",
    "# u'\\u200c' + pron\n",
    "# 'ا' + pron if stem.endswith('ه')\n",
    "# 'ی' + pron if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا')\n",
    "\n",
    "\n",
    "artsAll = {'ی':' YEH', '': ''}\n",
    "artsAIUE = {'یی': ' YEH', 'ئی': ' YEH', u'\\u200c'+'یی': ' YEH', u'\\u200c'+'ئی': ' YEH','': ''}\n",
    "# art = 'یی' if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# art = 'ئی' if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# u'\\u200c' + art\n",
    "\n",
    "ras = {'را': ' POSTP', '': ''}\n",
    "\n",
    "\n",
    "copsE = {u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': '',\n",
    "        \n",
    "          'ستم': ' COP1SG', 'ستی': ' COP2SG',  'ستیم': ' COP1PL', 'ستید': ' COP2PL',\n",
    "       'ستند': ' COP3PL', u'\\u200c'+'هستم': ' COP1SG', u'\\u200c'+'هستی': ' COP2SG', u'\\u200c'+'هست': ' COP3SG', \n",
    "         u'\\u200c'+'هستیم': ' COP1PL', u'\\u200c'+'هستید': ' COP2PL',\n",
    "       u'\\u200c'+'هستند': ' COP3PL', u'\\u200c'+'ستم': ' COP1SG', u'\\u200c'+'ستی': ' COP2SG',  \n",
    "         u'\\u200c'+'ستیم': ' COP1PL', u'\\u200c'+'ستید': ' COP2PL', u'\\u200c'+'ستند': ' COP3PL'\n",
    "        \n",
    "        }\n",
    "\n",
    "copsAll = {'م': ' COP1SG', 'ی': ' COP2SG', 'ست': ' COP3SG', 'یم': ' COP1PL', 'ید': ' COP2PL',\n",
    "       'ند': ' COP3PL', u'\\u200c'+'ام': ' COP1SG', u'\\u200c'+'ای': ' COP2SG', u'\\u200c'+'ست': ' COP3SG', \n",
    "         u'\\u200c'+'ایم': ' COP1PL', u'\\u200c'+'اید': ' COP2PL',u'\\u200c'+'است': ' COP3SG',\n",
    "       u'\\u200c'+'اند': ' COP3PL', u'\\u200c'+'م': ' COP1SG', u'\\u200c'+'ی': ' COP2SG',  \n",
    "         u'\\u200c'+'یم': ' COP1PL', u'\\u200c'+'ید': ' COP2PL', u'\\u200c'+'ند': ' COP3PL', '': '',\n",
    "          \n",
    "           'ستم': ' COP1SG', 'ستی': ' COP2SG',  'ستیم': ' COP1PL', 'ستید': ' COP2PL',\n",
    "       'ستند': ' COP3PL', u'\\u200c'+'هستم': ' COP1SG', u'\\u200c'+'هستی': ' COP2SG', u'\\u200c'+'هست': ' COP3SG', \n",
    "         u'\\u200c'+'هستیم': ' COP1PL', u'\\u200c'+'هستید': ' COP2PL',\n",
    "       u'\\u200c'+'هستند': ' COP3PL', u'\\u200c'+'ستم': ' COP1SG', u'\\u200c'+'ستی': ' COP2SG',  \n",
    "         u'\\u200c'+'ستیم': ' COP1PL', u'\\u200c'+'ستید': ' COP2PL', u'\\u200c'+'ستند': ' COP3PL'\n",
    "          \n",
    "          \n",
    "          }\n",
    "# u'\\u200c' + cop\n",
    "# 'ا' + cop #if stem.endswith('ه')\n",
    "# u'\\u200c' + cop\n",
    "\n",
    "ezsAll = {'ی': ' EZ', '': ''}\n",
    "ezsE = {u'\\u200c'+'ی': ' EZ', '': ''}\n",
    "# if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "# u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "kes = {'که': ' CONJ', '':''}  #if gloss.endswith('YEH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#conj + prep + stem + cop\n",
    "\n",
    "pos = 'ADV'\n",
    "\n",
    "def advforms(stem):\n",
    "    Forms = {}\n",
    "    pos = 'ADV'\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "    \n",
    "    for conj in conjs:\n",
    "        conjform = ''\n",
    "        conjtag = ''\n",
    "        conjform += conj\n",
    "        conjtag += conjs[conj]\n",
    "        \n",
    "        for prep in preps:\n",
    "            prepform = ''\n",
    "            preptag = ''\n",
    "            prepform = conjform + prep\n",
    "            preptag = conjtag + preps[prep]\n",
    "            \n",
    "            stemform = prepform + stem\n",
    "            \n",
    "                        \n",
    "            if (stemform.endswith('ه') or stemform.endswith('ة')):\n",
    "                cops = copsE\n",
    "            else:\n",
    "                cops = copsAll\n",
    "\n",
    "            for cop in cops:\n",
    "                copform = ''\n",
    "                coptag = ''\n",
    "                copform = stemform + cop\n",
    "                coptag = preptag + cops[cop]\n",
    "\n",
    "                if copform in corpus:\n",
    "                    addform(copform, coptag, stem)\n",
    "                        \n",
    "                        \n",
    "                                                         \n",
    "def addform(form, tag, stem):\n",
    "    if form not in CorpusTagged:\n",
    "        CorpusTagged[form] = {pos: {}}\n",
    "        if stem not in CorpusTagged[form][pos]:\n",
    "            CorpusTagged[form][pos][stem] = {tag}\n",
    "        else:\n",
    "            CorpusTagged[form][pos][stem].add(tag)\n",
    "    else:\n",
    "        if pos not in CorpusTagged[form]:\n",
    "            CorpusTagged[form][pos] = {}\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag)\n",
    "        else:\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag)                            \n",
    "                        \n",
    "    #return Forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CorpusTagged = {}\n",
    "for word in adverbs:\n",
    "    advforms(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2573"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CorpusTagged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate prepositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conj + stem + pron\n",
    "\n",
    "\n",
    "pos = 'P'\n",
    "\n",
    "def prepforms(stem):\n",
    "    Forms = {}\n",
    "    pos = 'P'\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "    \n",
    "    for conj in conjs:\n",
    "        conjform = ''\n",
    "        conjtag = ''\n",
    "        conjform += conj\n",
    "        conjtag += conjs[conj]\n",
    "        \n",
    "        \n",
    "            \n",
    "        stemform = conjform + stem\n",
    "            \n",
    "        if stemform.endswith('ی') or stemform.endswith('و') or stemform.endswith('ا'):\n",
    "            prons = pronsAIU\n",
    "        elif (stemform.endswith('ه') or stemform.endswith('ة')):\n",
    "            prons = pronsE\n",
    "        else:\n",
    "            prons = pronsAll\n",
    "\n",
    "        for pron in prons:\n",
    "            pronform = ''\n",
    "            prontag = ''\n",
    "            pronform = stemform + pron\n",
    "            prontag = conjtag + prons[pron]             \n",
    "            \n",
    "\n",
    "            if pronform in corpus:\n",
    "                addform(pronform, prontag, stem)\n",
    "                        \n",
    "                        \n",
    "                                                         \n",
    "def addform(form, tag, stem):\n",
    "    if form not in CorpusTagged:\n",
    "        CorpusTagged[form] = {pos: {}}\n",
    "        if stem not in CorpusTagged[form][pos]:\n",
    "            CorpusTagged[form][pos][stem] = {tag}\n",
    "        else:\n",
    "            CorpusTagged[form][pos][stem].add(tag)\n",
    "    else:\n",
    "        if pos not in CorpusTagged[form]:\n",
    "            CorpusTagged[form][pos] = {}\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag)\n",
    "        else:\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag)                            \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for word in preps:\n",
    "    prepforms(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2626"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CorpusTagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate interjections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stem + pron\n",
    "\n",
    "pos = 'INT'\n",
    "\n",
    "def intforms(stem):\n",
    "    Forms = {}\n",
    "    pos = 'INT'\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "  \n",
    "    stemform = stem\n",
    "    stemtag = ''\n",
    "\n",
    "    if stemform.endswith('ی') or stemform.endswith('و') or stemform.endswith('ا'):\n",
    "        prons = pronsAIU\n",
    "    elif (stemform.endswith('ه') or stemform.endswith('ة')):\n",
    "        prons = pronsE\n",
    "    else:\n",
    "        prons = pronsAll\n",
    "\n",
    "    for pron in prons:\n",
    "        pronform = ''\n",
    "        prontag = ''\n",
    "        pronform = stemform + pron\n",
    "        prontag = stemtag + prons[pron]             \n",
    "\n",
    "\n",
    "        if pronform in corpus:\n",
    "            addform(pronform, prontag, stem)\n",
    "                        \n",
    "                        \n",
    "                                                         \n",
    "def addform(form, tag, stem):\n",
    "    if form not in CorpusTagged:\n",
    "        CorpusTagged[form] = {pos: {}}\n",
    "        if stem not in CorpusTagged[form][pos]:\n",
    "            CorpusTagged[form][pos][stem] = {tag}\n",
    "        else:\n",
    "            CorpusTagged[form][pos][stem].add(tag)\n",
    "    else:\n",
    "        if pos not in CorpusTagged[form]:\n",
    "            CorpusTagged[form][pos] = {}\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag)\n",
    "        else:\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for word in intjs:\n",
    "    intforms(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CorpusTagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conj + prep + stem + (plur) + pron + art + cop+ ke\n",
    "#conj + prep + stem + (plur) + pron + art + ra\n",
    "#conj + prep + stem + (plur) + ez\n",
    "\n",
    "pos = 'PRO'\n",
    "\n",
    "def pronforms(stem):\n",
    "    Forms = {}\n",
    "    pos = 'PRO'\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "    \n",
    "    for conj in conjs:\n",
    "        conjform = ''\n",
    "        conjtag = ''\n",
    "        conjform += conj\n",
    "        conjtag += conjs[conj]\n",
    "        \n",
    "        for prep in preps:\n",
    "            prepform = ''\n",
    "            preptag = ''\n",
    "            prepform = conjform + prep\n",
    "            preptag = conjtag + preps[prep]\n",
    "            \n",
    "            stemform = prepform + stem\n",
    "            \n",
    "            if (stemform.endswith('ه') or stemform.endswith('ة')):\n",
    "                plurs = plursE\n",
    "            else:\n",
    "                plurs = plursAll\n",
    "                \n",
    "            for plur in plurs:\n",
    "                \n",
    "                plurform = ''\n",
    "                plurtag = ''\n",
    "                \n",
    "                plurstemform = stemform\n",
    "                if plur == 'ات' or plur == 'گان':\n",
    "                    plurstemform = stemform[:-1]\n",
    "                \n",
    "                plurform = plurstemform + plur\n",
    "                plurtag = preptag + plurs[plur]\n",
    "                \n",
    "    \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    ezs = ezsAll\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    ezs = ezsE\n",
    "                else:\n",
    "                    ezs = {'':''}\n",
    "                # if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "                # u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "                for ez in ezs:\n",
    "                    ezform = ''\n",
    "                    eztag = ''\n",
    "                    ezform = plurform + ez\n",
    "                    eztag = plurtag + ezs[ez]\n",
    "                    \n",
    "                    #forms.add((ezform, eztag))\n",
    "                    \n",
    "                    if ezform in corpus:\n",
    "                        addform(ezform, eztag, stem)\n",
    "                    \n",
    "                \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    prons = pronsAIU\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    prons = pronsE\n",
    "                else:\n",
    "                    prons = pronsAll\n",
    "                \n",
    "                for pron in prons:\n",
    "                    pronform = ''\n",
    "                    prontag = ''\n",
    "                    pronform = plurform + pron\n",
    "                    prontag = plurtag + prons[pron]\n",
    "                    \n",
    "                    if pronform.endswith('ی') or pronform.endswith('و') or pronform.endswith('ا') or pronform.endswith('ه') or pronform.endswith('ة'):\n",
    "                        arts = artsAIUE\n",
    "                    else:\n",
    "                        arts = artsAll\n",
    "                \n",
    "                    for art in arts:\n",
    "                        artform = ''\n",
    "                        arttag = ''\n",
    "                        artform = pronform + art\n",
    "                        arttag = prontag + arts[art]\n",
    "                        \n",
    "                        if (artform.endswith('ه') or artform.endswith('ة')):\n",
    "                                cops = copsE\n",
    "                        else:\n",
    "                            cops = copsAll\n",
    "                                \n",
    "                        for cop in cops:\n",
    "                            copform = ''\n",
    "                            coptag = ''\n",
    "                            copform = artform + cop\n",
    "                            coptag = arttag + cops[cop]\n",
    "                        \n",
    "                        \n",
    "                            #if 'YEH' in arttag:\n",
    "                            for ke in kes:\n",
    "                                keform = ''\n",
    "                                ketag = ''\n",
    "                                keform = copform + ke\n",
    "                                ketag = coptag + kes[ke]\n",
    "\n",
    "                                \n",
    "                                if keform in corpus:\n",
    "                                    addform(keform, ketag, stem)\n",
    "                               \n",
    "                        \n",
    "                        for ra in ras:\n",
    "                            raform = ''\n",
    "                            ratag = ''\n",
    "                            \n",
    "                            raform = artform + ra\n",
    "                            ratag = arttag + ras[ra]\n",
    "                            \n",
    "                            if raform in corpus:\n",
    "                                addform(raform, ratag, stem)\n",
    "                                \n",
    "                                \n",
    "def addform(form, tag, stem):\n",
    "    if form not in CorpusTagged:\n",
    "        CorpusTagged[form] = {pos: {}}\n",
    "        if stem not in CorpusTagged[form][pos]:\n",
    "            CorpusTagged[form][pos][stem] = {tag}\n",
    "        else:\n",
    "            CorpusTagged[form][pos][stem].add(tag)\n",
    "    else:\n",
    "        if pos not in CorpusTagged[form]:\n",
    "            CorpusTagged[form][pos] = {}\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag)\n",
    "        else:\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for word in prons:\n",
    "    pronforms(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3639"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CorpusTagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate conjunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stem + pron\n",
    "\n",
    "pos = 'CONJ'\n",
    "\n",
    "def conjforms(stem):\n",
    "    Forms = {}\n",
    "    pos = 'CONJ'\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "  \n",
    "    stemform = stem\n",
    "    stemtag = ''\n",
    "\n",
    "    if stemform.endswith('ی') or stemform.endswith('و') or stemform.endswith('ا'):\n",
    "        prons = pronsAIU\n",
    "    elif (stemform.endswith('ه') or stemform.endswith('ة')):\n",
    "        prons = pronsE\n",
    "    else:\n",
    "        prons = pronsAll\n",
    "\n",
    "    for pron in prons:\n",
    "        pronform = ''\n",
    "        prontag = ''\n",
    "        pronform = stemform + pron\n",
    "        prontag = stemtag + prons[pron]             \n",
    "\n",
    "\n",
    "        if pronform in corpus:\n",
    "            addform(pronform, prontag, stem)\n",
    "                        \n",
    "                        \n",
    "                                                         \n",
    "def addform(form, tag, stem):\n",
    "    if form not in CorpusTagged:\n",
    "        CorpusTagged[form] = {pos: {}}\n",
    "        if stem not in CorpusTagged[form][pos]:\n",
    "            CorpusTagged[form][pos][stem] = {tag}\n",
    "        else:\n",
    "            CorpusTagged[form][pos][stem].add(tag)\n",
    "    else:\n",
    "        if pos not in CorpusTagged[form]:\n",
    "            CorpusTagged[form][pos] = {}\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag)\n",
    "        else:\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for word in conjs:\n",
    "    conjforms(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3639"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CorpusTagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conj + stem + plur + pron+ cop\n",
    "\n",
    "\n",
    "\n",
    "#conj + prep + stem + (plur) + pron + art + cop+ ke\n",
    "#conj + prep + stem + (plur) + pron + art + ra\n",
    "#conj + prep + stem + (plur) + ez\n",
    "\n",
    "pos = 'NUM'\n",
    "\n",
    "def numforms(stem):\n",
    "    Forms = {}\n",
    "    pos = 'NUM'\n",
    "    \n",
    "    #form, tag = addAff(conjs, form, tag)\n",
    "    \n",
    "    for conj in conjs:\n",
    "        conjform = ''\n",
    "        conjtag = ''\n",
    "        conjform += conj\n",
    "        conjtag += conjs[conj]\n",
    "        \n",
    "        for prep in preps:\n",
    "            prepform = ''\n",
    "            preptag = ''\n",
    "            prepform = conjform + prep\n",
    "            preptag = conjtag + preps[prep]\n",
    "            \n",
    "            stemform = prepform + stem\n",
    "            \n",
    "            if (stemform.endswith('ه') or stemform.endswith('ة')):\n",
    "                plurs = plursE\n",
    "            else:\n",
    "                plurs = plursAll\n",
    "                \n",
    "            for plur in plurs:\n",
    "                \n",
    "                plurform = ''\n",
    "                plurtag = ''\n",
    "                \n",
    "                plurstemform = stemform\n",
    "                if plur == 'ات' or plur == 'گان':\n",
    "                    plurstemform = stemform[:-1]\n",
    "                \n",
    "                plurform = plurstemform + plur\n",
    "                plurtag = preptag + plurs[plur]\n",
    "                \n",
    "    \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    ezs = ezsAll\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    ezs = ezsE\n",
    "                else:\n",
    "                    ezs = {'':''}\n",
    "                # if stem.endswith('ی') or stem.endswith('و') or stem.endswith('ا') or stem.endswith('ه')\n",
    "                # u'\\u200c' + ez if stem.endswith('ه')\n",
    "\n",
    "                for ez in ezs:\n",
    "                    ezform = ''\n",
    "                    eztag = ''\n",
    "                    ezform = plurform + ez\n",
    "                    eztag = plurtag + ezs[ez]\n",
    "                    \n",
    "                    #forms.add((ezform, eztag))\n",
    "                    \n",
    "                    if ezform in corpus:\n",
    "                        addform(ezform, eztag, stem)\n",
    "                    \n",
    "                \n",
    "                if plurform.endswith('ی') or plurform.endswith('و') or plurform.endswith('ا'):\n",
    "                    prons = pronsAIU\n",
    "                elif (plurform.endswith('ه') or plurform.endswith('ة')):\n",
    "                    prons = pronsE\n",
    "                else:\n",
    "                    prons = pronsAll\n",
    "                \n",
    "                for pron in prons:\n",
    "                    pronform = ''\n",
    "                    prontag = ''\n",
    "                    pronform = plurform + pron\n",
    "                    prontag = plurtag + prons[pron]\n",
    "                    \n",
    "                    if pronform.endswith('ی') or pronform.endswith('و') or pronform.endswith('ا') or pronform.endswith('ه') or pronform.endswith('ة'):\n",
    "                        arts = artsAIUE\n",
    "                    else:\n",
    "                        arts = artsAll\n",
    "                \n",
    "                    for art in arts:\n",
    "                        artform = ''\n",
    "                        arttag = ''\n",
    "                        artform = pronform + art\n",
    "                        arttag = prontag + arts[art]\n",
    "                        \n",
    "                        if (artform.endswith('ه') or artform.endswith('ة')):\n",
    "                                cops = copsE\n",
    "                        else:\n",
    "                            cops = copsAll\n",
    "                                \n",
    "                        for cop in cops:\n",
    "                            copform = ''\n",
    "                            coptag = ''\n",
    "                            copform = artform + cop\n",
    "                            coptag = arttag + cops[cop]\n",
    "                        \n",
    "                        \n",
    "                            #if 'YEH' in arttag:\n",
    "                            for ke in kes:\n",
    "                                keform = ''\n",
    "                                ketag = ''\n",
    "                                keform = copform + ke\n",
    "                                ketag = coptag + kes[ke]\n",
    "\n",
    "                                \n",
    "                                if keform in corpus:\n",
    "                                    addform(keform, ketag, stem)\n",
    "                               \n",
    "                        \n",
    "                        for ra in ras:\n",
    "                            raform = ''\n",
    "                            ratag = ''\n",
    "                            \n",
    "                            raform = artform + ra\n",
    "                            ratag = arttag + ras[ra]\n",
    "                            \n",
    "                            if raform in corpus:\n",
    "                                addform(raform, ratag, stem)\n",
    "                                \n",
    "                                \n",
    "def addform(form, tag, stem):\n",
    "    if form not in CorpusTagged:\n",
    "        CorpusTagged[form] = {pos: {}}\n",
    "        if stem not in CorpusTagged[form][pos]:\n",
    "            CorpusTagged[form][pos][stem] = {tag}\n",
    "        else:\n",
    "            CorpusTagged[form][pos][stem].add(tag)\n",
    "    else:\n",
    "        if pos not in CorpusTagged[form]:\n",
    "            CorpusTagged[form][pos] = {}\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag)\n",
    "        else:\n",
    "            if stem not in CorpusTagged[form][pos]:\n",
    "                CorpusTagged[form][pos][stem] = {tag}\n",
    "            else:\n",
    "                CorpusTagged[form][pos][stem].add(tag) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in nums:\n",
    "    numforms(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4198"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CorpusTagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeCorpusTagged(filename):\n",
    "    filepath = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "    with open(filepath+filename, 'w', encoding='utf-8') as w:\n",
    "        for form in sorted(CorpusTagged):\n",
    "            w.write(form+'\\t')\n",
    "            npos = 0\n",
    "            for pos in CorpusTagged[form]:\n",
    "                npos += 1\n",
    "                if npos == 1:\n",
    "                    w.write(pos+'$')\n",
    "                else:\n",
    "                    w.write('&' + pos+'$')\n",
    "                nlem = 0\n",
    "                for lemma in CorpusTagged[form][pos]:\n",
    "                    nlem+=1\n",
    "                    if nlem == 1:\n",
    "                        w.write(lemma)\n",
    "                        w.write('+')\n",
    "                    else:\n",
    "                        w.write('*')\n",
    "                        w.write(lemma)\n",
    "                        w.write('+')\n",
    "                    ntag = 0\n",
    "                    for tag in CorpusTagged[form][pos][lemma]:\n",
    "                        ntag += 1\n",
    "                        w.write(tag)\n",
    "                        if ntag != len(CorpusTagged[form][pos][lemma]):\n",
    "                            w.write('#')\n",
    "                    #w.write('@')\n",
    "            w.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'unchangable_tagged_new.txt'\n",
    "writeCorpusTagged(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbfile = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\allverbs_duble.txt'\n",
    "with open(verbfile, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        past, present = line.strip('\\n').split('\\t')\n",
    "        partcs.add(past+'ه')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = open(path+'participles.txt', 'w', encoding='utf-8')\n",
    "\n",
    "for word in partcs:\n",
    "    w.write(word +'\\n')\n",
    "    \n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addform(form, tag, lemm, pos):\n",
    "    if form not in CorpusTaggedFull:\n",
    "        CorpusTaggedFull[form] = {pos: {}}\n",
    "        if lemm not in CorpusTaggedFull[form][pos]:\n",
    "            CorpusTaggedFull[form][pos][lemm] = {tag}\n",
    "        else:\n",
    "            CorpusTaggedFull[form][pos][lemm].add(tag)\n",
    "    else:\n",
    "        if pos not in CorpusTaggedFull[form]:\n",
    "            CorpusTaggedFull[form][pos] = {}\n",
    "            if lemm not in CorpusTaggedFull[form][pos]:\n",
    "                CorpusTaggedFull[form][pos][lemm] = {tag}\n",
    "            else:\n",
    "                CorpusTaggedFull[form][pos][lemm].add(tag)\n",
    "        else:\n",
    "            if lemm not in CorpusTaggedFull[form][pos]:\n",
    "                CorpusTaggedFull[form][pos][lemm] = {tag}\n",
    "            else:\n",
    "                CorpusTaggedFull[form][pos][lemm].add(tag) \n",
    "                \n",
    "                \n",
    "for word in rest:\n",
    "    if word in corpus:\n",
    "        addform(word, '', word, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeCorpusTagged(filename):\n",
    "    filepath = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "    with open(filepath+filename, 'w', encoding='utf-8') as w:\n",
    "        for form in sorted(CorpusTagged):\n",
    "            w.write(form+'\\t')\n",
    "            npos = 0\n",
    "            for pos in CorpusTagged[form]:\n",
    "                npos += 1\n",
    "                if npos == 1:\n",
    "                    w.write(pos+'$')\n",
    "                else:\n",
    "                    w.write('&' + pos+'$')\n",
    "                nlem = 0\n",
    "                for lemma in CorpusTagged[form][pos]:\n",
    "                    nlem+=1\n",
    "                    if nlem == 1:\n",
    "                        w.write(lemma)\n",
    "                        w.write('+')\n",
    "                    else:\n",
    "                        w.write('*')\n",
    "                        w.write(lemma)\n",
    "                        w.write('+')\n",
    "                    ntag = 0\n",
    "                    for tag in CorpusTagged[form][pos][lemma]:\n",
    "                        ntag += 1\n",
    "                        w.write(tag)\n",
    "                        if ntag != len(CorpusTagged[form][pos][lemma])\n",
    "                            w.write('#')\n",
    "                    #w.write('@')\n",
    "            w.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\TaggedWords_unchange.txt'\n",
    "filepath = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "with open(file, 'w', encoding='utf-8') as w: \n",
    "    for form in sorted(CorpusTagged):\n",
    "        w.write(form+'\\t')\n",
    "        npos = 0\n",
    "        for pos in CorpusTagged[form]:\n",
    "            npos += 1\n",
    "            if npos == 1:\n",
    "                w.write(pos+'$')\n",
    "            else:\n",
    "                w.write('&' + pos+'$')\n",
    "            nlem = 0\n",
    "            for lemma in CorpusTagged[form][pos]:\n",
    "                nlem+=1\n",
    "                if nlem == 1:\n",
    "                    w.write(lemma)\n",
    "                    w.write('+')\n",
    "                else:\n",
    "                    w.write('*')\n",
    "                    w.write(lemma)\n",
    "                    w.write('+')\n",
    "                ntag = 0\n",
    "                for tag in CorpusTagged[form][pos][lemma]:\n",
    "                    ntag += 1\n",
    "                    w.write(tag)\n",
    "                    if ntag != len(CorpusTagged[form][pos][lemma])\n",
    "                        w.write('#')\n",
    "                #w.write('@')\n",
    "        w.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addformFull(form, tag, lemm, pos):\n",
    "    if form not in CorpusTaggedFull:\n",
    "        CorpusTaggedFull[form] = {pos: {}}\n",
    "        if lemm not in CorpusTaggedFull[form][pos]:\n",
    "            CorpusTaggedFull[form][pos][lemm] = {tag}\n",
    "        else:\n",
    "            CorpusTaggedFull[form][pos][lemm].add(tag)\n",
    "    else:\n",
    "        if pos not in CorpusTaggedFull[form]:\n",
    "            CorpusTaggedFull[form][pos] = {}\n",
    "            if lemm not in CorpusTagged[form][pos]:\n",
    "                CorpusTaggedFull[form][pos][lemm] = {tag}\n",
    "            else:\n",
    "                CorpusTaggedFull[form][pos][lemm].add(tag)\n",
    "        else:\n",
    "            if lemm not in CorpusTaggedFull[form][pos]:\n",
    "                CorpusTaggedFull[form][pos][lemm] = {tag}\n",
    "            else:\n",
    "                CorpusTaggedFull[form][pos][lemm].add(tag) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CorpusTaggedFull = {}\n",
    "\n",
    "def getCorpusTaggedFromFile(filename):\n",
    "    filepath = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\data\\\\'\n",
    "    f = open(filepath+filename, 'r', encoding='utf-8')\n",
    "    w = open(filepath+'test.txt', 'w', encoding='utf-8')\n",
    "\n",
    "\n",
    "    for line in f:\n",
    "        try:\n",
    "            form, alltags = line.strip('\\n').split('\\t')\n",
    "            postags = alltags.split('&')\n",
    "            for postag in postags:\n",
    "                pos, onepostag = postag.split('$')\n",
    "\n",
    "                lemmtags = onepostag.split('*')\n",
    "                for lemmtag in lemmtags:\n",
    "                    lemm, onelemmtag = lemmtag.split('+')\n",
    "                    tags = onelemmtag.split('#')\n",
    "                    for tag in tags:\n",
    "                        addformFull(form, tag, lemm, pos)\n",
    "\n",
    "        except:\n",
    "            w.write(line)\n",
    "\n",
    "    f.close()\n",
    "    w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CorpusTaggedFull = {}\n",
    "getCorpusTaggedFromFile('unchangable_tagged_new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4198"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CorpusTaggedFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to PRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def add2bayts(bayt, semibayt, sentno, writer):\n",
    "#def getprsdata():\n",
    "    rowDic = {}\n",
    "    #semibayt = 0\n",
    "\n",
    "    #sentno1 = sentn-1\n",
    "    #sentno2 = sentn\n",
    "    #semibayt += 1\n",
    "    #words = punctsplit(delimiters, b.strip())\n",
    "\n",
    "    sent_pos = ''\n",
    "    wordno = 0\n",
    "    for word, taggerpos in bayt:\n",
    "        #if taggerpos == 'PUNC':\n",
    "        #    continue\n",
    "\n",
    "        sent_pos = ''\n",
    "        wordno += 1\n",
    "\n",
    "        if wordno == 1:\n",
    "            sent_pos = 'bos'\n",
    "        elif wordno == len(bayt):\n",
    "            sent_pos = 'eos'\n",
    "\n",
    "        punct = ''   \n",
    "        if sent_pos == 'eos' and semibayt == 1:\n",
    "            punct = '\\\\t'\n",
    "        elif sent_pos == 'eos' and semibayt == 2:\n",
    "            punct = '\\\\n'\n",
    "\n",
    "\n",
    "        #if semibayt == 1:\n",
    "        #    sentno = sentno1\n",
    "        #elif semibayt == 2:\n",
    "        #    sentno = sentno2\n",
    "\n",
    "        newtags = set()\n",
    "        newlemms = set()\n",
    "\n",
    "        if word not in CorpusTaggedFull:\n",
    "            nvars = 1\n",
    "            nvar = 1\n",
    "            nlems = '?'\n",
    "            lem = '?'\n",
    "            lex = taggerpos\n",
    "            gram = '?'\n",
    "\n",
    "            rowDic['#sentno'] = sentno\n",
    "            rowDic['#wordno'] = wordno\n",
    "            #rowDic['#lang'] \n",
    "            #rowDic['#graph'] = graph\n",
    "            rowDic['#word'] = word\n",
    "            #rowDic['#indexword']\n",
    "            rowDic['#nvars'] = nvars\n",
    "            rowDic['#nlems'] = nlems\n",
    "            rowDic['#nvar'] = nvar\n",
    "            rowDic['#lem'] = lem\n",
    "            #rowDic['#trans'] = trans\n",
    "            #rowDic['#trans_ru']\n",
    "            rowDic['#lex'] = lex\n",
    "            rowDic['#gram'] = gram\n",
    "            #rowDic['#flex'] = *?\n",
    "            #rowDic['#punctl'] = punctl\n",
    "            rowDic['#punctr'] = punct\n",
    "            rowDic['#sent_pos'] = sent_pos\n",
    "\n",
    "            writer.writerow(rowDic)\n",
    "            rowDic = {}\n",
    "\n",
    "        else:\n",
    "\n",
    "            if taggerpos == 'V' and word.endswith('ست'):\n",
    "                nvars = 0\n",
    "                for pos in CorpusTaggedFull[word]:\n",
    "                    for lemm in CorpusTaggedFull[word][pos]:\n",
    "                        for tag in CorpusTaggedFull[word][pos][lemm]:\n",
    "                            if 'COP' in tag:\n",
    "                                nvars += 1\n",
    "                                newtags.add((pos, lemm, tag))\n",
    "                                newlemms.add(lemm)\n",
    "                nlems = len(newlemms)\n",
    "            \n",
    "\n",
    "            elif taggerpos in CorpusTaggedFull[word]:\n",
    "                #CorpusTaggedFull[form][pos][lemm] = {tag}\n",
    "\n",
    "                lems = set(CorpusTaggedFull[word][taggerpos].keys())\n",
    "                nlems = len(lems)\n",
    "                nvars = 0\n",
    "                for lemm in lems:\n",
    "                    nvars += len(CorpusTaggedFull[word][taggerpos][lemm])\n",
    "                    for tag in CorpusTaggedFull[word][taggerpos][lemm]:\n",
    "                        newtags.add((taggerpos, lemm, tag))\n",
    "                    newlemms.add(lemm)\n",
    "                    \n",
    "            elif taggerpos not in CorpusTaggedFull[word]: #in ('CL', 'RES', 'DET'):\n",
    "                nvars = 0\n",
    "                for pos in CorpusTaggedFull[word]:\n",
    "                    for lemm in CorpusTaggedFull[word][pos]:\n",
    "                        for tag in CorpusTaggedFull[word][pos][lemm]:\n",
    "                            nvars += 1\n",
    "                            newtags.add((pos, lemm, tag))\n",
    "                            newlemms.add(lemm)\n",
    "                nlems = len(newlemms)\n",
    "\n",
    "\n",
    "            nvar = 0\n",
    "\n",
    "            for pos, lemm, tag in newtags:\n",
    "                nvar += 1\n",
    "                lem = lemm\n",
    "                lex = pos\n",
    "                gram = tag\n",
    "\n",
    "\n",
    "\n",
    "                rowDic['#sentno'] = sentno\n",
    "                rowDic['#wordno'] = wordno\n",
    "                #rowDic['#lang'] \n",
    "                #rowDic['#graph'] = graph\n",
    "                rowDic['#word'] = word\n",
    "                #rowDic['#indexword']\n",
    "                rowDic['#nvars'] = nvars\n",
    "                rowDic['#nlems'] = nlems\n",
    "                rowDic['#nvar'] = nvar\n",
    "                rowDic['#lem'] = lem\n",
    "                #rowDic['#trans'] = trans\n",
    "                #rowDic['#trans_ru']\n",
    "                rowDic['#lex'] = lex\n",
    "                rowDic['#gram'] = gram\n",
    "                #rowDic['#flex'] = *?\n",
    "                #rowDic['#punctl'] = punctl\n",
    "                rowDic['#punctr'] = punct\n",
    "                rowDic['#sent_pos'] = sent_pos\n",
    "\n",
    "                writer.writerow(rowDic)\n",
    "                rowDic = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('از', 'P'), ('تو', 'PRO'), ('مهرم', 'N'), ('چو', 'ADV'), ('در', 'P'), ('نهاد', 'N'), ('بود', 'V')]\n",
      "[('من', 'PRO'), ('کیم', 'V'), ('تا', 'CONJ'), ('مرا', 'PRO'), ('مراد', 'N'), ('بود', 'V')]\n",
      "[('جز', 'P'), ('مرادت', 'N'), ('مرا', 'PRO'), ('مرادی', 'N'), ('نیست', 'V')]\n",
      "[('غیر', 'N'), ('ازین', 'N'), ('خاطری', 'N'), ('و', 'CONJ'), ('یادی', 'N'), ('نیست', 'V')]\n",
      "[('هرکه', 'CONJ'), ('او', 'PRO'), ('در', 'P'), ('غم', 'N'), ('تو', 'PRO'), ('دل', 'N'), ('بنهاد', 'V')]\n",
      "[('آرزوها', 'N'), ('به', 'P'), ('آرزوی', 'N'), ('تو', 'PRO'), ('داد', 'V')]\n",
      "[('شوق', 'N'), ('دل\\u200cها', 'N'), ('ارادت', 'N'), ('تو', 'PRO'), ('بود', 'V')]\n",
      "[('ذوق', 'N'), ('جان\\u200cها', 'N'), ('عبادت', 'N'), ('تو', 'PRO'), ('بود', 'V')]\n",
      "[('تا', 'CONJ'), ('که', 'CONJ'), ('خاک', 'N'), ('درت', 'N'), ('پناه', 'N'), ('من', 'PRO'), ('است', 'V')]\n",
      "[('آستان', 'N'), ('تو', 'PRO'), ('سجده\\u200cگاه', 'N'), ('من', 'PRO'), ('است', 'V')]\n",
      "[('من', 'PRO'), ('ز', 'P'), ('کویت', 'N'), ('بدر', 'N'), ('ندانم', 'V'), ('رفت', 'V')]\n",
      "[('زانکه', 'P'), ('زین', 'N'), ('در', 'P'), ('کجا', 'ADV'), ('توانم', 'N'), ('رفت', 'V')]\n",
      "[('زین', 'P'), ('سخن\\u200cها', 'N'), ('خلاصه', 'AJ'), ('دانی', 'V'), ('چیست', 'V')]\n",
      "[('آنکه', 'CONJ'), ('دور', 'AJ'), ('از', 'P'), ('تو', 'PRO'), ('من', 'PRO'), ('ندانم', 'V'), ('زیست', 'N')]\n",
      "[('گرچه', 'CONJ'), ('داری', 'V'), ('چو', 'ADV'), ('من', 'PRO'), ('هزار', 'NUM'), ('هزار', 'NUM')]\n",
      "[('ختم', 'N'), ('گشت', 'N'), ('این', 'DET'), ('سخن', 'N'), ('برین', 'AJ'), ('گفتار', 'N')]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def toPRS(infile, outfile)\n",
    "#path = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\collect\\\\POStagged\\\\fa\\\\9\\\\13\\\\47\\\\'\n",
    "#infile = path+'2446.txt'\n",
    "#outfile = path+ '2446.prs'\n",
    "    with open(infile, 'r', encoding='utf-8') as f:\n",
    "    with open(outfile, 'w', encoding='utf-8') as w:\n",
    "\n",
    "        fieldnames = ['#sentno','#wordno','#lang','#graph','#word','#indexword','#nvars','#nlems','#nvar',\n",
    "                      '#lem','#trans','#trans_ru','#lex','#gram','#flex','#punctl','#punctr','#sent_pos']\n",
    "\n",
    "        writer = csv.DictWriter(w, fieldnames=fieldnames, delimiter = '\\t', restval = '', lineterminator='\\n')\n",
    "\n",
    "        sentno = 0\n",
    "        #wordno = 0\n",
    "        #linelist = []\n",
    "        baytlist_1 = []\n",
    "        baytlist_2 = []\n",
    "        bnum = 1\n",
    "        for line in f:\n",
    "\n",
    "\n",
    "\n",
    "            #sentno = 1\n",
    "            if line.startswith('#meta.') or line.startswith('#sentno'):\n",
    "                if line.startswith('#meta.sentences'):\n",
    "                    meta, num = line.strip('\\n').split('\\t')\n",
    "                    newnum = int(num)*2\n",
    "                    w.write(meta+'\\t'+str(newnum)+'\\n')\n",
    "                else:\n",
    "                    w.write(line)\n",
    "            elif line != '\\n':\n",
    "                if line.startswith('##'):\n",
    "                    sentno += 1\n",
    "                    add2bayts(baytlist_2, 2, sentno, writer)\n",
    "                    print(baytlist_2)\n",
    "                    bnum = 1\n",
    "                    baytlist_1 = []\n",
    "                    baytlist_2 = []\n",
    "                elif line == '#\\n':\n",
    "                    bnum += 1\n",
    "                    sentno += 1\n",
    "                    #print(len(baytlist_1))\n",
    "                    print(baytlist_1)\n",
    "                    add2bayts(baytlist_1, 1 , sentno, writer)\n",
    "\n",
    "                else:\n",
    "                    word, taggerpos = line.strip('\\n').split('\\t')\n",
    "\n",
    "                    if taggerpos.endswith('e'):\n",
    "                        taggerpos = taggerpos[:-1]\n",
    "\n",
    "                    if taggerpos == 'PUNC':\n",
    "                        continue\n",
    "\n",
    "                    #linelist.append((word, taggerpos))\n",
    "                    elif bnum == 1:\n",
    "                        baytlist_1.append((word, taggerpos))\n",
    "                    elif bnum == 2:\n",
    "                        baytlist_2.append((word, taggerpos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INT': {'جز': {''}}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "path = \"C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\collect\\\\POStagged\\\\fa\\\\\"\n",
    "#newpath = 'C:\\\\Users\\\\TK_adm\\\\Documents\\\\HSE\\\\comp_ling_progr\\\\iranica\\\\collect\\\\prs\\\\fa\\\\'\n",
    "#os.makedirs(os.path.dirname(filenamefa), exist_ok=True)\n",
    "\n",
    "count = 0\n",
    "for dirpath, dirnames, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        oldfile = '\\\\'.join((dirpath, filename))\n",
    "        #print('\\\\'.join((dirpath, filename)))\n",
    "        newfile = oldfile.replace('POStagged', 'PRSnew')\n",
    "        newfile = newfile.replace('.txt', '.prs')\n",
    "        \n",
    "        os.makedirs(os.path.dirname(newfile), exist_ok=True)\n",
    "        \n",
    "        #taggedfile = open(newfile, 'w', encoding='utf-8')\n",
    "        #writer = csv.DictWriter(taggedfile, fieldnames=fieldnames, delimiter = '\\t', restval = '', lineterminator='\\n')\n",
    "        #writer.writeheader()\n",
    "        \n",
    "        #print(oldfile)\n",
    "        #print(newfile)\n",
    "        \n",
    "        toPRS(oldfile, newfile)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
